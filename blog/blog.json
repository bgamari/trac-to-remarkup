[{"name":"about","version":1,"title":"The About post","body":"This is the about post.","publish_time":1282656028,"version_time":1282656028,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"about","version":2,"title":"The GHC blog","body":"As an experiment, we are moving the GHC blog from [http://ghcmutterings.wordpress.com/] to here.\\r\\n","publish_time":1282656028,"version_time":1282656177,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"debian-squeeze","version":1,"title":"Debian 6.0 \"Squeeze\" frozen... announcement mentions GHC","body":"The [http://www.debian.org/News/2010/20100806 announcement for the recent freeze of Debian 6.0] specifically mentions GHC 6.12 alongside Python, Perl, and GCC in  the list of compilers and interpreters for \"common languages\".  A milestone reached?\\r\\n","publish_time":1282743124,"version_time":1282743124,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"debian-squeeze","version":2,"title":"Debian 6.0 \"Squeeze\" frozen... announcement mentions GHC","body":"The [http://www.debian.org/News/2010/20100806 announcement for the recent freeze of Debian 6.0] specifically mentions GHC 6.12 alongside Python, Perl, and GCC in  the list of compilers and interpreters for \"common languages\".  A milestone reached?  (thanks to Reuben Thomas for sending us the link)\\r\\n","publish_time":1282743124,"version_time":1282743211,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"new-gc-preview","version":1,"title":"First results from GHC's new garbage collector","body":"For a number of months now, we have been designing and developing a new garbage collector for GHC, with the primary goal of improving scaling on multicores.  The current garbage collector isn't exactly a slouch: it is a parallel generational design, and after [http://www.haskell.org/~simonmar/bib/multicore-ghc-09_abstract.html going to some effort to improve locality] we managed to achieve some respectable scaling results on up to 8 cores, and the Intel CnC project has been able to achieve [http://www.haskell.org/~simonmar/bib/cnc-2010_abstract.html even greater speedups] (as much as 22x on a 32-core machine) with carefully-tuned benchmarks.\\r\\n\\r\\nStill, we recognise that the garbage collector is often the bottleneck where scaling is concerned.  Tuning a program for scaling usually involves reducing its demands on the memory subsystem and hence reducing the amount of GC that happens.  Here's how the current GC impedes scaling:\\r\\n\\r\\n[[Image(minimax-head.png)]]\\r\\n\\r\\nThis is a screenshot from [http://research.microsoft.com/en-us/projects/threadscope/ ThreadScope], showing part of the timeline of the execution of a parallel Haskell program - in this case, the [http://darcs.haskell.org/nofib/parallel/minimax minimax] program for searching the game tree of 4x4 noughts and crosses.  Each bar represents the execution of a single CPU, and the thin orange/green bars are the GCs.  Every GC stops all the threads and performs the GC in parallel, before restarting the computation again.  This is known as \"stop the world\" parallal GC - compared to other techniques such as concurrent GC it's easier to implement and generally gives good performance.  Many industrial-strength virtual machines use stop-the-world parallel GC in their server products, because it gives the best throughput.  However, the diagram clearly shows that we're wasting time here: the GCs aren't well-balanced (the green parts show the actual work, the orange parts are setup/shutdown of the GC tasks and idle time).  We deliberately don't load-balance the work in young-generation collections, because doing so impacts locality and is worse for overall performance (we discussed this in the [http://www.haskell.org/~simonmar/bib/multicore-ghc-09_abstract.html ICFP'09 paper] and gave measurements).  So we end up wasting some of our processor bandwidth, and hence losing some scaling.\\r\\n\\r\\nNot only that, but the cost of the all-core synchronisation becomes a bottleneck as the number of cores increases, and the need for rapid synchronisations causes problems if the OS decides to borrow one of the cores to do something else for a while: the symptom of this problem has been dubbed the \"last core parallel slowdown\" in Haskell.\\r\\n\\r\\nHere's what our new GC looks like on the same program:\\r\\n\\r\\n[[Image(minimax-new.png)]]\\r\\n\\r\\nThe heap organisation in fact hasn't changed much: there are still per-core young generations and a single old generation, but the improvement is that the per-core young generations can be collected independently without stopping the other threads.  Collecting the old generation - the \"global heap\" - still requires stopping all the threads, but since this is the old generation, global collections are much less frequent than local collections.\\r\\n\\r\\nSince there are fewer synchronisations and less wasted processor bandwidth, the overall throughput is higher - only about 10% on 8 cores with this example, but there are other (less picturesque) examples that improve more, and it's still early days and we have a lot of tuning to do.  We expect the benefits to be greater on larger numbers of cores, and furthermore the \"last core slowdown\" should be finally banished.\\r\\n\\r\\nDesigns like this have appeared in the literature (starting with [http://portal.acm.org/citation.cfm?id=158511.158611 Doligez/Leroy POPL'93]), and ours borrows ideas from several of these earlier designs while adding a few novel twists of our own.  We plan to write up the design properly once all the tuning is done and we have some solid results.  I expect it to land in GHC HEAD in a few months time, and it should be in the autumn 2011 major release of GHC.\\r\\n","publish_time":1283503352,"version_time":1283503352,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":"garbage-collector runtime-system"},
{"name":"new-gc-preview","version":2,"title":"First results from GHC's new garbage collector","body":"For a number of months now, we have been designing and developing a new garbage collector for GHC, with the primary goal of improving scaling on multicores.  The current garbage collector isn't exactly a slouch: it is a parallel generational design, and after [http://www.haskell.org/~simonmar/bib/multicore-ghc-09_abstract.html going to some effort to improve locality] we managed to achieve some respectable scaling results on up to 8 cores, and the Intel CnC project has been able to achieve [http://www.haskell.org/~simonmar/bib/cnc-2010_abstract.html even greater speedups] (as much as 22x on a 32-core machine) with carefully-tuned benchmarks.\\r\\n\\r\\nStill, we recognise that the garbage collector is often the bottleneck where scaling is concerned.  Tuning a program for scaling usually involves reducing its demands on the memory subsystem and hence reducing the amount of GC that happens.  Here's how the current GC impedes scaling:\\r\\n\\r\\n[[Image(minimax-head.png)]]\\r\\n\\r\\nThis is a screenshot from [http://research.microsoft.com/en-us/projects/threadscope/ ThreadScope], showing part of the timeline of the execution of a parallel Haskell program - in this case, the [http://darcs.haskell.org/nofib/parallel/minimax minimax] program for searching the game tree of 4x4 noughts and crosses.  Each bar represents the execution of a single CPU, and the thin orange/green bars are the GCs.  Every GC stops all the threads and performs the GC in parallel, before restarting the computation again.  This is known as \"stop the world\" parallal GC - compared to other techniques such as concurrent GC it's easier to implement and generally gives good performance.  Many industrial-strength virtual machines use stop-the-world parallel GC in their server products, because it gives the best throughput.  However, the diagram clearly shows that we're wasting time here: the GCs aren't well-balanced (the green parts show the actual work, the blank parts are idle time).  We deliberately don't load-balance the work in young-generation collections, because doing so impacts locality and is worse for overall performance (we discussed this in the [http://www.haskell.org/~simonmar/bib/multicore-ghc-09_abstract.html ICFP'09 paper] and gave measurements).  So we end up wasting some of our processor bandwidth, and hence losing some scaling.\\r\\n\\r\\nNot only that, but the cost of the all-core synchronisation becomes a bottleneck as the number of cores increases, and the need for rapid synchronisations causes problems if the OS decides to borrow one of the cores to do something else for a while: the symptom of this problem has been dubbed the \"last core parallel slowdown\" in Haskell.\\r\\n\\r\\nHere's what our new GC looks like on the same program:\\r\\n\\r\\n[[Image(minimax-new.png)]]\\r\\n\\r\\nThe heap organisation in fact hasn't changed much: there are still per-core young generations and a single old generation, but the improvement is that the per-core young generations can be collected independently without stopping the other threads.  Collecting the old generation - the \"global heap\" - still requires stopping all the threads, but since this is the old generation, global collections are much less frequent than local collections.\\r\\n\\r\\nSince there are fewer synchronisations and less wasted processor bandwidth, the overall throughput is higher - only about 10% on 8 cores with this example, but there are other (less picturesque) examples that improve more, and it's still early days and we have a lot of tuning to do.  We expect the benefits to be greater on larger numbers of cores, and furthermore the \"last core slowdown\" should be finally banished.\\r\\n\\r\\nDesigns like this have appeared in the literature (starting with [http://portal.acm.org/citation.cfm?id=158511.158611 Doligez/Leroy POPL'93]), and ours borrows ideas from several of these earlier designs while adding a few novel twists of our own.  We plan to write up the design properly once all the tuning is done and we have some solid results.  I expect it to land in GHC HEAD in a few months time, and it should be in the autumn 2011 major release of GHC.\\r\\n","publish_time":1283503352,"version_time":1283503621,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":"garbage-collector runtime-system"},
{"name":"LetGeneralisationInGhc7","version":1,"title":"Let generalisation in GHC 7.0","body":"GHC 7.0 has a completely new type inference engine. The old one had\\r\\ngrown to resemble the closing stages of a game of Jenga, in which making any\\r\\nchange was an extremely delicate operation that risked bringing \\r\\nthe whole edifice crashing down.  In particular, there were a dozen open\\r\\nbugs concerning type families that I had no idea how to fix.\\r\\n\\r\\nThis summer Dimitrios Vytiniotis, Brent Yorgey and I built \\r\\na completely new inference engine.  It rests on a solid\\r\\ntechnical foundation developed over the last couple\\r\\nof years, in a collaboration with Dimitrios, Tom Schrijvers, and Martin\\r\\nSulzmann.  There is a series of papers that lead up to it, but our\\r\\nJFP submission \\r\\n\"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\"\\r\\nsummarises the whole thing in one consistent notation.\\r\\n\\r\\nThe new engine feels much more solid to me, and indeed I've been able\\r\\nto close almost all those open bugs.  Doubtless there will be some\\r\\nnew ones, but I feel vastly more confident that we can fix them\\r\\nthan I did with the old engine.\\r\\n\\r\\nOne other thing is that the new typechecker has completely swept away\\r\\nthe old rather ''ad-hoc'' stuff about \"rigid\" types in GADT pattern matches.  So\\r\\nyou may find that some GADT programs will typecheck with fewer\\r\\ntype annotations than before.  \\r\\n\\r\\nHowever, there is one way in which GHC 7.0 will type ''fewer'' programs\\r\\nthan before, and that is the focus of this post. I want explain what the\\r\\nchange is, and  how to adapt your code to accommodate it.\\r\\n\\r\\n== Local polymorphism ==\\r\\n\\r\\nConsider this (contrived) program:\\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\n\\r\\nf :: forall a. a -> ((a, Char), (a, Bool))\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g :: forall b. b -> (a,b)\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nThis polymorphism is expressed in `g`'s type signature:\\r\\n  * `g` is a ''polymorphic'' function, because it is applied both to the character 'v' and to the boolean `True`.  \\r\\n  * However, `g` is ''monomorphic'' in `a`, because `g`'s body mentions `x`\\r\\nThe type signature `g :: forall b. b -> (a,b)`\\r\\nreflects these two points:\\r\\n  * The \"`forall b`\" says that `g` is polymorphic in `b`.  \\r\\n\\r\\n  * The `a` in the signature must is the `a` in the type of `x`.  This type variable `a` is brought into scope, in the body of `f`, by the `forall a` in the type signature for `f`.\\r\\nThe `LANGUAGE ScopedTypeVariables` pragma (a) allows you to use an\\r\\nexplicit \"`forall`\" in the type signature for a function `f`, and (b)\\r\\nbrings the `forall`'d type variables (`a` in this case) into scope in the body of the\\r\\nfunction `f`.\\r\\n\\r\\n== What has changed in GHC 7.0? == \\r\\n\\r\\nGHC 6.12 will compile the above program without any type signatures at all.\\r\\nIt infers the polymorphic type for `g`.  But, if you are using\\r\\ntype families or GADTs, GHC 7.0 will not.  More precisely:\\r\\n * The flags `-XGADTs` or `-XTypeFamilies`, or the corresponding `LANGUAGE` pragmas,\\r\\n   imply the (new) flag `-XMonoLocalBinds`.  \\r\\n\\r\\n * With `-XMonoLocalBinds`, non-top-level (or ''local'') let/where \\r\\n   bindings are not generalised.\\r\\n\\r\\n * Remember that `-fglasgow-exts` implies `-XGADTs` and hence `-XTypeFamilies`.\\r\\n\\r\\nSo given the type-signature-free code\\r\\n{{{\\r\\n{-# LANGUAGE MonoLocalBinds #-}\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nGHC 7.0 will reject the program with\\r\\n{{{\\r\\nFoo.hs:6:17:\\r\\n    Couldn't match expected type `Char' with actual type `Bool'\\r\\n    In the first argument of `g', namely `True'\\r\\n    In the expression: g True\\r\\n    In the expression: (g 'v', g True)\\r\\n}}}\\r\\nWhy?  Because the type of `g` is not generalised, so it\\r\\ncan only be applied to either `Char` or `Bool` but not both.\\r\\n\\r\\n== How can I fix my program? ==\\r\\n\\r\\nAlmost all code doesn't need local let definitions to have\\r\\na polymorphic type, because the function is only used at one type.\\r\\nBut not all.  There are two ways to fix your program if it falls\\r\\nover because of the `MonoLocalBinds` change.\\r\\n\\r\\n * The good way is simply give a type signature to the local definition, as I did for `g` above.  Writing such a type signature may force you to use `{-# LANGUAGE ScopedTypeVariables #-}` as the above example showed.  My experience is that the code is easier to understand with the type signature.\\r\\n\\r\\n * The `-XGADTs` or `-XTypeFamilies` pragmas switch on `MonoLocalBinds` but, if you want, you can override it with `-XNoMonoLocalBinds` (or the equivalent `LANGUAGE` pragma).  The type checker will then do its best to generalise local bindings, and your program will almost certainly work.  However, I don't know how to guarantee any good properties of the type inference algorithm.  So I think this is ok as as short term fix, but I'd like to encourage you to add that handful of type signatures instead.\\r\\n\\r\\nYou may not be very familiar with the code,\\r\\nso it can be tricky to work out what type the local definition should have.\\r\\n(That's one reason I think that the code is improved by having a type signature!)\\r\\nWith this in mind I've added a new warning flag `-fwarn-missing-local-sigs`, which\\r\\nprints a warning, and the type, of any ''polymorphic'' local binding that\\r\\nlacks a type signature. So you can follow this procedure:\\r\\n * Compile with `-XNoMonoLocalBinds -fwarn-missing-local-sigs`. The first flag makes it compile, and the second shows you the types.\\r\\n * Compile with neither flag, getting some errors.\\r\\n * Add type signatures to cure the errors, using the types printed out in the first step.\\r\\n\\r\\n== A second, bigger example == \\r\\n\\r\\nOne relatively common situation in which you need a local type signature\\r\\nis when you use `runST` with some auxiliary definitions.  \\r\\nHere is a typical example: \\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\nmodule Test where\\r\\nimport Control.Monad.ST\\r\\nimport Data.STRef\\r\\n\\r\\nfoo :: forall a. Bool -> a -> a -> a\\r\\nfoo b x y = runST (do { r <- newSTRef x; fill r; readSTRef r })\\r\\n          where\\r\\n            -- fill :: forall s. STRef s a -> ST s ()\\r\\n            fill r = case b of\\r\\n                       True  -> return ()\\r\\n                       False -> writeSTRef r y\\r\\n\\r\\n-- runST :: forall a. (forall s. ST s a) -> a\\r\\n-- newSTRef   :: a -> ST s (STRef s a)\\r\\n-- readSTRef  :: STRef s a -> ST s a\\r\\n-- writeSTRef :: STRef s a -> a -> ST s ()\\r\\n}}}\\r\\nThe function `foo` is a bit contrived, but it's typical of the way\\r\\nin which `runST` is often used.  We allocate a reference cell, containing `x`,\\r\\ncall `fill`, and then read out what is now in the reference cell.  \\r\\nAll `fill` does is overwrite the cell if `b` is `False`.\\r\\nSo `foo` is really an elaborate `if` function.\\r\\n\\r\\nBut in GHC 7.0, with `-XMonoLocalBinds` (or `-XGADTs`, `-XTypeFamilies`),\\r\\nthe program will be rejected with this alarming-seeming error message\\r\\n{{{\\r\\nFoo.hs:7:11:\\r\\n    Couldn't match type `s' with `s1'\\r\\n      because this skolem type variable would escape: `s1'\\r\\n    This skolem is bound by the polymorphic type `forall s. ST s a'\\r\\n    The following variables have types that mention s\\r\\n      fill :: STRef s a -> ST s () (bound at Foo.hs:10:11)\\r\\n    In the first argument of `runST', namely\\r\\n      `(do { r <- newSTRef x; fill r; readSTRef r })'\\r\\n}}}\\r\\nRemember, `fill` has not been generalised, so it gets a monomorphic type.\\r\\nThat in turn means that the argument to `runST` is not polymorphic enough.\\r\\n\\r\\nDespite its scariness, in some ways the error message identifies\\r\\nthe problem more clearly than the previous example. In particular, the error\\r\\nmessage identifies `fill` as the culprit.  \\r\\nYou can fix it the same way as before, by adding a signature for `fill`;\\r\\nI've put it in a comment above.\\r\\n\\r\\n== Why make this change? ==\\r\\n\\r\\nAt first this change seems like retrograde step, so why did we make\\r\\nit?  It's a long story, but the short summary is this: I don't know\\r\\nhow to build a reliable, predictable type inference engine for a type\\r\\nsystem that has both (a) generalisation of local let/where and (b) local\\r\\ntype equality assumptions, such as those introduced by GADTs.  The story is told\\r\\nin our paper \"[http://research.microsoft.com/en-us/um/people/simonpj/papers/constraints/index.htm Let should not be generalised]\" and, at greater length, in \\r\\nthe journal version \"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\".\\r\\n\\r\\n","publish_time":1285811634,"version_time":1285811634,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"LetGeneralisationInGhc7","version":2,"title":"Let generalisation in GHC 7.0","body":"GHC 7.0 has a completely new type inference engine. The old one had\\r\\ngrown to resemble the closing stages of a game of Jenga, in which making any\\r\\nchange was a delicate operation that risked bringing \\r\\nthe whole edifice crashing down.  In particular, there were a dozen open\\r\\nbugs concerning type families that I had no idea how to fix.\\r\\n\\r\\nThis summer Dimitrios Vytiniotis, Brent Yorgey and I built \\r\\na completely new inference engine.  It rests on a solid\\r\\ntechnical foundation developed over the last couple\\r\\nof years, in a collaboration with Dimitrios, Tom Schrijvers, and Martin\\r\\nSulzmann.  There is a series of papers that lead up to it, but our\\r\\nJFP submission \\r\\n\"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\"\\r\\nsummarises the whole thing in one consistent notation.\\r\\n\\r\\nThe new engine feels much more solid to me, and indeed I've been able\\r\\nto close almost all those open bugs.  Doubtless there will be some\\r\\nnew ones, but I feel vastly more confident that we can fix them\\r\\nthan I did with the old engine.\\r\\n\\r\\nOne other thing is that the new typechecker has completely swept away\\r\\nthe old rather ''ad-hoc'' stuff about \"rigid\" types in GADT pattern matches.  So\\r\\nyou may find that some GADT programs will typecheck with fewer\\r\\ntype annotations than before.  \\r\\n\\r\\nHowever, there is one way in which GHC 7.0 will type ''fewer'' programs\\r\\nthan before, and that is the focus of this post. I want explain what the\\r\\nchange is, and  how to adapt your code to accommodate it.\\r\\n\\r\\n== Local polymorphism ==\\r\\n\\r\\nConsider this (contrived) program:\\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\n\\r\\nf :: forall a. a -> ((a, Char), (a, Bool))\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g :: forall b. b -> (a,b)\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nThis polymorphism is expressed in `g`'s type signature:\\r\\n  * `g` is a ''polymorphic'' function, because it is applied both to the character 'v' and to the boolean `True`.  \\r\\n  * However, `g` is ''monomorphic'' in `a`, because `g`'s body mentions `x`\\r\\nThe type signature `g :: forall b. b -> (a,b)`\\r\\nreflects these two points:\\r\\n  * The \"`forall b`\" says that `g` is polymorphic in `b`.  \\r\\n\\r\\n  * The `a` in the signature must is the `a` in the type of `x`.  This type variable `a` is brought into scope, in the body of `f`, by the `forall a` in the type signature for `f`.\\r\\nThe `LANGUAGE ScopedTypeVariables` pragma (a) allows you to use an\\r\\nexplicit \"`forall`\" in the type signature for a function `f`, and (b)\\r\\nbrings the `forall`'d type variables (`a` in this case) into scope in the body of the\\r\\nfunction `f`.\\r\\n\\r\\n== What has changed in GHC 7.0? == \\r\\n\\r\\nGHC 6.12 will compile the above program without any type signatures at all.\\r\\nIt infers the polymorphic type for `g`.  But, if you are using\\r\\ntype families or GADTs, GHC 7.0 will not.  More precisely:\\r\\n * The flags `-XGADTs` or `-XTypeFamilies`, or the corresponding `LANGUAGE` pragmas,\\r\\n   imply the (new) flag `-XMonoLocalBinds`.  \\r\\n\\r\\n * With `-XMonoLocalBinds`, non-top-level (or ''local'') let/where \\r\\n   bindings are not generalised.\\r\\n\\r\\n * Remember that `-fglasgow-exts` implies `-XGADTs` and hence `-XTypeFamilies`.\\r\\n\\r\\nSo given the type-signature-free code\\r\\n{{{\\r\\n{-# LANGUAGE MonoLocalBinds #-}\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nGHC 7.0 will reject the program with\\r\\n{{{\\r\\nFoo.hs:6:17:\\r\\n    Couldn't match expected type `Char' with actual type `Bool'\\r\\n    In the first argument of `g', namely `True'\\r\\n    In the expression: g True\\r\\n    In the expression: (g 'v', g True)\\r\\n}}}\\r\\nWhy?  Because the type of `g` is not generalised, so it\\r\\ncan only be applied to either `Char` or `Bool` but not both.\\r\\n\\r\\n== How can I fix my program? ==\\r\\n\\r\\nAlmost all code doesn't need local let definitions to have\\r\\na polymorphic type, because the function is only used at one type.\\r\\nBut not all.  There are two ways to fix your program if it falls\\r\\nover because of the `MonoLocalBinds` change.\\r\\n\\r\\n * The good way is simply give a type signature to the local definition, as I did for `g` above.  Writing such a type signature may force you to use `{-# LANGUAGE ScopedTypeVariables #-}` as the above example showed.  My experience is that the code is easier to understand with the type signature.\\r\\n\\r\\n * The `-XGADTs` or `-XTypeFamilies` pragmas switch on `MonoLocalBinds` but, if you want, you can override it with `-XNoMonoLocalBinds` (or the equivalent `LANGUAGE` pragma).  The type checker will then do its best to generalise local bindings, and your program will almost certainly work.  However, I don't know how to guarantee any good properties of the type inference algorithm.  So I think this is ok as as short term fix, but I'd like to encourage you to add that handful of type signatures instead.\\r\\n\\r\\nYou may not be very familiar with the code,\\r\\nso it can be tricky to work out what type the local definition should have.\\r\\n(That's one reason I think that the code is improved by having a type signature!)\\r\\nWith this in mind I've added a new warning flag `-fwarn-missing-local-sigs`, which\\r\\nprints a warning, and the type, of any ''polymorphic'' local binding that\\r\\nlacks a type signature. So you can follow this procedure:\\r\\n * Compile with `-XNoMonoLocalBinds -fwarn-missing-local-sigs`. The first flag makes it compile, and the second shows you the types.\\r\\n * Compile with neither flag, getting some errors.\\r\\n * Add type signatures to cure the errors, using the types printed out in the first step.\\r\\n\\r\\n== A second, bigger example == \\r\\n\\r\\nOne relatively common situation in which you need a local type signature\\r\\nis when you use `runST` with some auxiliary definitions.  \\r\\nHere is a typical example: \\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\nmodule Test where\\r\\nimport Control.Monad.ST\\r\\nimport Data.STRef\\r\\n\\r\\nfoo :: forall a. Bool -> a -> a -> a\\r\\nfoo b x y = runST (do { r <- newSTRef x; fill r; readSTRef r })\\r\\n          where\\r\\n            -- fill :: forall s. STRef s a -> ST s ()\\r\\n            fill r = case b of\\r\\n                       True  -> return ()\\r\\n                       False -> writeSTRef r y\\r\\n\\r\\n-- runST :: forall a. (forall s. ST s a) -> a\\r\\n-- newSTRef   :: a -> ST s (STRef s a)\\r\\n-- readSTRef  :: STRef s a -> ST s a\\r\\n-- writeSTRef :: STRef s a -> a -> ST s ()\\r\\n}}}\\r\\nThe function `foo` is a bit contrived, but it's typical of the way\\r\\nin which `runST` is often used.  We allocate a reference cell, containing `x`,\\r\\ncall `fill`, and then read out what is now in the reference cell.  \\r\\nAll `fill` does is overwrite the cell if `b` is `False`.\\r\\nSo `foo` is really an elaborate `if` function.\\r\\n\\r\\nBut in GHC 7.0, with `-XMonoLocalBinds` (or `-XGADTs`, `-XTypeFamilies`),\\r\\nthe program will be rejected with this alarming-seeming error message\\r\\n{{{\\r\\nFoo.hs:7:11:\\r\\n    Couldn't match type `s' with `s1'\\r\\n      because this skolem type variable would escape: `s1'\\r\\n    This skolem is bound by the polymorphic type `forall s. ST s a'\\r\\n    The following variables have types that mention s\\r\\n      fill :: STRef s a -> ST s () (bound at Foo.hs:10:11)\\r\\n    In the first argument of `runST', namely\\r\\n      `(do { r <- newSTRef x; fill r; readSTRef r })'\\r\\n}}}\\r\\nRemember, `fill` has not been generalised, so it gets a monomorphic type.\\r\\nThat in turn means that the argument to `runST` is not polymorphic enough.\\r\\n\\r\\nDespite its scariness, in some ways the error message identifies\\r\\nthe problem more clearly than the previous example. In particular, the error\\r\\nmessage identifies `fill` as the culprit.  \\r\\nYou can fix it the same way as before, by adding a signature for `fill`;\\r\\nI've put it in a comment above.\\r\\n\\r\\n== Why make this change? ==\\r\\n\\r\\nAt first this change seems like retrograde step, so why did we make\\r\\nit?  It's a long story, but the short summary is this: I don't know\\r\\nhow to build a reliable, predictable type inference engine for a type\\r\\nsystem that has both (a) generalisation of local let/where and (b) local\\r\\ntype equality assumptions, such as those introduced by GADTs.  The story is told\\r\\nin our paper \"[http://research.microsoft.com/en-us/um/people/simonpj/papers/constraints/index.htm Let should not be generalised]\" and, at greater length, in \\r\\nthe journal version \"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\".\\r\\n\\r\\n","publish_time":1285811634,"version_time":1285811657,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"LetGeneralisationInGhc7","version":3,"title":"Let generalisation in GHC 7.0","body":"GHC 7.0 has a completely new type inference engine. The old one had\\r\\ngrown to resemble the closing stages of a game of Jenga, in which making any\\r\\nchange was a delicate operation that risked bringing \\r\\nthe whole edifice crashing down.  In particular, there were a dozen open\\r\\nbugs concerning type families that I had no idea how to fix.\\r\\n\\r\\nThis summer Dimitrios Vytiniotis, Brent Yorgey and I built \\r\\na completely new inference engine.  It rests on a solid\\r\\ntechnical foundation developed over the last couple\\r\\nof years, in a collaboration with Dimitrios, Tom Schrijvers, and Martin\\r\\nSulzmann.  There is a series of papers that lead up to it, but our\\r\\nJFP submission \\r\\n\"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\"\\r\\nsummarises the whole thing in one consistent notation.\\r\\n\\r\\nThe new engine feels much more solid to me, and indeed I've been able\\r\\nto close almost all those open bugs.  Doubtless there will be some\\r\\nnew ones, but I feel vastly more confident that we can fix them\\r\\nthan I did with the old engine.\\r\\n\\r\\nOne other thing is that the new typechecker has completely swept away\\r\\nthe old rather ''ad-hoc'' stuff about \"rigid\" types in GADT pattern matches.  So\\r\\nyou may find that some GADT programs will typecheck with fewer\\r\\ntype annotations than before.  \\r\\n\\r\\nHowever, there is one way in which GHC 7.0 will type ''fewer'' programs\\r\\nthan before, and that is the focus of this post. I want explain what the\\r\\nchange is, and  how to adapt your code to accommodate it.\\r\\n\\r\\n== Local polymorphism ==\\r\\n\\r\\nConsider this (contrived) program:\\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\n\\r\\nf :: forall a. a -> ((a, Char), (a, Bool))\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g :: forall b. b -> (a,b)\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nThis polymorphism is expressed in `g`'s type signature:\\r\\n  * `g` is a ''polymorphic'' function, because it is applied both to the character 'v' and to the boolean `True`.  \\r\\n  * However, `g` is ''monomorphic'' in `a`, because `g`'s body mentions `x`\\r\\nThe type signature `g :: forall b. b -> (a,b)`\\r\\nreflects these two points:\\r\\n  * The \"`forall b`\" says that `g` is polymorphic in `b`.  \\r\\n\\r\\n  * The `a` in the signature must is the `a` in the type of `x`.  This type variable `a` is brought into scope, in the body of `f`, by the `forall a` in the type signature for `f`.\\r\\nThe `LANGUAGE ScopedTypeVariables` pragma (a) allows you to use an\\r\\nexplicit \"`forall`\" in the type signature for a function `f`, and (b)\\r\\nbrings the `forall`'d type variables (`a` in this case) into scope in the body of the\\r\\nfunction `f`.\\r\\n\\r\\n== What has changed in GHC 7.0? == \\r\\n\\r\\nGHC 6.12 will compile the above program without any type signatures at all.\\r\\nIt infers the polymorphic type for `g`.  But, if you are using\\r\\ntype families or GADTs, GHC 7.0 will not.  More precisely:\\r\\n * The flags `-XGADTs` or `-XTypeFamilies`, or the corresponding `LANGUAGE` pragmas,\\r\\n   imply the (new) flag `-XMonoLocalBinds`.  \\r\\n\\r\\n * With `-XMonoLocalBinds`, non-top-level (or ''local'') let/where \\r\\n   bindings are not generalised.\\r\\n\\r\\n * Remember that `-fglasgow-exts` implies `-XGADTs` and hence `-XTypeFamilies`.\\r\\n\\r\\nSo given the type-signature-free code\\r\\n{{{\\r\\n{-# LANGUAGE MonoLocalBinds #-}\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nGHC 7.0 will reject the program with\\r\\n{{{\\r\\nFoo.hs:6:17:\\r\\n    Couldn't match expected type `Char' with actual type `Bool'\\r\\n    In the first argument of `g', namely `True'\\r\\n    In the expression: g True\\r\\n    In the expression: (g 'v', g True)\\r\\n}}}\\r\\nWhy?  Because the type of `g` is not generalised, so it\\r\\ncan only be applied to either `Char` or `Bool` but not both.\\r\\n\\r\\n== How can I fix my program? ==\\r\\n\\r\\nAlmost all code doesn't need local let definitions to have\\r\\na polymorphic type, because the function is only used at one type.\\r\\nBut not all.  There are two ways to fix your program if it falls\\r\\nover because of the `MonoLocalBinds` change.\\r\\n\\r\\n * Check whether you need `-XGADTs` or `-XTypeFamilies`.  If you are using the blunderbuss `-fglasgow-exts`, replace it with proper `LANGUAGE` pragmas.\\r\\n\\r\\n * The good way is simply give a type signature to the local definition, as I did for `g` above.  Writing such a type signature may force you to use `{-# LANGUAGE ScopedTypeVariables #-}` as the above example showed.  My experience is that the code is easier to understand with the type signature.\\r\\n\\r\\n * The `-XGADTs` or `-XTypeFamilies` pragmas switch on `MonoLocalBinds` but, if you want, you can override it with `-XNoMonoLocalBinds` (or the equivalent `LANGUAGE` pragma).  The type checker will then do its best to generalise local bindings, and your program will almost certainly work.  However, I don't know how to guarantee any good properties of the type inference algorithm.  So I think this is ok as as short term fix, but I'd like to encourage you to add that handful of type signatures instead.\\r\\n\\r\\nYou may not be very familiar with the code,\\r\\nso it can be tricky to work out what type the local definition should have.\\r\\n(That's one reason I think that the code is improved by having a type signature!)\\r\\nWith this in mind I've added a new warning flag `-fwarn-missing-local-sigs`, which\\r\\nprints a warning, and the type, of any ''polymorphic'' local binding that\\r\\nlacks a type signature. So you can follow this procedure:\\r\\n * Compile with `-XNoMonoLocalBinds -fwarn-missing-local-sigs`. The first flag makes it compile, and the second shows you the types.\\r\\n * Compile with neither flag, getting some errors.\\r\\n * Add type signatures to cure the errors, using the types printed out in the first step.\\r\\n\\r\\nAdding the type signature is completely compatible with GHC 6.12 etc, so you shouldn't need any conditional compilation if you want to compile your code with multiple versions of GHC.\\r\\n\\r\\n== A second, bigger example == \\r\\n\\r\\nOne relatively common situation in which you need a local type signature\\r\\nis when you use `runST` with some auxiliary definitions.  \\r\\nHere is a typical example: \\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\nmodule Test where\\r\\nimport Control.Monad.ST\\r\\nimport Data.STRef\\r\\n\\r\\nfoo :: forall a. Bool -> a -> a -> a\\r\\nfoo b x y = runST (do { r <- newSTRef x; fill r; readSTRef r })\\r\\n          where\\r\\n            -- fill :: forall s. STRef s a -> ST s ()\\r\\n            fill r = case b of\\r\\n                       True  -> return ()\\r\\n                       False -> writeSTRef r y\\r\\n\\r\\n-- runST :: forall a. (forall s. ST s a) -> a\\r\\n-- newSTRef   :: a -> ST s (STRef s a)\\r\\n-- readSTRef  :: STRef s a -> ST s a\\r\\n-- writeSTRef :: STRef s a -> a -> ST s ()\\r\\n}}}\\r\\nThe function `foo` is a bit contrived, but it's typical of the way\\r\\nin which `runST` is often used.  We allocate a reference cell, containing `x`,\\r\\ncall `fill`, and then read out what is now in the reference cell.  \\r\\nAll `fill` does is overwrite the cell if `b` is `False`.\\r\\nSo `foo` is really an elaborate `if` function.\\r\\n\\r\\nBut in GHC 7.0, with `-XMonoLocalBinds` (or `-XGADTs`, `-XTypeFamilies`),\\r\\nthe program will be rejected with this alarming-seeming error message\\r\\n{{{\\r\\nFoo.hs:7:11:\\r\\n    Couldn't match type `s' with `s1'\\r\\n      because this skolem type variable would escape: `s1'\\r\\n    This skolem is bound by the polymorphic type `forall s. ST s a'\\r\\n    The following variables have types that mention s\\r\\n      fill :: STRef s a -> ST s () (bound at Foo.hs:10:11)\\r\\n    In the first argument of `runST', namely\\r\\n      `(do { r <- newSTRef x; fill r; readSTRef r })'\\r\\n}}}\\r\\nRemember, `fill` has not been generalised, so it gets a monomorphic type.\\r\\nThat in turn means that the argument to `runST` is not polymorphic enough.\\r\\n\\r\\nDespite its scariness, in some ways the error message identifies\\r\\nthe problem more clearly than the previous example. In particular, the error\\r\\nmessage identifies `fill` as the culprit.  \\r\\nYou can fix it the same way as before, by adding a signature for `fill`;\\r\\nI've put it in a comment above.\\r\\n\\r\\n== Why make this change? ==\\r\\n\\r\\nAt first this change seems like retrograde step, so why did we make\\r\\nit?  It's a long story, but the short summary is this: I don't know\\r\\nhow to build a reliable, predictable type inference engine for a type\\r\\nsystem that has both (a) generalisation of local let/where and (b) local\\r\\ntype equality assumptions, such as those introduced by GADTs.  The story is told\\r\\nin our paper \"[http://research.microsoft.com/en-us/um/people/simonpj/papers/constraints/index.htm Let should not be generalised]\" and, at greater length, in \\r\\nthe journal version \"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\".\\r\\n\\r\\n","publish_time":1285811634,"version_time":1285812562,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":1,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices'''. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y\\r\\n   $(th2 10)\\r\\n   w z = z\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows:\\r\\n\\r\\n * The type environment seen by `reify` is the top-level environment in force just before the preceding top-level splice.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041 I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287438906,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":2,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y\\r\\n   $(th2 10)\\r\\n   w z = z\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows:\\r\\n\\r\\n * The type environment seen by `reify` is the top-level environment in force just before the preceding top-level splice.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041 I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287524548,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":3,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y\\r\\n   $(th2 10)\\r\\n   w z = z\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows:\\r\\n\\r\\n * The type environment seen by `reify` is the top-level environment in force just before the preceding top-level splice.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287524585,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":4,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287525337,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":5,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287994802,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":6,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n","publish_time":1287438906,"version_time":1287996400,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":7,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n","publish_time":1287438906,"version_time":1287997178,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"stack-chunks","version":1,"title":"An overhaul of stack management, and some performance improvements","body":"I just [http://www.haskell.org/pipermail/cvs-ghc/2010-December/058307.html committed a patch] I've been working on for a few days that\\r\\nrevamps the way thread stacks are managed in the runtime system.\\r\\nThere'll be some nice performance improvements coming in 7.2.1 as a\\r\\nresult of this.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nIn GHC 7.0 and earlier, a thread is represented by a TSO object in the\\r\\nheap.  The TSO contains:\\r\\n\\r\\n  * some thread-specific state and flags\\r\\n  * a couple of link fields for linking the TSO onto lists\\r\\n  * the stack, growing backwards from the end of the TSO\\r\\n\\r\\nwhen the stack overflows, as long as the maximum stack size (+RTS\\r\\n-K<size>) has not yet been reached, then the runtime system would\\r\\ncreate a new TSO double the size of the old one, copy the stack and\\r\\nthe thread state into the new object, and mark the old TSO as a\\r\\n`ThreadRelocated` pointing to the new one.  This last step is\\r\\nimportant, because the TSO might be reachable from other places: a\\r\\n`ThreadId` is basically a pointer to the TSO, for instance.\\r\\n\\r\\nThis `ThreadRelocated` thing is a nuisance, because it means every\\r\\ntime we derefernce a TSO pointer, we have to check for\\r\\n`ThreadRelocated` in a little loop.  This loop was enshrined in a\\r\\nfunction `deRefTSO()` in the RTS, and was called from various places.\\r\\nOver the years we've had several bugs caused by a missing `deRefTSO`.\\r\\n\\r\\n== Overheads of the old way ==\\r\\n\\r\\nObviously there's a certain amount of overhead associated with copying\\r\\nthe whole stack every time we need to enlarge the TSO: every stack\\r\\nword is written approximately twice.  What's worse, though, is that\\r\\nthe entire stack is traversed during every GC, if the thread is active\\r\\n(threads that haven't run since the last GC are marked \"clean\" and not\\r\\ntraversed).  If the thread has a deep stack, this makes minor GCs\\r\\nexpensive, which shows up as a high GC overhead.  A common workaround\\r\\nis to use a larger allocation area, e.g. `+RTS -A4m`, but that has the\\r\\ndisadvantage of making the allocation area larger than the L2 cache,\\r\\nwhich also hurts performance.\\r\\n\\r\\n== A better way: stack chunks ==\\r\\n\\r\\nThe solution to the repeated traversal problem is to identify the\\r\\nparts of the stack that are unmodified since the last GC, and not\\r\\ntraverse them.  The GC already does a lot of this kind of thing - it's\\r\\ncalled a \"write barrier\", and it's a basic requirement for\\r\\ngenerational GC.\\r\\n\\r\\nThere are two ways we could do this: either do a card-marking trick\\r\\nlike we do for mutable arrays, or we could divide the stack up into\\r\\nmultiple objects and mark each object as either clean or dirty.  The\\r\\ncard-marking option would have been fairly complicated to administer,\\r\\nso we discarded that idea.  In contrast, having multiple objects\\r\\ncontaining parts of the stack was relatively straightforward.\\r\\n\\r\\nPerhaps we should have done this ages ago.  I put it off because I\\r\\nthought it would be complex - we have lots of places in the RTS that\\r\\ntraverse stacks.  It turns out that the majority of these places don't\\r\\ncare about stack chunks, which is nice.\\r\\n\\r\\n== Death to `ThreadRelocated` ==\\r\\n\\r\\nThe obvious solution to the `ThreadRelocated` problem is to separate\\r\\nthe stack from the TSO, and that's exactly what we've done.  Now the\\r\\nTSO contains the thread state only, and it points to a separate STACK\\r\\nobject for the topmost stack chunk, containing the stack pointer and the stack itself.  The result is that a fragile invariant goes away, which is a very good thing.\\r\\n\\r\\nWhy didn't we do this before?  Well, in fact I did try making this\\r\\nchange a long time ago, and found that it made performance worse for\\r\\nsome thread benchmarks.  I put it down to the extra cache-line fill\\r\\nrequired to access the stack pointer in the separate STACK object.  However,\\r\\nthis time the results look pretty good - I'm not entirely sure why,\\r\\nmaybe it's the combination of doing this with stack chunks, or maybe I\\r\\ndid something wrong last time, who knows (or cares!).\\r\\n\\r\\n== Performance ==\\r\\n\\r\\nHere are some performance figures from a small collection of thread\\r\\nbenchmarks ([http://darcs.haskell.org/nofib/smp]).  This is comparing\\r\\nyesterday's HEAD with my working branch:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed\\r\\n--------------------------------------------------------------------------------\\r\\n    callback001        +289.3%    -13.5%     +0.8%     +1.2%\\r\\n    callback002        +302.0%    -13.5%     -1.3%     -1.3%\\r\\n          sieve        +329.2%     -0.2%     -1.6%     -1.3%\\r\\n     threads001        +292.4%     +0.0%     +4.2%     +4.5%\\r\\n     threads003        +298.9%     -0.5%    -36.5%    -36.4%\\r\\n     threads006        +304.1%     -2.2%    -66.4%    -66.4%\\r\\n     threads007        +409.7%     +0.0%     +2.4%     +2.5%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +289.3%    -13.5%    -66.4%    -66.4%\\r\\n            Max        +409.7%     +0.0%     +4.2%     +4.5%\\r\\n Geometric Mean        +316.3%     -4.5%    -19.3%    -19.2%\\r\\n}}}\\r\\n\\r\\nIgnore the size figures, it's because the HEAD build was using\\r\\n`-split-objs`.\\r\\n\\r\\nWe can see that several benchmarks display no difference or get very\\r\\nslightly worse, but a couple (threads003 and threads006) see a big\\r\\njump in performance.  threads003 is an old variant on threadring, and\\r\\nthreads006 is a microbenchmark for throwTo.  I don't fully understand\\r\\nthe difference in performance here, but typically I don't investigate\\r\\nwhen things go faster, only when they go slower.\\r\\n\\r\\nGHC itself got a little faster: 1-2% when compiling Cabal.\\r\\n\\r\\nBut what you really wanted to know was... what about threadring,\\r\\nright?  Well, it currently goes a few percent slower with the new\\r\\nchanges.  However, I notice that it's allocating a lot more than\\r\\nbefore, so I think there's something suspicious going on.  I shall\\r\\ninvestigate...\\r\\n","publish_time":1292430562,"version_time":1292430562,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"stack-chunks","version":2,"title":"An overhaul of stack management, and some performance improvements","body":"I just [http://www.haskell.org/pipermail/cvs-ghc/2010-December/058307.html committed a patch] I've been working on for a few days that\\r\\nrevamps the way thread stacks are managed in the runtime system.\\r\\nThere'll be some nice performance improvements coming in 7.2.1 as a\\r\\nresult of this.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nIn GHC 7.0 and earlier, a thread is represented by a TSO object in the\\r\\nheap.  The TSO contains:\\r\\n\\r\\n  * some thread-specific state and flags\\r\\n  * a couple of link fields for linking the TSO onto lists\\r\\n  * the stack, growing backwards from the end of the TSO\\r\\n\\r\\nwhen the stack overflows, as long as the maximum stack size (+RTS\\r\\n-K<size>) has not yet been reached, then the runtime system would\\r\\ncreate a new TSO double the size of the old one, copy the stack and\\r\\nthe thread state into the new object, and mark the old TSO as a\\r\\n`ThreadRelocated` pointing to the new one.  This last step is\\r\\nimportant, because the TSO might be reachable from other places: a\\r\\n`ThreadId` is basically a pointer to the TSO, for instance.\\r\\n\\r\\nThis `ThreadRelocated` thing is a nuisance, because it means every\\r\\ntime we derefernce a TSO pointer, we have to check for\\r\\n`ThreadRelocated` in a little loop.  This loop was enshrined in a\\r\\nfunction `deRefTSO()` in the RTS, and was called from various places.\\r\\nOver the years we've had several bugs caused by a missing `deRefTSO`.\\r\\n\\r\\n== Overheads of the old way ==\\r\\n\\r\\nObviously there's a certain amount of overhead associated with copying\\r\\nthe whole stack every time we need to enlarge the TSO: every stack\\r\\nword is written approximately twice.  What's worse, though, is that\\r\\nthe entire stack is traversed during every GC, if the thread is active\\r\\n(threads that haven't run since the last GC are marked \"clean\" and not\\r\\ntraversed).  If the thread has a deep stack, this makes minor GCs\\r\\nexpensive, which shows up as a high GC overhead.  A common workaround\\r\\nis to use a larger allocation area, e.g. `+RTS -A4m`, but that has the\\r\\ndisadvantage of making the allocation area larger than the L2 cache,\\r\\nwhich also hurts performance.\\r\\n\\r\\n== A better way: stack chunks ==\\r\\n\\r\\nThe solution to the repeated traversal problem is to identify the\\r\\nparts of the stack that are unmodified since the last GC, and not\\r\\ntraverse them.  The GC already does a lot of this kind of thing - it's\\r\\ncalled a \"write barrier\", and it's a basic requirement for\\r\\ngenerational GC.\\r\\n\\r\\nThere are two ways we could do this: either do a card-marking trick\\r\\nlike we do for mutable arrays, or we could divide the stack up into\\r\\nmultiple objects and mark each object as either clean or dirty.  The\\r\\ncard-marking option would have been fairly complicated to administer,\\r\\nso we discarded that idea.  In contrast, having multiple objects\\r\\ncontaining parts of the stack was relatively straightforward.\\r\\n\\r\\nPerhaps we should have done this ages ago.  I put it off because I\\r\\nthought it would be complex - we have lots of places in the RTS that\\r\\ntraverse stacks.  It turns out that the majority of these places don't\\r\\ncare about stack chunks, which is nice.\\r\\n\\r\\n== Death to `ThreadRelocated` ==\\r\\n\\r\\nThe obvious solution to the `ThreadRelocated` problem is to separate\\r\\nthe stack from the TSO, and that's exactly what we've done.  Now the\\r\\nTSO contains the thread state only, and it points to a separate STACK\\r\\nobject for the topmost stack chunk, containing the stack pointer and the stack itself.  The result is that a fragile invariant goes away, which is a very good thing.\\r\\n\\r\\nWhy didn't we do this before?  Well, in fact I did try making this\\r\\nchange a long time ago, and found that it made performance worse for\\r\\nsome thread benchmarks.  I put it down to the extra cache-line fill\\r\\nrequired to access the stack pointer in the separate STACK object.  However,\\r\\nthis time the results look pretty good - I'm not entirely sure why,\\r\\nmaybe it's the combination of doing this with stack chunks, or maybe I\\r\\ndid something wrong last time, who knows (or cares!).\\r\\n\\r\\n== Performance ==\\r\\n\\r\\nHere are some performance figures from a small collection of thread\\r\\nbenchmarks ([http://darcs.haskell.org/nofib/smp]).  This is comparing\\r\\nyesterday's HEAD with my working branch:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed\\r\\n--------------------------------------------------------------------------------\\r\\n    callback001        +289.3%    -13.5%     +0.8%     +1.2%\\r\\n    callback002        +302.0%    -13.5%     -1.3%     -1.3%\\r\\n          sieve        +329.2%     -0.2%     -1.6%     -1.3%\\r\\n     threads001        +292.4%     +0.0%     +4.2%     +4.5%\\r\\n     threads003        +298.9%     -0.5%    -36.5%    -36.4%\\r\\n     threads006        +304.1%     -2.2%    -66.4%    -66.4%\\r\\n     threads007        +409.7%     +0.0%     +2.4%     +2.5%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +289.3%    -13.5%    -66.4%    -66.4%\\r\\n            Max        +409.7%     +0.0%     +4.2%     +4.5%\\r\\n Geometric Mean        +316.3%     -4.5%    -19.3%    -19.2%\\r\\n}}}\\r\\n\\r\\nIgnore the size figures, it's because the HEAD build was using\\r\\n`-split-objs`.\\r\\n\\r\\nWe can see that several benchmarks display no difference or get very\\r\\nslightly worse, but a couple (threads003 and threads006) see a big\\r\\njump in performance.  threads003 is an old variant on threadring, and\\r\\nthreads006 is a microbenchmark for throwTo.  I don't fully understand\\r\\nthe difference in performance here, but typically I don't investigate\\r\\nwhen things go faster, only when they go slower.\\r\\n\\r\\nGHC itself got a little faster: 1-2% when compiling Cabal.\\r\\n\\r\\nBut what you really wanted to know was... what about threadring,\\r\\nright?  Well, it currently goes a few percent slower with the new\\r\\nchanges.  However, I notice that it's allocating a lot more than\\r\\nbefore, so I think there's something suspicious going on.  I shall\\r\\ninvestigate...\\r\\n\\r\\n\\r\\n== Update: some more results ==\\r\\n\\r\\nBinaryTrees, from the shootout:\\r\\n\\r\\n  * before: 64.26s\\r\\n  * after: 17.61s\\r\\n\\r\\nSo I guess the problem with BinaryTrees was more to do with repeated stack traversals than it was to do with a low mortality rate.  Nice that we can get good performance from this program without tweaking the heap settings at all now.\\r\\n\\r\\nHackage benchmarks, from David Peixotto's fibon benchmark suite:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed  TotalMem\\r\\n--------------------------------------------------------------------------------\\r\\n           Agum        +306.5%     +3.5%     +0.8%     +0.9%     +0.0%\\r\\n          Bzlib          -----     -----     -----     -----     -----\\r\\n           Cpsa        +125.1%     +2.1%     -2.2%     -2.3%     +0.0%\\r\\n         Crypto          -----     -----     -----     -----     -----\\r\\n            Fgl        +408.9%     +0.1%     +2.0%     +2.0%     -5.4%\\r\\n            Fst        +137.7%     -0.0%     -4.4%     -4.3%     +0.0%\\r\\n         Funsat        +151.4%     +0.2%     +1.7%     +1.8%     -2.0%\\r\\n             Gf         13990k 13885653k      9.03      9.60   116736k\\r\\n          HaLeX        +195.9%     +0.0%     +1.2%     +1.1%     +0.0%\\r\\n          Happy        +135.0%     +3.3%     -5.3%     -5.4%    -13.7%\\r\\n         Hgalib        +236.7%     +1.0%     +0.7%     +0.7%     +0.0%\\r\\n    Palindromes        +243.1%    -10.1%     +3.4%     +3.4%     +2.1%\\r\\n          Pappy        +148.9%     +0.5%     +3.7%     +3.8%    -17.7%\\r\\n     QuickCheck        +139.5%     -0.1%     -1.6%     -1.6%     +0.0%\\r\\n          Regex        +182.1%     +0.0%     +3.5%     +3.5%    -21.4%\\r\\n          Simgi        +159.3%     +0.0%     +6.9%     +6.9%     +0.0%\\r\\n   TernaryTrees        +519.4%     -2.0%    -32.4%    -32.7%    -14.3%\\r\\n          Xsact        +246.4%     +1.2%     +0.9%     +0.9%     -0.6%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +125.1%    -10.1%    -32.4%    -32.7%    -21.4%\\r\\n            Max        +519.4%     +3.5%     +6.9%     +6.9%     +2.1%\\r\\n Geometric Mean        +207.6%     -0.1%     -1.9%     -1.9%     -5.2%\\r\\n}}}\\r\\n\\r\\nOne or two nice ones in there: TernaryTrees, Happy, Fst all look good. Simgi probably deserves further investigation.\\r\\n\\r\\nNotice how the overall memory size is reducing too, by 5% on average.\\r\\n","publish_time":1292430562,"version_time":1292518605,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"stack-chunks","version":3,"title":"An overhaul of stack management, and some performance improvements","body":"I just [http://www.haskell.org/pipermail/cvs-ghc/2010-December/058307.html committed a patch] I've been working on for a few days that\\r\\nrevamps the way thread stacks are managed in the runtime system.\\r\\nThere'll be some nice performance improvements coming in 7.2.1 as a\\r\\nresult of this.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nIn GHC 7.0 and earlier, a thread is represented by a TSO object in the\\r\\nheap.  The TSO contains:\\r\\n\\r\\n  * some thread-specific state and flags\\r\\n  * a couple of link fields for linking the TSO onto lists\\r\\n  * the stack, growing backwards from the end of the TSO\\r\\n\\r\\nwhen the stack overflows, as long as the maximum stack size (+RTS\\r\\n-K<size>) has not yet been reached, then the runtime system would\\r\\ncreate a new TSO double the size of the old one, copy the stack and\\r\\nthe thread state into the new object, and mark the old TSO as a\\r\\n`ThreadRelocated` pointing to the new one.  This last step is\\r\\nimportant, because the TSO might be reachable from other places: a\\r\\n`ThreadId` is basically a pointer to the TSO, for instance.\\r\\n\\r\\nThis `ThreadRelocated` thing is a nuisance, because it means every\\r\\ntime we derefernce a TSO pointer, we have to check for\\r\\n`ThreadRelocated` in a little loop.  This loop was enshrined in a\\r\\nfunction `deRefTSO()` in the RTS, and was called from various places.\\r\\nOver the years we've had several bugs caused by a missing `deRefTSO`.\\r\\n\\r\\n== Overheads of the old way ==\\r\\n\\r\\nObviously there's a certain amount of overhead associated with copying\\r\\nthe whole stack every time we need to enlarge the TSO: every stack\\r\\nword is written approximately twice.  What's worse, though, is that\\r\\nthe entire stack is traversed during every GC, if the thread is active\\r\\n(threads that haven't run since the last GC are marked \"clean\" and not\\r\\ntraversed).  If the thread has a deep stack, this makes minor GCs\\r\\nexpensive, which shows up as a high GC overhead.  A common workaround\\r\\nis to use a larger allocation area, e.g. `+RTS -A4m`, but that has the\\r\\ndisadvantage of making the allocation area larger than the L2 cache,\\r\\nwhich also hurts performance.\\r\\n\\r\\n== A better way: stack chunks ==\\r\\n\\r\\nThe solution to the repeated traversal problem is to identify the\\r\\nparts of the stack that are unmodified since the last GC, and not\\r\\ntraverse them.  The GC already does a lot of this kind of thing - it's\\r\\ncalled a \"write barrier\", and it's a basic requirement for\\r\\ngenerational GC.\\r\\n\\r\\nThere are two ways we could do this: either do a card-marking trick\\r\\nlike we do for mutable arrays, or we could divide the stack up into\\r\\nmultiple objects and mark each object as either clean or dirty.  The\\r\\ncard-marking option would have been fairly complicated to administer,\\r\\nso we discarded that idea.  In contrast, having multiple objects\\r\\ncontaining parts of the stack was relatively straightforward.\\r\\n\\r\\nPerhaps we should have done this ages ago.  I put it off because I\\r\\nthought it would be complex - we have lots of places in the RTS that\\r\\ntraverse stacks.  It turns out that the majority of these places don't\\r\\ncare about stack chunks, which is nice.\\r\\n\\r\\n== Death to `ThreadRelocated` ==\\r\\n\\r\\nThe obvious solution to the `ThreadRelocated` problem is to separate\\r\\nthe stack from the TSO, and that's exactly what we've done.  Now the\\r\\nTSO contains the thread state only, and it points to a separate STACK\\r\\nobject for the topmost stack chunk, containing the stack pointer and the stack itself.  The result is that a fragile invariant goes away, which is a very good thing.\\r\\n\\r\\nWhy didn't we do this before?  Well, in fact I did try making this\\r\\nchange a long time ago, and found that it made performance worse for\\r\\nsome thread benchmarks.  I put it down to the extra cache-line fill\\r\\nrequired to access the stack pointer in the separate STACK object.  However,\\r\\nthis time the results look pretty good - I'm not entirely sure why,\\r\\nmaybe it's the combination of doing this with stack chunks, or maybe I\\r\\ndid something wrong last time, who knows (or cares!).\\r\\n\\r\\n== Performance ==\\r\\n\\r\\nHere are some performance figures from a small collection of thread\\r\\nbenchmarks ([http://darcs.haskell.org/nofib/smp]).  This is comparing\\r\\nyesterday's HEAD with my working branch:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed\\r\\n--------------------------------------------------------------------------------\\r\\n    callback001        +289.3%    -13.5%     +0.8%     +1.2%\\r\\n    callback002        +302.0%    -13.5%     -1.3%     -1.3%\\r\\n          sieve        +329.2%     -0.2%     -1.6%     -1.3%\\r\\n     threads001        +292.4%     +0.0%     +4.2%     +4.5%\\r\\n     threads003        +298.9%     -0.5%    -36.5%    -36.4%\\r\\n     threads006        +304.1%     -2.2%    -66.4%    -66.4%\\r\\n     threads007        +409.7%     +0.0%     +2.4%     +2.5%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +289.3%    -13.5%    -66.4%    -66.4%\\r\\n            Max        +409.7%     +0.0%     +4.2%     +4.5%\\r\\n Geometric Mean        +316.3%     -4.5%    -19.3%    -19.2%\\r\\n}}}\\r\\n\\r\\nIgnore the size figures, it's because the HEAD build was using\\r\\n`-split-objs`.\\r\\n\\r\\nWe can see that several benchmarks display no difference or get very\\r\\nslightly worse, but a couple (threads003 and threads006) see a big\\r\\njump in performance.  threads003 is an old variant on threadring, and\\r\\nthreads006 is a microbenchmark for throwTo.  I don't fully understand\\r\\nthe difference in performance here, but typically I don't investigate\\r\\nwhen things go faster, only when they go slower.\\r\\n\\r\\nGHC itself got a little faster: 1-2% when compiling Cabal.\\r\\n\\r\\nBut what you really wanted to know was... what about threadring,\\r\\nright?  Well, it currently goes a few percent slower with the new\\r\\nchanges.  However, I notice that it's allocating a lot more than\\r\\nbefore, so I think there's something suspicious going on.  I shall\\r\\ninvestigate...\\r\\n\\r\\n\\r\\n== Update: some more results ==\\r\\n\\r\\n!BinaryTrees, from the shootout:\\r\\n\\r\\n  * before: 64.26s\\r\\n  * after: 17.61s\\r\\n\\r\\nSo I guess the problem with !BinaryTrees was more to do with repeated stack traversals than it was to do with a low mortality rate.  Nice that we can get good performance from this program without tweaking the heap settings at all now.\\r\\n\\r\\nHackage benchmarks, from David Peixotto's fibon benchmark suite:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed  TotalMem\\r\\n--------------------------------------------------------------------------------\\r\\n           Agum        +306.5%     +3.5%     +0.8%     +0.9%     +0.0%\\r\\n          Bzlib          -----     -----     -----     -----     -----\\r\\n           Cpsa        +125.1%     +2.1%     -2.2%     -2.3%     +0.0%\\r\\n         Crypto          -----     -----     -----     -----     -----\\r\\n            Fgl        +408.9%     +0.1%     +2.0%     +2.0%     -5.4%\\r\\n            Fst        +137.7%     -0.0%     -4.4%     -4.3%     +0.0%\\r\\n         Funsat        +151.4%     +0.2%     +1.7%     +1.8%     -2.0%\\r\\n             Gf         13990k 13885653k      9.03      9.60   116736k\\r\\n          HaLeX        +195.9%     +0.0%     +1.2%     +1.1%     +0.0%\\r\\n          Happy        +135.0%     +3.3%     -5.3%     -5.4%    -13.7%\\r\\n         Hgalib        +236.7%     +1.0%     +0.7%     +0.7%     +0.0%\\r\\n    Palindromes        +243.1%    -10.1%     +3.4%     +3.4%     +2.1%\\r\\n          Pappy        +148.9%     +0.5%     +3.7%     +3.8%    -17.7%\\r\\n     QuickCheck        +139.5%     -0.1%     -1.6%     -1.6%     +0.0%\\r\\n          Regex        +182.1%     +0.0%     +3.5%     +3.5%    -21.4%\\r\\n          Simgi        +159.3%     +0.0%     +6.9%     +6.9%     +0.0%\\r\\n   TernaryTrees        +519.4%     -2.0%    -32.4%    -32.7%    -14.3%\\r\\n          Xsact        +246.4%     +1.2%     +0.9%     +0.9%     -0.6%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +125.1%    -10.1%    -32.4%    -32.7%    -21.4%\\r\\n            Max        +519.4%     +3.5%     +6.9%     +6.9%     +2.1%\\r\\n Geometric Mean        +207.6%     -0.1%     -1.9%     -1.9%     -5.2%\\r\\n}}}\\r\\n\\r\\nOne or two nice ones in there: TernaryTrees, Happy, Fst all look good. Simgi probably deserves further investigation.\\r\\n\\r\\nNotice how the overall memory size is reducing too, by 5% on average.\\r\\n","publish_time":1292430562,"version_time":1292518623,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"stack-chunks","version":4,"title":"An overhaul of stack management, and some performance improvements","body":"I just [http://www.haskell.org/pipermail/cvs-ghc/2010-December/058307.html committed a patch] I've been working on for a few days that\\r\\nrevamps the way thread stacks are managed in the runtime system.\\r\\nThere'll be some nice performance improvements coming in 7.2.1 as a\\r\\nresult of this.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nIn GHC 7.0 and earlier, a thread is represented by a TSO object in the\\r\\nheap.  The TSO contains:\\r\\n\\r\\n  * some thread-specific state and flags\\r\\n  * a couple of link fields for linking the TSO onto lists\\r\\n  * the stack, growing backwards from the end of the TSO\\r\\n\\r\\nwhen the stack overflows, as long as the maximum stack size (+RTS\\r\\n-K<size>) has not yet been reached, then the runtime system would\\r\\ncreate a new TSO double the size of the old one, copy the stack and\\r\\nthe thread state into the new object, and mark the old TSO as a\\r\\n`ThreadRelocated` pointing to the new one.  This last step is\\r\\nimportant, because the TSO might be reachable from other places: a\\r\\n`ThreadId` is basically a pointer to the TSO, for instance.\\r\\n\\r\\nThis `ThreadRelocated` thing is a nuisance, because it means every\\r\\ntime we derefernce a TSO pointer, we have to check for\\r\\n`ThreadRelocated` in a little loop.  This loop was enshrined in a\\r\\nfunction `deRefTSO()` in the RTS, and was called from various places.\\r\\nOver the years we've had several bugs caused by a missing `deRefTSO`.\\r\\n\\r\\n== Overheads of the old way ==\\r\\n\\r\\nObviously there's a certain amount of overhead associated with copying\\r\\nthe whole stack every time we need to enlarge the TSO: every stack\\r\\nword is written approximately twice.  What's worse, though, is that\\r\\nthe entire stack is traversed during every GC, if the thread is active\\r\\n(threads that haven't run since the last GC are marked \"clean\" and not\\r\\ntraversed).  If the thread has a deep stack, this makes minor GCs\\r\\nexpensive, which shows up as a high GC overhead.  A common workaround\\r\\nis to use a larger allocation area, e.g. `+RTS -A4m`, but that has the\\r\\ndisadvantage of making the allocation area larger than the L2 cache,\\r\\nwhich also hurts performance.\\r\\n\\r\\n== A better way: stack chunks ==\\r\\n\\r\\nThe solution to the repeated traversal problem is to identify the\\r\\nparts of the stack that are unmodified since the last GC, and not\\r\\ntraverse them.  The GC already does a lot of this kind of thing - it's\\r\\ncalled a \"write barrier\", and it's a basic requirement for\\r\\ngenerational GC.\\r\\n\\r\\nThere are two ways we could do this: either do a card-marking trick\\r\\nlike we do for mutable arrays, or we could divide the stack up into\\r\\nmultiple objects and mark each object as either clean or dirty.  The\\r\\ncard-marking option would have been fairly complicated to administer,\\r\\nso we discarded that idea.  In contrast, having multiple objects\\r\\ncontaining parts of the stack was relatively straightforward.\\r\\n\\r\\nPerhaps we should have done this ages ago.  I put it off because I\\r\\nthought it would be complex - we have lots of places in the RTS that\\r\\ntraverse stacks.  It turns out that the majority of these places don't\\r\\ncare about stack chunks, which is nice.\\r\\n\\r\\n== Death to `ThreadRelocated` ==\\r\\n\\r\\nThe obvious solution to the `ThreadRelocated` problem is to separate\\r\\nthe stack from the TSO, and that's exactly what we've done.  Now the\\r\\nTSO contains the thread state only, and it points to a separate STACK\\r\\nobject for the topmost stack chunk, containing the stack pointer and the stack itself.  The result is that a fragile invariant goes away, which is a very good thing.\\r\\n\\r\\nWhy didn't we do this before?  Well, in fact I did try making this\\r\\nchange a long time ago, and found that it made performance worse for\\r\\nsome thread benchmarks.  I put it down to the extra cache-line fill\\r\\nrequired to access the stack pointer in the separate STACK object.  However,\\r\\nthis time the results look pretty good - I'm not entirely sure why,\\r\\nmaybe it's the combination of doing this with stack chunks, or maybe I\\r\\ndid something wrong last time, who knows (or cares!).\\r\\n\\r\\n== Performance ==\\r\\n\\r\\nHere are some performance figures from a small collection of thread\\r\\nbenchmarks ([http://darcs.haskell.org/nofib/smp]).  This is comparing\\r\\nyesterday's HEAD with my working branch:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed\\r\\n--------------------------------------------------------------------------------\\r\\n    callback001        +289.3%    -13.5%     +0.8%     +1.2%\\r\\n    callback002        +302.0%    -13.5%     -1.3%     -1.3%\\r\\n          sieve        +329.2%     -0.2%     -1.6%     -1.3%\\r\\n     threads001        +292.4%     +0.0%     +4.2%     +4.5%\\r\\n     threads003        +298.9%     -0.5%    -36.5%    -36.4%\\r\\n     threads006        +304.1%     -2.2%    -66.4%    -66.4%\\r\\n     threads007        +409.7%     +0.0%     +2.4%     +2.5%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +289.3%    -13.5%    -66.4%    -66.4%\\r\\n            Max        +409.7%     +0.0%     +4.2%     +4.5%\\r\\n Geometric Mean        +316.3%     -4.5%    -19.3%    -19.2%\\r\\n}}}\\r\\n\\r\\nIgnore the size figures, it's because the HEAD build was using\\r\\n`-split-objs`.\\r\\n\\r\\nWe can see that several benchmarks display no difference or get very\\r\\nslightly worse, but a couple (threads003 and threads006) see a big\\r\\njump in performance.  threads003 is an old variant on threadring, and\\r\\nthreads006 is a microbenchmark for throwTo.  I don't fully understand\\r\\nthe difference in performance here, but typically I don't investigate\\r\\nwhen things go faster, only when they go slower.\\r\\n\\r\\nGHC itself got a little faster: 1-2% when compiling Cabal.\\r\\n\\r\\nBut what you really wanted to know was... what about threadring,\\r\\nright?  Well, it currently goes a few percent slower with the new\\r\\nchanges.  However, I notice that it's allocating a lot more than\\r\\nbefore, so I think there's something suspicious going on.  I shall\\r\\ninvestigate...\\r\\n\\r\\n\\r\\n== Update: some more results ==\\r\\n\\r\\n!BinaryTrees, from the shootout:\\r\\n\\r\\n  * before: 64.26s\\r\\n  * after: 17.61s\\r\\n\\r\\nSo I guess the problem with !BinaryTrees was more to do with repeated stack traversals than it was to do with a low mortality rate.  Nice that we can get good performance from this program without tweaking the heap settings at all now.\\r\\n\\r\\nHackage benchmarks, from David Peixotto's fibon benchmark suite:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed  TotalMem\\r\\n--------------------------------------------------------------------------------\\r\\n           Agum        +306.5%     +3.5%     +0.8%     +0.9%     +0.0%\\r\\n          Bzlib          -----     -----     -----     -----     -----\\r\\n           Cpsa        +125.1%     +2.1%     -2.2%     -2.3%     +0.0%\\r\\n         Crypto          -----     -----     -----     -----     -----\\r\\n            Fgl        +408.9%     +0.1%     +2.0%     +2.0%     -5.4%\\r\\n            Fst        +137.7%     -0.0%     -4.4%     -4.3%     +0.0%\\r\\n         Funsat        +151.4%     +0.2%     +1.7%     +1.8%     -2.0%\\r\\n             Gf         13990k 13885653k      9.03      9.60   116736k\\r\\n          HaLeX        +195.9%     +0.0%     +1.2%     +1.1%     +0.0%\\r\\n          Happy        +135.0%     +3.3%     -5.3%     -5.4%    -13.7%\\r\\n         Hgalib        +236.7%     +1.0%     +0.7%     +0.7%     +0.0%\\r\\n    Palindromes        +243.1%    -10.1%     +3.4%     +3.4%     +2.1%\\r\\n          Pappy        +148.9%     +0.5%     +3.7%     +3.8%    -17.7%\\r\\n     QuickCheck        +139.5%     -0.1%     -1.6%     -1.6%     +0.0%\\r\\n          Regex        +182.1%     +0.0%     +3.5%     +3.5%    -21.4%\\r\\n          Simgi        +159.3%     +0.0%     +6.9%     +6.9%     +0.0%\\r\\n   TernaryTrees        +519.4%     -2.0%    -32.4%    -32.7%    -14.3%\\r\\n          Xsact        +246.4%     +1.2%     +0.9%     +0.9%     -0.6%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +125.1%    -10.1%    -32.4%    -32.7%    -21.4%\\r\\n            Max        +519.4%     +3.5%     +6.9%     +6.9%     +2.1%\\r\\n Geometric Mean        +207.6%     -0.1%     -1.9%     -1.9%     -5.2%\\r\\n}}}\\r\\n\\r\\nOne or two nice ones in there: !TernaryTrees, Happy, Fst all look good. Simgi probably deserves further investigation.\\r\\n\\r\\nNotice how the overall memory size is reducing too, by 5% on average.\\r\\n","publish_time":1292430562,"version_time":1292518637,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"stack-chunks","version":5,"title":"An overhaul of stack management, and some performance improvements","body":"I just [http://www.haskell.org/pipermail/cvs-ghc/2010-December/058307.html committed a patch] I've been working on for a few days that\\r\\nrevamps the way thread stacks are managed in the runtime system.\\r\\nThere'll be some nice performance improvements coming in 7.2.1 as a\\r\\nresult of this.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nIn GHC 7.0 and earlier, a thread is represented by a TSO object in the\\r\\nheap.  The TSO contains:\\r\\n\\r\\n  * some thread-specific state and flags\\r\\n  * a couple of link fields for linking the TSO onto lists\\r\\n  * the stack, growing backwards from the end of the TSO\\r\\n\\r\\nwhen the stack overflows, as long as the maximum stack size (+RTS\\r\\n-K<size>) has not yet been reached, then the runtime system would\\r\\ncreate a new TSO double the size of the old one, copy the stack and\\r\\nthe thread state into the new object, and mark the old TSO as a\\r\\n`ThreadRelocated` pointing to the new one.  This last step is\\r\\nimportant, because the TSO might be reachable from other places: a\\r\\n`ThreadId` is basically a pointer to the TSO, for instance.\\r\\n\\r\\nThis `ThreadRelocated` thing is a nuisance, because it means every\\r\\ntime we derefernce a TSO pointer, we have to check for\\r\\n`ThreadRelocated` in a little loop.  This loop was enshrined in a\\r\\nfunction `deRefTSO()` in the RTS, and was called from various places.\\r\\nOver the years we've had several bugs caused by a missing `deRefTSO`.\\r\\n\\r\\n== Overheads of the old way ==\\r\\n\\r\\nObviously there's a certain amount of overhead associated with copying\\r\\nthe whole stack every time we need to enlarge the TSO: every stack\\r\\nword is written approximately twice.  What's worse, though, is that\\r\\nthe entire stack is traversed during every GC, if the thread is active\\r\\n(threads that haven't run since the last GC are marked \"clean\" and not\\r\\ntraversed).  If the thread has a deep stack, this makes minor GCs\\r\\nexpensive, which shows up as a high GC overhead.  A common workaround\\r\\nis to use a larger allocation area, e.g. `+RTS -A4m`, but that has the\\r\\ndisadvantage of making the allocation area larger than the L2 cache,\\r\\nwhich also hurts performance.\\r\\n\\r\\n== A better way: stack chunks ==\\r\\n\\r\\nThe solution to the repeated traversal problem is to identify the\\r\\nparts of the stack that are unmodified since the last GC, and not\\r\\ntraverse them.  The GC already does a lot of this kind of thing - it's\\r\\ncalled a \"write barrier\", and it's a basic requirement for\\r\\ngenerational GC.\\r\\n\\r\\nThere are two ways we could do this: either do a card-marking trick\\r\\nlike we do for mutable arrays, or we could divide the stack up into\\r\\nmultiple objects and mark each object as either clean or dirty.  The\\r\\ncard-marking option would have been fairly complicated to administer,\\r\\nso we discarded that idea.  In contrast, having multiple objects\\r\\ncontaining parts of the stack was relatively straightforward.\\r\\n\\r\\nPerhaps we should have done this ages ago.  I put it off because I\\r\\nthought it would be complex - we have lots of places in the RTS that\\r\\ntraverse stacks.  It turns out that the majority of these places don't\\r\\ncare about stack chunks, which is nice.\\r\\n\\r\\n== Death to `ThreadRelocated` ==\\r\\n\\r\\nThe obvious solution to the `ThreadRelocated` problem is to separate\\r\\nthe stack from the TSO, and that's exactly what we've done.  Now the\\r\\nTSO contains the thread state only, and it points to a separate STACK\\r\\nobject for the topmost stack chunk, containing the stack pointer and the stack itself.  The result is that a fragile invariant goes away, which is a very good thing.\\r\\n\\r\\nWhy didn't we do this before?  Well, in fact I did try making this\\r\\nchange a long time ago, and found that it made performance worse for\\r\\nsome thread benchmarks.  I put it down to the extra cache-line fill\\r\\nrequired to access the stack pointer in the separate STACK object.  However,\\r\\nthis time the results look pretty good - I'm not entirely sure why,\\r\\nmaybe it's the combination of doing this with stack chunks, or maybe I\\r\\ndid something wrong last time, who knows (or cares!).\\r\\n\\r\\n== Performance ==\\r\\n\\r\\nHere are some performance figures from a small collection of thread\\r\\nbenchmarks ([http://darcs.haskell.org/nofib/smp]).  This is comparing\\r\\nyesterday's HEAD with my working branch:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed\\r\\n--------------------------------------------------------------------------------\\r\\n    callback001        +289.3%    -13.5%     +0.8%     +1.2%\\r\\n    callback002        +302.0%    -13.5%     -1.3%     -1.3%\\r\\n          sieve        +329.2%     -0.2%     -1.6%     -1.3%\\r\\n     threads001        +292.4%     +0.0%     +4.2%     +4.5%\\r\\n     threads003        +298.9%     -0.5%    -36.5%    -36.4%\\r\\n     threads006        +304.1%     -2.2%    -66.4%    -66.4%\\r\\n     threads007        +409.7%     +0.0%     +2.4%     +2.5%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +289.3%    -13.5%    -66.4%    -66.4%\\r\\n            Max        +409.7%     +0.0%     +4.2%     +4.5%\\r\\n Geometric Mean        +316.3%     -4.5%    -19.3%    -19.2%\\r\\n}}}\\r\\n\\r\\nIgnore the size figures, it's because the HEAD build was using\\r\\n`-split-objs`.\\r\\n\\r\\nWe can see that several benchmarks display no difference or get very\\r\\nslightly worse, but a couple (threads003 and threads006) see a big\\r\\njump in performance.  threads003 is an old variant on threadring, and\\r\\nthreads006 is a microbenchmark for throwTo.  I don't fully understand\\r\\nthe difference in performance here, but typically I don't investigate\\r\\nwhen things go faster, only when they go slower.\\r\\n\\r\\nGHC itself got a little faster: 1-2% when compiling Cabal.\\r\\n\\r\\nBut what you really wanted to know was... what about threadring,\\r\\nright?  Well, it currently goes a few percent slower with the new\\r\\nchanges.  However, I notice that it's allocating a lot more than\\r\\nbefore, so I think there's something suspicious going on.  I shall\\r\\ninvestigate...\\r\\n\\r\\n\\r\\n== Update: some more results ==\\r\\n\\r\\n!BinaryTrees, from the shootout:\\r\\n\\r\\n  * before: 64.26s\\r\\n  * after: 17.61s\\r\\n\\r\\nSo I guess the problem with !BinaryTrees was more to do with repeated stack traversals than it was to do with a low mortality rate.  Nice that we can get good performance from this program without tweaking the heap settings at all now.\\r\\n\\r\\nHackage benchmarks, from David Peixotto's fibon benchmark suite:\\r\\n\\r\\n{{{\\r\\n--------------------------------------------------------------------------------\\r\\n        Program           Size    Allocs   Runtime   Elapsed  TotalMem\\r\\n--------------------------------------------------------------------------------\\r\\n           Agum        +306.5%     +3.5%     +0.8%     +0.9%     +0.0%\\r\\n          Bzlib          -----     -----     -----     -----     -----\\r\\n           Cpsa        +125.1%     +2.1%     -2.2%     -2.3%     +0.0%\\r\\n         Crypto          -----     -----     -----     -----     -----\\r\\n            Fgl        +408.9%     +0.1%     +2.0%     +2.0%     -5.4%\\r\\n            Fst        +137.7%     -0.0%     -4.4%     -4.3%     +0.0%\\r\\n         Funsat        +151.4%     +0.2%     +1.7%     +1.8%     -2.0%\\r\\n             Gf         13990k 13885653k      9.03      9.60   116736k\\r\\n          HaLeX        +195.9%     +0.0%     +1.2%     +1.1%     +0.0%\\r\\n          Happy        +135.0%     +3.3%     -5.3%     -5.4%    -13.7%\\r\\n         Hgalib        +236.7%     +1.0%     +0.7%     +0.7%     +0.0%\\r\\n    Palindromes        +243.1%    -10.1%     +3.4%     +3.4%     +2.1%\\r\\n          Pappy        +148.9%     +0.5%     +3.7%     +3.8%    -17.7%\\r\\n     QuickCheck        +139.5%     -0.1%     -1.6%     -1.6%     +0.0%\\r\\n          Regex        +182.1%     +0.0%     +3.5%     +3.5%    -21.4%\\r\\n          Simgi        +159.3%     +0.0%     +6.9%     +6.9%     +0.0%\\r\\n   TernaryTrees        +519.4%     -2.0%    -32.4%    -32.7%    -14.3%\\r\\n          Xsact        +246.4%     +1.2%     +0.9%     +0.9%     -0.6%\\r\\n--------------------------------------------------------------------------------\\r\\n            Min        +125.1%    -10.1%    -32.4%    -32.7%    -21.4%\\r\\n            Max        +519.4%     +3.5%     +6.9%     +6.9%     +2.1%\\r\\n Geometric Mean        +207.6%     -0.1%     -1.9%     -1.9%     -5.2%\\r\\n}}}\\r\\n\\r\\nOne or two nice ones in there: !TernaryTrees, Happy, Fst all look good. Simgi probably deserves further investigation.\\r\\n\\r\\nNotice how the overall memory size is reducing too, by 5% on average.\\r\\n\\r\\n== Update 2: threadring results ==\\r\\n\\r\\nthreadring 10000000, without `-threaded`:\\r\\n \\r\\n * 6.12.3: 1.50s\\r\\n * 7.0.1: 2.05s\\r\\n * HEAD with stack patches: 1.67s\\r\\n\\r\\nSo the stack patches recovered almost all the performance lost between 6.12.3 and 7.0.1 on non-threaded threadring.  The performance lost in 7.0.1 was due to the BLACKHOLE changes and some other changes to fix pathological cases of bad `MVar` performance.\\r\\n\\r\\nMore interesting are the `-threaded` numbers:\\r\\n\\r\\n * 6.12.3: 5.86s\\r\\n * 7.0.1: 3.00s\\r\\n * HEAD with stack patches: 2.31s\\r\\n\\r\\nThe new code is very clearly winning here.  I spent a little while with the perf tool on Linux trying to understand the results, but wasn't able to fully account for it, sadly.\\r\\n","publish_time":1292430562,"version_time":1293034749,"version_comment":"Add some threadring results","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"Template Haskell Proposal","version":8,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1294852297,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":9,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1301665803,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":10,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1301665922,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":11,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1308821005,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":12,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1308821172,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"LetGeneralisationInGhc7","version":4,"title":"Let generalisation in GHC 7.0","body":"[Note: updated to GHC 7.2, Sept 2011]\\r\\n\\r\\nGHC 7.2 has a completely new type inference engine. The old one had\\r\\ngrown to resemble the closing stages of a game of Jenga, in which making any\\r\\nchange was a delicate operation that risked bringing \\r\\nthe whole edifice crashing down.  In particular, there were a dozen open\\r\\nbugs concerning type families that I had no idea how to fix.\\r\\n\\r\\nThis summer Dimitrios Vytiniotis, Brent Yorgey and I built \\r\\na completely new inference engine.  It rests on a solid\\r\\ntechnical foundation developed over the last couple\\r\\nof years, in a collaboration with Dimitrios, Tom Schrijvers, and Martin\\r\\nSulzmann.  There is a series of papers that lead up to it, but our\\r\\nJFP submission \\r\\n\"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\"\\r\\nsummarises the whole thing in one consistent notation.\\r\\n\\r\\nThe new engine feels much more solid to me, and indeed I've been able\\r\\nto close almost all those open bugs.  Doubtless there will be some\\r\\nnew ones, but I feel vastly more confident that we can fix them\\r\\nthan I did with the old engine.\\r\\n\\r\\nOne other thing is that the new typechecker has completely swept away\\r\\nthe old rather ''ad-hoc'' stuff about \"rigid\" types in GADT pattern matches.  So\\r\\nyou may find that some GADT programs will typecheck with fewer\\r\\ntype annotations than before.  \\r\\n\\r\\nHowever, there is one way in which GHC 7.2 will type ''fewer'' programs\\r\\nthan before, and that is the focus of this post. I want explain what the\\r\\nchange is, and  how to adapt your code to accommodate it.\\r\\n\\r\\n== Local polymorphism ==\\r\\n\\r\\nConsider this (contrived) program:\\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\n\\r\\nf :: forall a. a -> ((a, Char), (a, Bool))\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g :: forall b. b -> (a,b)\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nThis polymorphism is expressed in `g`'s type signature:\\r\\n  * `g` is a ''polymorphic'' function, because it is applied both to the character 'v' and to the boolean `True`.  \\r\\n  * However, `g` is ''monomorphic'' in `a`, because `g`'s body mentions `x`\\r\\nThe type signature `g :: forall b. b -> (a,b)`\\r\\nreflects these two points:\\r\\n  * The \"`forall b`\" says that `g` is polymorphic in `b`.  \\r\\n\\r\\n  * The `a` in the signature must is the `a` in the type of `x`.  This type variable `a` is brought into scope, in the body of `f`, by the `forall a` in the type signature for `f`.\\r\\nThe `LANGUAGE ScopedTypeVariables` pragma (a) allows you to use an\\r\\nexplicit \"`forall`\" in the type signature for a function `f`, and (b)\\r\\nbrings the `forall`'d type variables (`a` in this case) into scope in the body of the\\r\\nfunction `f`.\\r\\n\\r\\n== What has changed in GHC 7.2? == \\r\\n\\r\\nGHC 6.12 will compile the above program without any type signatures at all.\\r\\nIt infers the polymorphic type for `g`.  But, if you are using\\r\\ntype families or GADTs, GHC 7.0 will not.  More precisely:\\r\\n * The flags `-XGADTs` or `-XTypeFamilies`, or the corresponding `LANGUAGE` pragmas,\\r\\n   imply the (new) flag `-XMonoLocalBinds`.  \\r\\n\\r\\n * With `-XMonoLocalBinds`, non-top-level (or ''local'') let/where \\r\\n   bindings are not generalised.\\r\\n\\r\\n * Remember that `-fglasgow-exts` implies `-XGADTs` and hence `-XTypeFamilies`.\\r\\n\\r\\nSo given the type-signature-free code\\r\\n{{{\\r\\n{-# LANGUAGE MonoLocalBinds #-}\\r\\nf x = (g 'v', g True)\\r\\n    where\\r\\n      g y = (x,y)\\r\\n}}}\\r\\nGHC 7.2 will reject the program with\\r\\n{{{\\r\\nFoo.hs:6:17:\\r\\n    Couldn't match expected type `Char' with actual type `Bool'\\r\\n    In the first argument of `g', namely `True'\\r\\n    In the expression: g True\\r\\n    In the expression: (g 'v', g True)\\r\\n}}}\\r\\nWhy?  Because the type of `g` is not generalised, so it\\r\\ncan only be applied to either `Char` or `Bool` but not both.\\r\\n\\r\\n== Which bindings are affected? == \\r\\n\\r\\nIn the JFP paper we propose the rule that ''local bindings are not generalised'',\\r\\nwhere \"local\" means \"syntactically not top level\".  This was the rule implemented by GHC 7.0.\\r\\n\\r\\nHowever GHC 7.2 relaxes the restriction slightly.  Consider\\r\\n{{{\\r\\n{-# LANGUAGE MonoLocalBinds #-}\\r\\nf x = (k 'v', k True)\\r\\n    where\\r\\n      h y = (y,y)  -- Note: x is not mentioned\\r\\n      k z = (h z, h z)\\r\\n}}} \\r\\nNow the binding for `h` is \"local\" in the sense that it is\\r\\nnot syntactically top-level, but it has no free variables, so it\\r\\n''could have been'' top-level.  Similarly, `k` is \"local\" but\\r\\nonly mentions `h` which could have been top-level, and hence `k`\\r\\ncould be top-level too.  GHC 7.2 spots this, and generalises both\\r\\njust as if they had been top level.\\r\\n\\r\\nHere's the rule. With `-XMonoLocalBinds` (the default), a binding without a\\r\\ntype signature is '''generalised only if all its free variables are closed'''.  \\r\\n\\r\\nA binding is '''closed''' if and only if\\r\\n * It has a type signature, and the type signature has no free variables; or\\r\\n * It has no type signature, and all its free variables are closed, and it\\r\\n   is unaffected by the monomorphism restriction. And hence it is \\r\\n   fully generalised.\\r\\n\\r\\nIn our example, `h` has no free variables and hence is generalised;\\r\\nmoreover, `k` has free variable `h`, but it is closed, so `k` too can be\\r\\ngeneralised.\\r\\n\\r\\nHere's another example:\\r\\n{{{\\r\\nx = 4 + 5\\r\\ny = x + 7\\r\\n}}}\\r\\nBoth bindings are top-level, but `x` falls under the Monomorphism Restriction and is not generalised for that reason.  So `x` is not closed.  Hence `y` is not generalised either, since it has a non-closed free variable `x`.  (This really fixes a bug in GHC 7.0 which erroneously generalised `y` because it was syntactically top level.)\\r\\n\\r\\n== How can I fix my program? ==\\r\\n\\r\\nAlmost all code doesn't need local let definitions to have\\r\\na polymorphic type, because the function is only used at one type.\\r\\nBut not all.  There are two ways to fix your program if it falls\\r\\nover because of the `MonoLocalBinds` change.\\r\\n\\r\\n * Check whether you need `-XGADTs` or `-XTypeFamilies`.  If you are using the blunderbuss `-fglasgow-exts`, replace it with proper `LANGUAGE` pragmas.\\r\\n\\r\\n * The good way is simply give a type signature to the local definition, as I did for `g` above.  Writing such a type signature may force you to use `{-# LANGUAGE ScopedTypeVariables #-}` as the above example showed.  My experience is that the code is easier to understand with the type signature.\\r\\n\\r\\n * The `-XGADTs` or `-XTypeFamilies` pragmas switch on `MonoLocalBinds` but, if you want, you can override it with `-XNoMonoLocalBinds` (or the equivalent `LANGUAGE` pragma).  The type checker will then do its best to generalise local bindings, and your program will almost certainly work.  However, I don't know how to guarantee any good properties of the type inference algorithm.  So I think this is ok as as short term fix, but I'd like to encourage you to add that handful of type signatures instead.\\r\\n\\r\\nYou may not be very familiar with the code,\\r\\nso it can be tricky to work out what type the local definition should have.\\r\\n(That's one reason I think that the code is improved by having a type signature!)\\r\\nWith this in mind I've added a new warning flag `-fwarn-missing-local-sigs`, which\\r\\nprints a warning, and the type, of any ''polymorphic'' local binding that\\r\\nlacks a type signature. So you can follow this procedure:\\r\\n * Compile with `-XNoMonoLocalBinds -fwarn-missing-local-sigs`. The first flag makes it compile, and the second shows you the types.\\r\\n * Compile with neither flag, getting some errors.\\r\\n * Add type signatures to cure the errors, using the types printed out in the first step.\\r\\n\\r\\nAdding the type signature is completely compatible with GHC 6.12 etc, so you shouldn't need any conditional compilation if you want to compile your code with multiple versions of GHC.\\r\\n\\r\\n== A second, bigger example == \\r\\n\\r\\nOne relatively common situation in which you need a local type signature\\r\\nis when you use `runST` with some auxiliary definitions.  \\r\\nHere is a typical example: \\r\\n{{{\\r\\n{-# LANGUAGE ScopedTypeVariables #-}\\r\\nmodule Test where\\r\\nimport Control.Monad.ST\\r\\nimport Data.STRef\\r\\n\\r\\nfoo :: forall a. Bool -> a -> a -> a\\r\\nfoo b x y = runST (do { r <- newSTRef x; fill r; readSTRef r })\\r\\n          where\\r\\n            -- fill :: forall s. STRef s a -> ST s ()\\r\\n            fill r = case b of\\r\\n                       True  -> return ()\\r\\n                       False -> writeSTRef r y\\r\\n\\r\\n-- runST :: forall a. (forall s. ST s a) -> a\\r\\n-- newSTRef   :: a -> ST s (STRef s a)\\r\\n-- readSTRef  :: STRef s a -> ST s a\\r\\n-- writeSTRef :: STRef s a -> a -> ST s ()\\r\\n}}}\\r\\nThe function `foo` is a bit contrived, but it's typical of the way\\r\\nin which `runST` is often used.  We allocate a reference cell, containing `x`,\\r\\ncall `fill`, and then read out what is now in the reference cell.  \\r\\nAll `fill` does is overwrite the cell if `b` is `False`.\\r\\nSo `foo` is really an elaborate `if` function.\\r\\n\\r\\nBut in GHC 7.0, with `-XMonoLocalBinds` (or `-XGADTs`, `-XTypeFamilies`),\\r\\nthe program will be rejected with this alarming-seeming error message\\r\\n{{{\\r\\nFoo.hs:7:11:\\r\\n    Couldn't match type `s' with `s1'\\r\\n      because this skolem type variable would escape: `s1'\\r\\n    This skolem is bound by the polymorphic type `forall s. ST s a'\\r\\n    The following variables have types that mention s\\r\\n      fill :: STRef s a -> ST s () (bound at Foo.hs:10:11)\\r\\n    In the first argument of `runST', namely\\r\\n      `(do { r <- newSTRef x; fill r; readSTRef r })'\\r\\n}}}\\r\\nRemember, `fill` has not been generalised, so it gets a monomorphic type.\\r\\nThat in turn means that the argument to `runST` is not polymorphic enough.\\r\\n\\r\\nDespite its scariness, in some ways the error message identifies\\r\\nthe problem more clearly than the previous example. In particular, the error\\r\\nmessage identifies `fill` as the culprit.  \\r\\nYou can fix it the same way as before, by adding a signature for `fill`;\\r\\nI've put it in a comment above.\\r\\n\\r\\n== Why make this change? ==\\r\\n\\r\\nAt first this change seems like retrograde step, so why did we make\\r\\nit?  It's a long story, but the short summary is this: I don't know\\r\\nhow to build a reliable, predictable type inference engine for a type\\r\\nsystem that has both (a) generalisation of local let/where and (b) local\\r\\ntype equality assumptions, such as those introduced by GADTs.  The story is told\\r\\nin our paper \"[http://research.microsoft.com/en-us/um/people/simonpj/papers/constraints/index.htm Let should not be generalised]\" and, at greater length, in \\r\\nthe journal version \"[http://haskell.org/haskellwiki/Simonpj/Talk:OutsideIn Modular type inference with local assumptions]\".\\r\\n\\r\\n\\r\\n","publish_time":1285811634,"version_time":1315408081,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":13,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- refiy 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  \\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1325067838,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":14,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1325089692,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":15,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1327432129,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":16,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364, #6062.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1335871831,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":17,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1336988357,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":18,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089.  Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nThere's an interesting [http://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell critique of Template Haskell] on !StackOverflow, some (but not all) of which is addressed by proposals here.\\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1338879382,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":19,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089. (See also #7016, which work better with the suggestions below.) Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nThere's an interesting [http://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell critique of Template Haskell] on !StackOverflow, some (but not all) of which is addressed by proposals here.\\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1340206094,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"newcg-update","version":1,"title":"The new code generator is nearly ready to go live","body":"I've just spent another week working on the Glorious New Code Generator, and I'm pleased to say it's now in a state that we can think about switching over.\\r\\n\\r\\nJust to recap, the \"new code generator\" is a replacement for the STG->Cmm phase of the compiler, using a new intermediate representation based on [http://research.microsoft.com/en-us/um/people/simonpj/papers/c--/dfopt.pdf Hoopl] , and separating out the mechanics of layout out stack frames from code generation.  It's mainly an architectural change with little visible benefit, but it will be a big improvement in terms of flexibility and modularity inside the compiler.  We'll be able to express many optimisations that were hard before, e.g. #1498.\\r\\n\\r\\nFurthermore, many bits of cruft will go away, such as large chunks of the horrible `CoreToStg` pass, and the SRT analysis.  These things are replaced by much cleaner analyses of the generated code using Hoopl.\\r\\n\\r\\nFor more details on the new code generator see [wiki:Commentary/Compiler/NewCodeGen], although that page needs a lot of updating after my recent hacking.\\r\\n\\r\\nThe current status in more detail:\\r\\n\\r\\n * everything works, with the possible exception of profiling.  I've just got a stage2 compiler working, and the whole test suite passes with no new failures.\\r\\n\\r\\n * generated code is on average as good as before, sometimes better and sometimes worse.  I have a few examples of tight loops that get better with the new code gen, but of course for complex low-level loopy code LLVM will still be necessary to get really good code.  On the other hand, GHC can take advantage of its better knowledge about aliasing, and I expect to make more use of this in the future.  There's quite a bit of scope for generating better code and adding cool Hoopl-based optimisations later.  Things are definitely looking up for low-level performance in GHC.\\r\\n\\r\\n * compile times will get a bit worse, at least initially.  This is where I've been spending a lot of effort: when I started work on the new code generator it was adding more than 100% to compile times, and I've got that down to about 5% for optimised compilation, 10-15% for non-optimised.  Compile times will improve further when we switch over properly and we can start removing a lot of cruft.\\r\\n\\r\\nWe now have a 7.6 branch, so my plan is to fix the one remaining blocker (profiling) and then switch over.  There will no doubt be breakage that hasn't shown up so far, but we have until 7.8 to find and fix it.\\r\\n\\r\\n","publish_time":1344006824,"version_time":1344006824,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"weekly20141107","version":5,"title":"GHC Weekly News - 2014/11/07","body":"Hello *,\\r\\n\\r\\nIt's that time again, so get ready for some good ol' fashion news about your favorite compiler.\\r\\n\\r\\n  - Austin announced the 7.10 STABLE freeze date earlier today, which is two weeks from the time of this posting: November 21st, 2014. If you're a developer and have a feature you want, you'd better get it reviewed and checked soon! https://www.haskell.org/pipermail/ghc-devs/2014-November/007206.html\\r\\n  - Austin also opened a discussion about a possible LTS branch for GHC, spawned off from a suggestion by John Lato a few weeks email. This discussion has been brought up several times before this, but for the most part has fizzled out a bit. But maybe with a different focus - on a separate branch with a team of maintainers - we can hash out a plan of action, and just give it a whirl. https://www.haskell.org/pipermail/ghc-devs/2014-November/007207.html\\r\\n  - This past week, Simon PJ, Austin, Gintautas Miliauskas, and several others met over a video chat to discuss the future of windows builds. And it went pretty well! We've scribed up some notes, and sort of laid out what we think will be happening for Windows in the near future. https://www.haskell.org/pipermail/ghc-devs/2014-October/006897.html\\r\\n  - Gergo Erdi opened up an RFC about type signatures for pattern synonyms, which is one of the last pieces of the pattern synonyms implementation we've been missing. https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n  - Simon PJ pushed a major overhaul of the constraint solver, just in time for GHC 7.10. This was the result of a few months of work that Simon has been glad to get off his plate, and hopefully should make the type checker faster, leaner, and more modular (as usual).\\r\\n  - Jan Stolarek talked about his planned improvements to the users guide, which is ticket #9358. Hopefully for 7.10 the resulting documentation will be *much* more clear and up to date. https://www.haskell.org/pipermail/ghc-devs/2014-November/007169.html\\r\\n  - Alan Zimmerman has got some more patches up for adding annotations to the GHC Abstract Syntax Tree (AST). The hope is this new representation will make it much easier for tools to enrich the AST with their own custom metadata. Alan has been working on this for several weeks now, so a good review is in order! https://www.haskell.org/pipermail/ghc-devs/2014-November/007133.html\\r\\n  - Mateusz Lenik, a new contributor, has discussed improving the 'Ticky Ticky' profiling code and resurrecting some of the older features; luckily Jan inspired this work and had some comments. Thanks Mateusz! https://www.haskell.org/pipermail/ghc-devs/2014-November/007078.html\\r\\n  - Alexander Berntsen asked an question about abstracting over constraints in GHC. Richard replied, but it seems this work might be quite difficult! https://www.haskell.org/pipermail/ghc-devs/2014-November/007165.html\\r\\n  - Austin Seipp brought up a question about Windows support: can we officially drop support for XP, now that Microsoft has done the same? And what minimum version requirements should we endorse? Vista or Windows 7 would give improvements due to API improvements, with Windows 7 offering even more. If you're a GHC on Windows user, please let us know! https://www.haskell.org/pipermail/ghc-devs/2014-November/007199.html\\r\\n\\r\\nAnd this weeks closed tickets include quite a long list, thanks to everyone cleaning up the bug tracker: #9747, #9236, #9753, #9752, #9262, #8953, #9084, #9738, #8571, #8295, #8261, #9754, #110, #9345, #8849, #8819, #9658, #8960, #9395, #9705, #9433, #9633, #9359, #9081, #8482, #3376, #9712, #9739, #9211, #9728, #9750, #9768, #9773, #9741, #9284, #9774, #9771, #9001, #8626, #8986, #9268, #8975, #8962, #8921, #8089, #8843, #8829, #9295, #7913, #2528, #9779.","publish_time":1415397312,"version_time":1415397858,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141118","version":1,"title":"Weekly 2014/11/18","body":"Hello *,\\r\\n\\r\\nOnce more we have the GHC Weekly news! This one is a bit late due to Austin being in limbo unexpectedly for a few days last week. (The next one will of course come again on Friday to keep things straight.)\\r\\n\\r\\nWith that out of the way, let's see what exactly is going on:\\r\\n\\r\\n - The STABLE freeze is happening at the end of this week! That means if you have something you want to get in, try to get people aware of it! Austin (yours truly) has a backed up review queue it would seem, but hopes to clear a bunch of it out before then.\\r\\n\\r\\n - Simon and Gergo started a whole bunch of discussion about type signatures for pattern synonyms. There is a surprising amount of content to talk about here for something that might seem simple: https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n\\r\\n - Herbert Valerio Riedel has finally landed `integer-gmp2`, AKA Phab:D86, which implements a complete overhaul of the `integer-gmp` library. This library will be switched on by default in GHC 7.10.1, which means the `integer-gmp` library version will have a super-major bump (version `1.0.0.0`). This is the beginning of a longer-term vision for more flexible `Integer` support in GHC, as described by Herbert on the design page: https://ghc.haskell.org/trac/ghc/wiki/Design/IntegerGmp2\\r\\n  This implementation also fixes a long standing pain point where GHC would hook GMP allocations to exist on the GHC heap. Now GMP is just called to like any FFI library.\\r\\n\\r\\n  - Jan Stolarek made a heads up to help out GHC newcomers: if you see a ticket that should be easy, please tag it with the `newcomer` keyword! This will let us have a live search of bugs that new developers can take over. (Incidentally, Joachim mentions this is the same thing Debian is doing in their bug tracker): https://www.haskell.org/pipermail/ghc-devs/2014-November/007313.html\\r\\n\\r\\n  - Merijn Verstraaten has put forward a proposal for more flexible literate style Haskell file extensions. There doesn't seem to be any major opposition, just some questions about the actual specification and some other ramifications: https://www.haskell.org/pipermail/ghc-devs/2014-November/007319.html\\r\\n\\r\\n  - Facundo Domínguez posed a question about CAFs in the GC, which Jost Berthold was fairly quick to reply to: https://www.haskell.org/pipermail/ghc-devs/2014-November/007353.html\\r\\n\\r\\n  - Adam Gundry, Eric Seidel, and Iavor Diatchki have grouped together to get a new, unexpected feature into 7.10: type checking plugins. Now, GHC will be able to load a regular Haskell package as a plugin during the compilation process. Iavor has a work-in-progress plugin that solves constraints for type-level natural numbers using a SMT solver. The code review from everyone was published in Phab:D489.\\r\\n\\r\\n  - Austin opened up a discussion about the future of the Haskell98 and Haskell2010 packages, and the unfortunate conclusion is it looks like we're going to drop them for 7.10. Austin has some rationale, and there was some followup in the mailing list thread too: https://www.haskell.org/pipermail/ghc-devs/2014-November/007357.html\\r\\n\\r\\nClosed tickets this week include: #9785, #9053, #9513, #9073, #9077, #9683, #9662, #9646, #9787, #8672, #9791, #9781, #9621, #9594, #9066, #9527, #8100, #9064, #9204, #9788, #9794, #9608, #9442, #9428, #9763, #9664, #8750, #9796, #9341, #9330, #9323, #9322, #9749, #7381, #8701, #9286, #9802, #9800, #9302, #9174, #9171, #9141, #9100, #9134, #8798, #8756, #8716, #8688, #8680, #8664, #8647, #9804, #8620, #9801, #8559, #8559, #8545, #8528, #8544, #8558","publish_time":1416332137,"version_time":1416332137,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141118","version":2,"title":"GHC Weekly News 2014/11/18","body":"Hello *,\\r\\n\\r\\nOnce more we have the GHC Weekly news! This one is a bit late due to Austin being in limbo unexpectedly for a few days last week. (The next one will of course come again on Friday to keep things straight.)\\r\\n\\r\\nWith that out of the way, let's see what exactly is going on:\\r\\n\\r\\n - The STABLE freeze is happening at the end of this week! That means if you have something you want to get in, try to get people aware of it! Austin (yours truly) has a backed up review queue it would seem, but hopes to clear a bunch of it out before then.\\r\\n\\r\\n - Simon and Gergo started a whole bunch of discussion about type signatures for pattern synonyms. There is a surprising amount of content to talk about here for something that might seem simple: https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n\\r\\n - Herbert Valerio Riedel has finally landed `integer-gmp2`, AKA Phab:D86, which implements a complete overhaul of the `integer-gmp` library. This library will be switched on by default in GHC 7.10.1, which means the `integer-gmp` library version will have a super-major bump (version `1.0.0.0`). This is the beginning of a longer-term vision for more flexible `Integer` support in GHC, as described by Herbert on the design page: https://ghc.haskell.org/trac/ghc/wiki/Design/IntegerGmp2\\r\\n  This implementation also fixes a long standing pain point where GHC would hook GMP allocations to exist on the GHC heap. Now GMP is just called to like any FFI library.\\r\\n\\r\\n  - Jan Stolarek made a heads up to help out GHC newcomers: if you see a ticket that should be easy, please tag it with the `newcomer` keyword! This will let us have a live search of bugs that new developers can take over. (Incidentally, Joachim mentions this is the same thing Debian is doing in their bug tracker): https://www.haskell.org/pipermail/ghc-devs/2014-November/007313.html\\r\\n\\r\\n  - Merijn Verstraaten has put forward a proposal for more flexible literate style Haskell file extensions. There doesn't seem to be any major opposition, just some questions about the actual specification and some other ramifications: https://www.haskell.org/pipermail/ghc-devs/2014-November/007319.html\\r\\n\\r\\n  - Facundo Domínguez posed a question about CAFs in the GC, which Jost Berthold was fairly quick to reply to: https://www.haskell.org/pipermail/ghc-devs/2014-November/007353.html\\r\\n\\r\\n  - Adam Gundry, Eric Seidel, and Iavor Diatchki have grouped together to get a new, unexpected feature into 7.10: type checking plugins. Now, GHC will be able to load a regular Haskell package as a plugin during the compilation process. Iavor has a work-in-progress plugin that solves constraints for type-level natural numbers using a SMT solver. The code review from everyone was published in Phab:D489.\\r\\n\\r\\n  - Austin opened up a discussion about the future of the Haskell98 and Haskell2010 packages, and the unfortunate conclusion is it looks like we're going to drop them for 7.10. Austin has some rationale, and there was some followup in the mailing list thread too: https://www.haskell.org/pipermail/ghc-devs/2014-November/007357.html\\r\\n\\r\\nClosed tickets this week include: #9785, #9053, #9513, #9073, #9077, #9683, #9662, #9646, #9787, #8672, #9791, #9781, #9621, #9594, #9066, #9527, #8100, #9064, #9204, #9788, #9794, #9608, #9442, #9428, #9763, #9664, #8750, #9796, #9341, #9330, #9323, #9322, #9749, #7381, #8701, #9286, #9802, #9800, #9302, #9174, #9171, #9141, #9100, #9134, #8798, #8756, #8716, #8688, #8680, #8664, #8647, #9804, #8620, #9801, #8559, #8559, #8545, #8528, #8544, #8558","publish_time":1416332137,"version_time":1416606201,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141121","version":1,"title":"GHC Weekly News - 2014/11/21","body":"Hi *,\\r\\n\\r\\nTo get things back on track, we have a short post following up the earlier one this week. It's been busy today so I'll keep it short:\\r\\n\\r\\n  - The STABLE freeze Austin announced two weeks ago is happening now, although at this point a few things we wanted to ship are just 98% ready. So it may wait until Monday.\\r\\n\\r\\n  - Gergo Erdi merged the implementation of pattern synonym type signatures: https://www.haskell.org/pipermail/ghc-devs/2014-November/007369.html\\r\\n\\r\\n  - HEAD now has support for using the 'deriving' clause for arbitrary classes (see #5462).\\r\\n\\r\\n  - HEAD now has a new flag `-fwarn-missing-exported-sigs`, which fixes #2526. See https://phabricator.haskell.org/D482\\r\\n\\r\\n  - HEAD now has 64bit iOS and SMP support for ARM64, thanks to Luke Iannini. See #7942.\\r\\n\\r\\n  - HEAD no longer ships `haskell98`, `haskell2010`, `old-locale` or `old-time`, per our decision to drop support for `haskell98` and `haskell2010`. GHC 7.10 compatible releases of `old-locale` and `old-time` have been released on hackage.\\r\\n  - HEAD has been very busy the past two days as many things are now trying to merge as closely to the window as possible. \\r\\n\\r\\n  - `base` now exports a new module for Natural numbers called `Numeric.Natural` following Herbert Valerio Riedel's recent proposal.\\r\\n\\r\\n  - HEAD should finally be compatible with LLVM 3.5, AKA #9142. The patch from Ben Gamari is at https://phabricator.haskell.org/D155\\r\\n\\r\\n  - Your author has been busy and delayed due to some bad travel experiences the past week, so the 7.8.4 RC1 hasn't landed this past week. Hopefully it will be out by the end of this week still.\\r\\n\\r\\nSince the last update was only a few days ago, you'd think we haven't closed a lot of tickets, but we have! Thomas Miedema has been very very adamant about closing tickets and cleaning them up, which is greatly appreciated: #9810, #8324, #8310, #9396, #9626, #9776, #9807, #9698, #7942, #9703, #8584, #8968, #8174, #9812, #9209, #9220, #9151, #9201, #9318, #9109, #9126, #8406, #8102, #8093, #8085, #8068, #8094, #9590, #9368, #2526, #9569, #8149, #9815, #5462, #9647, #8568, #9293, #7484, #1476, #9824, #9628, #7942","publish_time":1416616428,"version_time":1416616428,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"newcg-update","version":2,"title":"The new code generator is nearly ready to go live","body":"I've just spent another week working on the Glorious New Code Generator, and I'm pleased to say it's now in a state that we can think about switching over.\\r\\n\\r\\nJust to recap, the \"new code generator\" is a replacement for the STG->Cmm phase of the compiler, using a new intermediate representation based on [http://research.microsoft.com/en-us/um/people/simonpj/papers/c--/dfopt.pdf Hoopl] , and separating out the mechanics of layout out stack frames from code generation.  It's mainly an architectural change with little visible benefit, but it will be a big improvement in terms of flexibility and modularity inside the compiler.  We'll be able to express many optimisations that were hard before, e.g. #1498.\\r\\n\\r\\nFurthermore, many bits of cruft will go away, such as large chunks of the horrible `CoreToStg` pass, and the SRT analysis.  These things are replaced by much cleaner analyses of the generated code using Hoopl.\\r\\n\\r\\nFor more details on the new code generator see [wiki:Commentary/Compiler/NewCodeGen], although that page needs a lot of updating after my recent hacking.\\r\\n\\r\\nThe current status in more detail:\\r\\n\\r\\n * everything works, with the possible exception of profiling.  I've just got a stage2 compiler working, and the whole test suite passes with no new failures.\\r\\n\\r\\n * generated code is on average as good as before, sometimes better and sometimes worse.  I have a few examples of tight loops that get better with the new code gen, but of course for complex low-level loopy code LLVM will still be necessary to get really good code.  On the other hand, GHC can take advantage of its better knowledge about aliasing, and I expect to make more use of this in the future.  There's quite a bit of scope for generating better code and adding cool Hoopl-based optimisations later.  Things are definitely looking up for low-level performance in GHC.\\r\\n\\r\\n * compile times will get a bit worse, at least initially.  This is where I've been spending a lot of effort: when I started work on the new code generator it was adding more than 100% to compile times, and I've got that down to about 5% for optimised compilation, 10-15% for non-optimised.  Compile times will improve further when we switch over properly and we can start removing a lot of cruft.\\r\\n\\r\\nWe now have a 7.6 branch, so my plan is to fix the one remaining blocker (profiling) and then switch over.  There will no doubt be breakage that hasn't shown up so far, but we have until 7.8 to find and fix it.\\r\\n\\r\\n'''EDIT''': I should mention that the new code generator is the work of many people, including Norman Ramsey, Simon Peyton Jones, John Dias, Edward Yang and probably others I've forgotten.\\r\\n","publish_time":1344006824,"version_time":1344007656,"version_comment":"","version_author":"simonmar","author":"simonmar","categories":""},
{"name":"Template Haskell Proposal","version":20,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089. (See also #7016, which work better with the suggestions below.) Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nThere's an interesting [http://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell critique of Template Haskell] on !StackOverflow, some (but not all) of which is addressed by proposals here.\\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\nHere's the [wiki:Commentary/Compiler/TemplateHaskell/Typed implementation page] the describes how we are going to implement this stuff.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1365776057,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":21,"title":"New directions for Template Haskell","body":"This post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4230, #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089. (See also #7016, which work better with the suggestions below.) Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nThere's an interesting [http://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell critique of Template Haskell] on !StackOverflow, some (but not all) of which is addressed by proposals here.\\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\nHere's the [wiki:Commentary/Compiler/TemplateHaskell/Typed implementation page] the describes how we are going to implement this stuff.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1368088676,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"Template Haskell Proposal","version":22,"title":"New directions for Template Haskell","body":"'''Nota bene''': ''[wiki:TemplateHaskell/BlogPostChanges] is a copy of this blog post, but with subsequent edits and improvements.  Don't pay too much attention to the text below; I'm keeping it only so that you can see the context for comments''.\\r\\n\\r\\nThis post explores a set of design proposals for Template Haskell.  They are inspired by discussion with Tim Sheard, Kathleen Fisher, and Jacques Carette.  It was originally triggered by several Template Haskell tickets: including #4230, #4135, #4128, #4170, #4125, #4124, #4364, #6062, #6089. (See also #7016, which work better with the suggestions below.) Taken together, these proposals would make quite a big change to TH, I think for the better.  Happily, I'm pretty sure they are relatively easy to implement.  \\r\\n\\r\\nThere's an interesting [http://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell critique of Template Haskell] on !StackOverflow, some (but not all) of which is addressed by proposals here.\\r\\n\\r\\nBut I'd like to get the design right; hence this post.  I'm going to treat it as a working draft, and modify it in the light of comments.  So please comment.\\r\\n\\r\\nI'm going to assume that you are more or less familiar with Template Haskell.  If not, there's lots of background on the [http://www.haskell.org/haskellwiki/Template_Haskell Template Haskell page].  It's a Wiki so you can help to improve it.\\r\\n\\r\\nHere's the [wiki:Commentary/Compiler/TemplateHaskell/Typed implementation page] the describes how we are going to implement this stuff.\\r\\n\\r\\n= Some brief background =\\r\\n\\r\\nAfter parsing, GHC runs two completely separate passes, one after the other:\\r\\n * The '''renamer''' resolves scopes, fixing precisely which ''binding site'' is connected which ''occurrence'' of every variable.  For example, you write \\r\\n{{{\\r\\nlet x = \\\\x -> x+1 in x\\r\\n}}}\\r\\n   and the renamer changes it to\\r\\n{{{\\r\\nlet x_77 = \\\\x_78 -> x_78 + 1 in x_77\\r\\n}}}\\r\\n   The renamer also performs depdenency analysis, which sorts bindings (both value declarations and type declarations) into the smallest possible mutually recursive groups.  This prior sorting is required to maximise polymorphism in mutually recursive value bindings.\\r\\n\\r\\n * The '''typechecker''' works on the renamed program, and typechecks it.\\r\\n\\r\\nAt the moment these two passes relate to Template Haskell as follows:\\r\\n * '''Quasi-quotes are run in the renamer'''.  Why?  Because quasi-quotes can expand to patterns. \\r\\nConsider this, which has a quasi-quoted pattern:\\r\\n{{{\\r\\n\\\\x -> \\\\ [pads| blah |] -> x+1\\r\\n}}}\\r\\n  Is the \"x\" in \"x+1\" bound by the outer `\\\\x` or by the 'x' that might be bought into scope by the `[pads| blah |]` quasi-quote?  The only way to know is to run the quasi-quote, so that's what happens.\\r\\n\\r\\n * '''All other Template Haskell stuff is run in the typechecker'''.  Why?  Because we try to typecheck quotations before feeding them into TH functions.  More on this below.\\r\\n\\r\\n--------------------------------\\r\\n= The main issue =\\r\\n\\r\\nThe big issue is this: Template Haskell is both too ''weakly'' typed and too ''strongly'' typed.\\r\\n\\r\\n== Too weakly typed ==\\r\\n\\r\\nA TH quotation has type `Q Exp`, a type that says nothing about the type of the quoted term.\\r\\nFor example, consider\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nPresumably the author expects `$x` to be a boolean-valued term, but\\r\\nthat is not checked.  For example we might write\\r\\n{{{\\r\\nh = $(qnot [| \"hello\" |])\\r\\n}}}\\r\\nin which we pass a string-valued term to `qnot`. The splice will typecheck fine,\\r\\nbut the returned code will be the ill-typed `not \"hello\"`. There is no soundness problem\\r\\nbecause GHC typechecks the result of the splice `$(qnot [| \"hello\" |])`, but \\r\\nthe error is reported in code that the user never wrote.\\r\\n\\r\\nMoreover, errors can be delayed.  For example, suppose `qnot` was like this:\\r\\n{{{\\r\\nqnot :: Q Exp -> Q Exp\\r\\nqnot x = [| (not $x, length $x) |]\\r\\n}}}\\r\\nThis cannot possibly be right, becuase `$x` cannot be both a boolean and a list.\\r\\nYet TH will accept it, because a splice has type `forall a.a`.  The error will\\r\\nonly be reported to ''callers'' of `qnot`.\\r\\n\\r\\nThis is bad.  MetaML solves this problem by giving types to quoted terms, something\\r\\nlike this:\\r\\n{{{\\r\\nqnot :: TExp Bool -> TExp Bool\\r\\nqnot x = [| not $x |]\\r\\n}}}\\r\\nHere `TExp` (short for typed expressions) has a type parameter that expresses the\\r\\ntype of the quoted term.  \\r\\n\\r\\nIn TH we deliberately did not do this, because it restricts expressiveness; see\\r\\n[http://research.microsoft.com/en-us/um/people/simonpj/papers/meta-haskell/index.htm the original TH paper].\\r\\nWe could make this choice without losing soundness because in TH, unlike in MetaML, all splicing is\\r\\ndone at compile time, and the result of a splice is typechecked from scratch.\\r\\nBut still, it's a weakness and, for some users (stand up Jacques), a very serious weakness.\\r\\n\\r\\n== Too strongly typed ==\\r\\n\\r\\nEven though TH cannot guarantee to construct only type-correct code,\\r\\nevery quotation is typechecked.  For example, the quotation `[| \"hello\" && True |]`\\r\\nwould be rejected because it is internally inconsistent.\\r\\n\\r\\nBut with the advent of type splices (a \\r\\nvery useful feature) typechecking quotes has become hard to do. \\r\\nConsider this:\\r\\n{{{\\r\\n  f :: Q Type -> Q [Dec]\\r\\n  f t = [d| data T = MkT $t; \\r\\n            g (MkT x) = g+1 |]\\r\\n}}}\\r\\nThis function f returns a declaration quote, declaring T and g.\\r\\nYou'll see that the constructor MkT takes an argument whose type is passed (as a quotation) to f -- a type splice.\\r\\n\\r\\nThe difficulty is that we can't typecheck the declaration of 'g'\\r\\nuntil we know what $t is; and we won't know that until f is called.\\r\\nIn short, \\r\\n * we can't really typecheck the declaration quote at all\\r\\nAn analogous problem occurs in other declaration splices, for example\\r\\n{{{\\r\\n  f t = [d| instance C $t where ... |]\\r\\n}}}\\r\\nHere GHC's check that an instance decl is always of form\\r\\n{{{\\r\\n  instance C (T a b c)\\r\\n}}}\\r\\nfalls over, again because we don't know what $t will be.\\r\\nHere's another example:\\r\\n{{{\\r\\n      [| let { f :: $t; f = e } in .. |]\\r\\n}}}\\r\\nWe can't sensibly typecheck the term without knowing what f's type signature\\r\\nis, and we can't know that without expanding the splice.\\r\\n\\r\\nHere's a rather different example, #4364:\\r\\n{{{\\r\\ntype N0 = $( [t| Z |] )\\r\\ntype N1 = $( [t| Z |] )\\r\\n}}}\\r\\nFaced with a type splice\\r\\n{{{\\r\\ntype N0 = $(...blah...)\\r\\n}}}\\r\\nthe renamer doesn't know what the splice will expand to, because splices are currently\\r\\nrun later, in the type checker.  So it pessimistically assumes that the\\r\\nsplice could expand to mention anything in scope. But that pessimistic assuption triggers\\r\\nthe error message\\r\\n{{{\\r\\n     Cycle in type synonym declarations:\\r\\n       m.hs:7:1-23: type N0 = $([t| Z |])\\r\\n       m.hs:8:1-23: type N1 = $([t| Z |])  }}}\\r\\n}}}\\r\\nAll this is quite annoying.  Several users have said \"I'm just using a quotation as a convenient way \\r\\nto build a syntax tree.  Please don't even try to typecheck it; just wait\\r\\nuntil it is finally spliced into a top-level splice\".\\r\\n\\r\\n------------------------------\\r\\n= A proposal =\\r\\n\\r\\nTH currently embodies an uneasy compromise between being too strongly typed\\r\\nand too weakly typed.  So my proposal is to move TH in both directions at once:\\r\\n * Part A: Move the existing structures towards the expressive but weakly-typed end.\\r\\n * Part B: Add new MetaML-style constructs for strongly-typed metaprogramming.\\r\\n * Part C: Clean up and improve reification\\r\\n * Part D: Quasi-quotation improvements\\r\\n\\r\\n------------------------------\\r\\n== Part A: Reduce typechecking for quotes ==\\r\\n\\r\\nOn the \"make-it-weaker\" front, here's what I propose:\\r\\n\\r\\n * '''Cease typechecking TH quotes altogether'''. Instead, to use GHC's terminology, we would ''rename'' a quote, but not ''typecheck'' it.  The renaming pass ensures that the scope hygiene mechanisms would remain unchanged.  By not attempting to typecheck we avoid all the tricky problems sketched above.\\r\\n\\r\\n * '''Add pattern splices and local declaration splices''', as requested in #1476. For example\\r\\n{{{\\r\\n-- mkPat :: Q Pat -> Q Pat\\r\\nf $(mkPat [p| x |]) = x+1\\r\\n\\r\\n-- mkDecl :: Int -> Q [Dec]\\r\\ng x = let $(mkDecl 3) in ...\\r\\n}}}\\r\\n   These are not supported today because they bring new variables into scope, and hence are incompatible with running splices only after the renamer is finished; see [http://research.microsoft.com/~simonpj/tmp/notes2.ps Notes on Template Haskell], section 8.  \\r\\n\\r\\n * '''Run TH splices in the renamer''', uniformly with quasi-quotes.  Of course, we must still typecheck the code we are about to run.  But there's an ''existing'' TH restriction that code run in top-level splices must be imported.  So we can typecheck this code even during renaming, because it can only mention imported (and hence already fully-typechecked) code.\\r\\n\\r\\n This solves #4364 because we run the splice in the renamer, so things are sorted out by the time we are checking for cycles (in the type checker).\\r\\n\\r\\n * '''Allow quoted names as patterns''' as [http://www.haskell.org/pipermail/libraries/2012-January/017449.html requested by Conal Eliott].  This is just a variation on allowing splices in patterns, since a quoted name `'x` is really just a simple splice\\r\\n\\r\\nThese changes would essentially implement the desires of those who say \\r\\n\"I just want to generate syntax trees\".  All the mentioned bug reports would be fixed.\\r\\nThe big loss is that quotes would not be typechecked at all.\\r\\n\\r\\n== Lexical scoping ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\ng :: Int -> Q Pat\\r\\n\\r\\ny :: Int\\r\\ny = 7\\r\\n\\r\\nf :: Int -> Q Exp\\r\\nf n = [| \\\\ $(g n) -> y+1 |]\\r\\n}}}\\r\\nWhere is the 'y' bound in the RHS of `f`?  \\r\\n * Perhaps by the `y = 7` that is in scope at the definition of `f`?\\r\\n * Perhaps by the pattern that `$(g n)` expands to?  \\r\\n * Perhaps by a 'y' that is in scope at the splice site of `f`?\\r\\n * Does it depend on whether `$(g n)` in fact binds 'y'?\\r\\nA major point about TH is that we get lexical scoping (also called \"hygienic\").  So, to me it seems the the first of these choices is the only reasonable one.  If you want the second you can instead use explicit dynamic binding by saying\\r\\n{{{\\r\\nf n = [| \\\\ $(g n) -> $(return (VarE (mkName \"n\"))) + 1 |]\\r\\n}}}\\r\\nSo the rule would be:\\r\\n * In a quote, a variable 'v' is bound by the lexically enclosing binding of 'v', ignoring all pattern and declaration splices.\\r\\nTo be consistent this should apply to top level splices too.\\r\\n\\r\\n== A variation (probably not) ==\\r\\n\\r\\nA possible, rather ''ad hoc'', variation would be to still typecheck quotes that are (a) top level, and (b) expression quotes. For example, we might still reject this:\\r\\n{{{\\r\\nf x = [| $x + (True 'c') |]\\r\\n}}}\\r\\nbecause the quote is obviously ill-typed.  Only quotes nested inside top-level splices would avoid the type checker (because if the splice is run in the renamer, we can't typecheck the nexted quote).  For example:\\r\\n{{{\\r\\n$(f [| True 'c' |])\\r\\n}}}\\r\\nThis splice would run in the renamer, and only the ''result'' of the splice would be typechecked. \\r\\nBut what about this?\\r\\n{{{\\r\\nf t = [| let g :: $t-> Int; g = e in .... |]\\r\\n}}}\\r\\nThis is still very awkward to typecheck.  After all, if `$t` expands to a polymorphic type, the\\r\\nresult of the splice might typecheck, but it's really impossible to typecheck without \\r\\nknowing the signature.  Maybe we should just give up if there's a type splice?  The only really\\r\\nsimple thing is not to typecheck quotes at all.\\r\\n\\r\\n------------------------------\\r\\n== Part B: Add MetaML-style typed quotes ==\\r\\n\\r\\nTemplate Haskell has quotes for terms, types, patterns, and\\r\\ndeclarations.  They are all untyped, in the sense that the type of the quote\\r\\ntells you nothing about the type of the quoted thing.  For example\\r\\n{{{\\r\\n  [| True |] :: Q Exp\\r\\n}}}\\r\\nThere's no clue that the type of the quoted expression is `Bool`.\\r\\n\\r\\nIn the case of terms (only), we know how from MetaML to\\r\\nhave ''typed'' quotations.  Here's a proposed extension to TH to add\\r\\ntyped term quotes: \\r\\n\\r\\n * '''Add a new type of typed expressions''' `TExp a`\\r\\n\\r\\n * '''Add a new term quotation form''' `[|| e ||]`, called a ''typed quote''; the type of the quote is `TExp ty`, where `ty` is the type of `e`.  In the type-system jargon, this is the \"introduction form\" for `TExp`.\\r\\n\\r\\n * '''Add a new splice form''' `$$e`, called a ''typed splice''.  The term `e` must have type `TExp ty`, and the splice `$$e` then has type `ty`.  This is the \"elimination form\" for `TExp`.\\r\\n\\r\\n * '''Add a constant which takes a typed quote and returns an untyped one''': `unType :: TExp a -> Q Exp`\\r\\n\\r\\n * '''Run these new typed splices in the typechecker''', not the renamer.\\r\\n\\r\\n(The precise syntax for typed-quotes and type-splices is of course up for grabs.  But doubling the symbols seems plausible to me.)\\r\\n\\r\\nHere's a standard example:\\r\\n{{{\\r\\npower :: Int -> TExp (Int -> Int)\\r\\npower n = [|| \\\\x -> $$(go n [|| x ||]) ||]\\r\\n  where\\r\\n    go :: TExp Int -> TExp Int\\r\\n    go 0 x = [|| 1 ||]\\r\\n    go n x = [|| $x * $$(go (n-1)) ||]\\r\\n}}}\\r\\nYou could do this with existing TH but there'd be no guarantee that `power` would\\r\\nreturn a well-typed term. With `TExp` there is.\\r\\n\\r\\nPoints to notice\\r\\n * Unlike TH, the ''only'' way to construct a value of type `TExp` is with a quote.  You cannot drop into do-ntation, nor use explicit construction of the values in the `Exp` algebraic data type.  That restriction limits expressiveness, but it enables the strong typing guarantees.\\r\\n\\r\\n * There are no declaration, type, or pattern quotes for these typed quotes.  Only terms.\\r\\n\\r\\n * You can't use an untyped splice in a typed quote, thus `[|| ...$(e)... ||]`. Similarly, you can't splice a type, pattern, or declaration group in a typed term quote.\\r\\n\\r\\n * Using `unType` you can go from the typed world to the untyped one, which lets you mix the worlds.  Example:\\r\\n{{{\\r\\nf :: TExp Int -> Q Exp -> Q Exp\\r\\nf qt qu = [| $(unType qt) + $qu |]\\r\\n}}}\\r\\n * Unlike `Exp`, `TExp` is an abstract type, so you can't decompose values of type `TExp`.  All you can do with them is splice them (into a program or a larger quote).  Or you can convert to a `Q Exp` and ''then'' decompose, using the existing TH mechanisms.  For example\\r\\n{{{\\r\\ng :: TExp Int -> Q Exp\\r\\ng qt = do { tree <- unType qt\\r\\n          ; case tree of\\r\\n              VarE v -> ...\\r\\n              ConE c -> ...\\r\\n              ...etc...  }\\r\\n}}}\\r\\n * `TExp` is not a monad, but it is an applicative type constructor, although not quite an instance of `Applicative` class:\\r\\n{{{\\r\\n   pure e   ===   [|| e ||]\\r\\n   f <*> g   =    [|| $$f $$g ||]\\r\\n}}}\\r\\n Reminder: the `Applicative` class looks like this\\r\\n{{{\\r\\nclass Applicative f where\\r\\n  pure :: a -> f a\\r\\n  <*>  :: f (a->b) -> f a -> f b\\r\\n}}}\\r\\n `TExp` is only \"almost an instance\" because `pure` isn't a function; its argument must be syntactically quoted.\\r\\n\\r\\n'''Syntax''' is always a delicate point. \\r\\n * We could use some other kind of bracket, although brackets are always in short supply; eg `(| ... |)` or `{| ... |}`. \\r\\n * We could add Unicode brackets too (suggestions?); but I think we should have ASCII equivalents.\\r\\n * Ian asked whether `$(...)` could accept either `Q Exp` or `TExp`.  I think not; we need to know which kind of splice it is before type checking.\\r\\n\\r\\n\\r\\n------------------------------\\r\\n== Part C: Reification and typechecking ==\\r\\n\\r\\nThe third part of this proposal concerns reification.\\r\\nThe Q monad gives you access to the typechecker's environment.\\r\\nNotably, Template Haskell provides the function\\r\\n{{{\\r\\nreify :: Name -> Q Info\\r\\n}}}\\r\\nwhich, given the `Name` of a variable, type, or class, looks the `Name` up in the type environment and returns what the type checker knows about it:\\r\\n{{{\\r\\ndata Info = TyConI       -- A type\\r\\n               Dec\\t        -- Declaration of the type\\r\\n\\r\\n          | ClassI       -- A class\\r\\n               Dec              -- Declaration of the class\\r\\n               [ClassInstance]\\t-- The instances of that class\\r\\n\\r\\n          ...etc...\\r\\n}}}\\r\\n\\r\\n=== What reify sees ===\\r\\n\\r\\nA dark corner of `reify` is this: what types does `reify` see?  Consider\\r\\n{{{\\r\\nf x = ($(do { xi <- reify 'x; ... }),\\r\\n       x && True)\\r\\n}}}\\r\\nHere, `reify` can be used to examine the type of `x`.  But the type\\r\\nof `x` isn't fully known until the type checker has seen the \\r\\nterm `(x && True)`.   So in current TH it's going to be unpredicatable\\r\\nwhat you see for `x`, which is hardly satisfactory.\\r\\n\\r\\nIt seems to me that the only decent, predictable story is to say \\r\\nthat `reify` can only consult the ''top-level'' type environment.\\r\\nMore specifically, Template Haskell processes a program top-down:\\r\\n{{{\\r\\n  module M where\\r\\n   import ...\\r\\n   f x = x\\r\\n   $(th1 4)\\r\\n   h y = k y y $(blah1)\\r\\n   $(th2 10)\\r\\n   w z = $(blah2)\\r\\n}}}\\r\\nTH processes this module as follows:\\r\\n 1. Typecheck down to, but not including, the first splice, `$(th1 4)`.  These declarations constitute the first ''declaration group''.\\r\\n 2. Typecheck and run the splice, which returns a bunch of declarations D1\\r\\n 3. Typecheck the declarations D1 combined with the declarations down to, but not including, the second splice.  These declarations consitute the second declaration group.\\r\\n 4. Typecheck and run the next splice, `$(th2 10)`\\r\\n 5. Rinse and repeat\\r\\n\\r\\nSo the proposal is as follows. A ''declaration group'' is the chunk of declarations created by a top-level declaration splice, plus those following it, down to but not includig the next top-level declaration splice.  Then  '''the type environment seen by `reify` includes all the declaration up to the end of the immediately preceding declaration block, but no more.'''\\r\\n\\r\\nSo, in the preceding example:\\r\\n * A `reify` inside the splice `$(th1 ..)` would see the definition of `f`.\\r\\n * A `reify` inside the splice `$(blah)` woudl see the definition of `f`, but would not see any bindings created by `$(th1...)`.\\r\\n * A `reify` inside the splice `$(th2..)` would see the definition of `f`, all the bindings created by `$(th1..)`, and teh definition of `h`.\\r\\n * A `reify` inside the splice `$(blah2)` would see the same definitions as the splice `$(th2...)`.\\r\\n\\r\\nThis would mean that you could not say\\r\\n{{{\\r\\nf x = x\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\nbecause there is no top=level splice between the declaration of `f` and the splice. \\r\\nBut that seems reasonable to me.  If you want that behaviour you can say\\r\\n{{{\\r\\nf x = x\\r\\n$(return [])\\r\\ng y = $(do { info <- reify 'f; ... })\\r\\n}}}\\r\\n\\r\\n=== Reifying expressions ===\\r\\n\\r\\nBut what about ''expressions''? It would be useful (stand up Kathleen) \\r\\nto have a more elaborate reify, like this:\\r\\n{{{\\r\\ntypecheck :: [(Name,Type)]  -- Extend the type environment with this \\r\\n          -> Exp\\t    -- The expression to typecheck\\r\\n          -> Q (Either String Type)\\r\\n -- Typecheck the expression, returning\\r\\n --    Left error-message     if typechecking fails\\r\\n --    Right type             if typechecking succeeds\\r\\n}}}\\r\\n(For GHCi users, `reify f` is like `:info f`, while `typecheck [] (...)` is like `:type (...)`.)\\r\\n\\r\\nYou might ask whether we ''can'' typeckeck an expression; remember, these `Q ty` things \\r\\nare going to be run in the renamer.  But if the type environment is that in force\\r\\njust before the last top-level splice, then all is well: that stuff has been fully \\r\\ntypechecked. \\r\\n\\r\\n------------------------------\\r\\n== Part D: quasiquotation ==\\r\\n\\r\\nThis part is unrelated to the preceding proposals, and is responding to #4372 and #2041.\\r\\n\\r\\n * For #2041, rather than the proposal made there, I think the nicest thing is for `Language.Haskell.TH` to expose a ''Haskell'' quasiquoter:\\r\\n{{{\\r\\nparseHaskell :: QuasiQuoter\\r\\n}}}\\r\\n  Remember that a `QuasiQuoter` is a quadruple of parsers:\\r\\n{{{\\r\\ndata QuasiQuoter = QuasiQuoter { quoteExp  :: String -> Q Exp,\\r\\n                                 quotePat  :: String -> Q Pat,\\r\\n                                 quoteType :: String -> Q Type,\\r\\n                                 quoteDec  :: String -> Q [Dec] }\\r\\n}}}\\r\\n  If TH provided such parsers, you could use them to parse antiquotes.  That seems better to than having strings in the TH syntax.\\r\\n \\r\\n  See #4430 for an excellent point about fixities.\\r\\n\\r\\n * For #4372, I'm a bit agnostic.  There is no technical issue here; it's just about syntax.  Read the notes on the ticket.\\r\\n\\r\\n * See #4429 for a suggestion about reifying `Names`.\\r\\n\\r\\n------------------------------\\r\\n== Part E: Other minor issues ==\\r\\n\\r\\nThis section collects other TH changes that I think should be done.\\r\\n\\r\\n * The `InfixE` construtor of `Syntax.Exp` should only allow a `Var` in the operator position.  See Trac #4877","publish_time":1287438906,"version_time":1368720728,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"HIW2014","version":1,"title":"Haskell Implementors Workshop 2014 videos available!","body":"Without further ado, here's the [http://www.youtube.com/playlist?list=PL4UWOFngo5DW6nKDjK0UB5Oy9zmdWdo7K HIW 2014 Youtube Playlist] (kindly provided by Malcolm Wallace)","publish_time":1410191758,"version_time":1410191758,"version_comment":"","version_author":"hvr","author":"hvr","categories":""},
{"name":"simonpj/StaticPointers","version":1,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\n(11 Sept: not yet complete.)\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, he could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nThis all seems quite reasonable, but there is more ....\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define `unClo :: Closure a -> a`.\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can only see two ways out:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan b''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n\\r\\nBoth deserve more discussion.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410442463,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":2,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, he could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a typed version of `Typeable a`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\":\\r\\n{{{\\r\\ndata \\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nThis all seems quite reasonable, but there is more ....\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the '''Dict Trick''', well known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n","publish_time":1410442463,"version_time":1410450536,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":3,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, he could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nThis all seems quite reasonable, but there is more ....\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n","publish_time":1410442463,"version_time":1410450885,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":4,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nThis all seems quite reasonable, but there is more ....\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n","publish_time":1410442463,"version_time":1410472375,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":5,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in the\\r\\nlibraries [https://hackage.haskell.org/package/distributed-static\\r\\ndistributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  My\\r\\ngoal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be writeen in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410475688,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":6,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in the\\r\\nlibraries [https://hackage.haskell.org/package/distributed-static distributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  My\\r\\ngoal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be writeen in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410475788,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":7,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in the\\r\\nlibraries [https://hackage.haskell.org/package/distributed-static distributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  My\\r\\ngoal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one.  It is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\ndecomposeFun :: Typeable a => Maybe (FunTypeabe a)\\r\\n\\r\\ndata FunTypeable a where\\r\\n  FT :: (Typeable p, Typeable q) => FT (p->q)\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410475821,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":8,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in the\\r\\nlibraries [https://hackage.haskell.org/package/distributed-static distributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  My\\r\\ngoal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `TypeRep` ''must'' be implemented (and presmably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.  I'd rather avoid it.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410476662,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":9,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in the\\r\\nlibraries [https://hackage.haskell.org/package/distributed-static distributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  My\\r\\ngoal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on GdpH ==\\r\\n\\r\\nGdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410476726,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":10,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * Cloud Haskell libraries [https://hackage.haskell.org/package/distributed-static distributed-static] and\\r\\n[https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * HdpH libraries [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410510857,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":11,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp a where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410510892,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":12,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njsut a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonmys for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might adddionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can thikn of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeble a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Lookup it up in the SPT (not fount => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck becuase `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410510952,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":13,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place.\\r\\n\\r\\nNotice that a `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need\\r\\nto contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of\\r\\na `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why\\r\\nnot?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nHere we create an essentially-garbage `ByteString` by encoding a `[String]`, and\\r\\ntry to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`,\\r\\nthere is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\nInstead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the\\r\\nSPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting\\r\\n`TypeReps`.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410511188,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":14,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place. '''End of side note.'''\\r\\n\\r\\nThis design has some useful consequences that are worth calling out:\\r\\n\\r\\n * A `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need to contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of a `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why not?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\n   Here we create an essentially-garbage `ByteString` by encoding a `[String]`, and try to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`, there is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.\\r\\n\\r\\n   Instead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the SPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting`TypeReps`.\\r\\n\\r\\n * Since clients can effectively fabricate a `StaticName` (by supplying `decodeStatic` with a bogus `ByteString`, a `StaticName` is untrusted.  That gives the implementation a good deal of wiggle room for how it chooses to implement static names.  Even a simple index in the range 0..N would be type-safe!  \\r\\n\\r\\n   The motivation for choosing a richer representation for `StaticName` (eg package/module/name) is not type-safety but rather resilience to change.  For example, the Haskell programs at the two ends could be quite different, provided only that they agreed about what to call the static pointers that they want to exchange.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410511621,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":15,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place. '''End of side note.'''\\r\\n\\r\\nThis design has some useful consequences that are worth calling out:\\r\\n\\r\\n * A `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need to contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of a `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why not?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\n   Here we create an essentially-garbage `ByteString` by encoding a `[String]`, and try to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`, there is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.[[BR]][[BR]]\\r\\n   Instead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the SPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting`TypeReps`.\\r\\n\\r\\n * Since clients can effectively fabricate a `StaticName` (by supplying `decodeStatic` with a bogus `ByteString`, a `StaticName` is untrusted.  That gives the implementation a good deal of wiggle room for how it chooses to implement static names.  Even a simple index in the range 0..N would be type-safe!  \\r\\n\\r\\n   The motivation for choosing a richer representation for `StaticName` (eg package/module/name) is not type-safety but rather resilience to change.  For example, the Haskell programs at the two ends could be quite different, provided only that they agreed about what to call the static pointers that they want to exchange.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410511657,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":16,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place. '''End of side note.'''\\r\\n\\r\\nThis design has some useful consequences that are worth calling out:\\r\\n\\r\\n * A `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need to contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of a `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why not?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\n   Here we create an essentially-garbage `ByteString` by encoding a `[String]`, and try to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`, there is absolutely no reason to suppose that the `TypeRep` will describe the type of the function.[[BR]][[BR]]\\r\\n   Instead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the SPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting`TypeReps`.\\r\\n\\r\\n * Since clients can effectively fabricate a `StaticName` (by supplying `decodeStatic` with a bogus `ByteString`, a `StaticName` is untrusted.  That gives the implementation a good deal of wiggle room for how it chooses to implement static names.  Even a simple index in the range 0..N would be type-safe![[BR]][[BR]]\\r\\n   The motivation for choosing a richer representation for `StaticName` (eg package/module/name) is not type-safety but rather resilience to change.  For example, the Haskell programs at the two ends could be quite different, provided only that they agreed about what to call the static pointers that they want to exchange.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410511685,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"simonpj/StaticPointers","version":17,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also [wiki:StaticPointers].\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place. '''End of side note.'''\\r\\n\\r\\nThis design has some useful consequences that are worth calling out:\\r\\n\\r\\n * A `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need to contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of a `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why not?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\n   Here we create an essentially-garbage `ByteString` by encoding a `[String]`, and try to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`, there is absolutely no reason to suppose that the `TypeRep` will describe the type of the function. [[BR]][[BR]]\\r\\n   Instead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the SPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting`TypeReps`.\\r\\n\\r\\n * Since clients can effectively fabricate a `StaticName` (by supplying `decodeStatic` with a bogus `ByteString`, a `StaticName` is untrusted.  That gives the implementation a good deal of wiggle room for how it chooses to implement static names.  Even a simple index in the range 0..N would be type-safe! [[BR]][[BR]]\\r\\n   The motivation for choosing a richer representation for `StaticName` (eg package/module/name) is not type-safety but rather resilience to change.  For example, the Haskell programs at the two ends could be quite different, provided only that they agreed about what to call the static pointers that they want to exchange.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''ToDo: ...I have not yet followed through all the details'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1410511744,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"weekly20140915","version":1,"title":"GHC Weekly News - 2014/09/15","body":"Hi *,\\r\\n\\r\\nHere's a new thing: Blog posts! That's right. A while back, we started a new set of emails on the developers list containing weekly updates, from GHC HQ. But we eventually decided it should be more broad and encompass the work GHC sees as a project - including all the things our contributors do.\\r\\n\\r\\nSo now it's the weekly GHC news - and we (or, well, I) have decided to blogify the weekly emails!\\r\\n\\r\\nSo without further adieu, here's the current recap. The original mailing list copy is available [https://www.haskell.org/pipermail/ghc-devs/2014-September/006309.html here].\\r\\n\\r\\n - As Gabor mentioned on the list earlier today, I (Austin) accidentally broke the Windows build. Sorry. :( We really need to get Phab building Windows too ASAP... I'm working on a fix this morning.\\r\\n\\r\\n - I sent out the HCAR draft this morning. Please edit it! I think we have a few weeks of lead time however, so we're not in a rush like last time. But I will send reminders. :)\\r\\n\\r\\n - The server migration for ghc.haskell.org seems to have gone pretty smoothly in the past week. It's had plenty of traffic so far. The full migration is still ongoing and I want to complete it this week.\\r\\n\\r\\n - I've finished reorganizing some of the Git and Repository pages after some discussion. We now have the Repositories![1] page, linked to on the left side, which details some notes on the repositories we use, and links to other various pages. I'm thinking of replacing this side-bar \"root\" with a link to the main Git![2] page, perhaps.\\r\\n\\r\\n - Miscellaneous: ghc.haskell.org and phabricator.haskell.org now sets the `Strict-Transport-Security` header. This just means you always use SSL now when you visit those pages (so you can't be connection-hijacked via a 503 redirect).\\r\\n\\r\\n - I'm merging some patches at the moment, although the windows fix is currently what I'll push first: Phab:D205, Phab:D204, Phab:D203, Phab:D199, Phab:D194, Phab:D179, Phab:D174. Do let me know if there's anything you want me to look at.\\r\\n\\r\\n - GHC works on Wine apparently for all you Linux users - thanks Mikolaj!![3]\\r\\n\\r\\n - Jan had some questions about infrastructure which I just followed up on this morning. In particular: does anyone feel strongly about his first question?![4]\\r\\n\\r\\n - Herbert committed the first part of the Traversable/Foldable changes, by moving the typeclasses to Prelude. This is part of an ongoing series of patches. Things like adding Bifunctor will finally come after this.![5]\\r\\n\\r\\nAlso, added bonus: we'll start including some of the tickets we closed\\r\\nthis week.\\r\\n\\r\\nClosed tickets for the past week include: #9585, #9545, #9581, #6086, #9558, and #3658.\\r\\n\\r\\nPlease let me know if you have any questions.\\r\\n\\r\\n![1] https://ghc.haskell.org/trac/ghc/wiki/Repositories [[BR]]\\r\\n![2] https://ghc.haskell.org/trac/ghc/wiki/WorkingConventions/Git [[BR]]\\r\\n![3] https://www.haskell.org/pipermail/ghc-devs/2014-September/006283.html [[BR]]\\r\\n![4] https://www.haskell.org/pipermail/ghc-devs/2014-September/006275.html [[BR]]\\r\\n![5] https://phabricator.haskell.org/D209","publish_time":1410788849,"version_time":1410788849,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc"},
{"name":"weekly20140930","version":1,"title":"GHC Weekly News - 2014/09/30","body":"Hi *,\\r\\n\\r\\nHere's some news for y'all! Apologizes about the unavailability last week; the internet wasn't exactly a very fun place for a system administrator...\\r\\n\\r\\nSo without delay, here's the current recap of the past two weeks:\\r\\n\\r\\n - Lots of merged code and code reviews have gone in, and a lot of commits: in the past two weeks since the last update, `ghc.git` has seen just over 100 commits, from about a dozen different developers.\\r\\n\\r\\n - As part of those patches, a significant amount of them have gone towards implementing the \"Burning Bridges Proposal\" or BBP for the `base` library. This is a set of changes to `base` that have generalized many parts of the API, by putting `Traversable` and `Foldable` in the Prelude. This required a bit of shoveling by Herbert, but now this is all now in GHC HEAD, and will be part of 7.10:\\r\\n   - `Prelude` combinators, like `mapM`, have been generalized to the `Traversable` and `Foldable` classes.\\r\\n   - Several other modules, like `Control.Monad` and `Data.List`, have been generalized to `Traversable` and `Foldable` where applicable.\\r\\n   - `Control.Monad` combinators generalized to `Applicative` where possible.\\r\\n   - Similarly, `MonadPlus` combinators like `guard` are generalized to `Alternative`.\\r\\n   - `Foldable` has been extended with new methods, like `length` and `null`.\\r\\n\\r\\n - But also, GHC's compiler is now tab-free! That's right, after what seemed like a million years, a very large portion of the code has been detabbed, and `-fwarn-tabs` is now on by default in the GHC build.\\r\\n\\r\\n - There are an assortment of other changes: GHC's linker is not as loud[1], and various documentation improvements.\\r\\n\\r\\n - The windows build is broken *again* unfortunately, this time due to what seems to be a Cabal update, I think. Austin is once again on the case.\\r\\n\\r\\n - The HCAR draft for October has seen some nice improvements. If you're a developer, please amend things. If you're a user, read with eager anticipation of all the new features![2]\\r\\n\\r\\n - It turns out the new Applicative/Monad changes have unfortunately broken the `haskell98` and `haskell2010` packages, with an unclear migration strategy for the future: see #9590. For GHC 7.10, it seems the `haskell2010` packages will need to change to accomodate these standard deviations.\\r\\n If any users of the `haskell98` or `haskell2010` packages would speak up to help, that would be fantastic. The discussion will surely continue for a little bit - 7.10 is still a ways off.\\r\\n\\r\\nIn miscellaneous news:\\r\\n\\r\\n - ghc.haskell.org may have been temporarily unavailable during this weekend due to an emergency downtime with our provider for a security update, but the window was quite small.\\r\\n\\r\\n - Relatedly (but not the exact same scenario), the internet also caught fire in several other places, requiring quite a lot of careful watching and remediation after the Bash \"ShellShock\" bug hit last week.\\r\\n\\r\\nAnd I think that sums it up quite nicely, folks!\\r\\n\\r\\nClosed tickets for the past two weeks include (there are a lot of them!): #9650, #7068, #5190, #5880, #8374, #9603, #3303, #3470, #3509, #781, #8115, #9641, #9191, #9515, #9326, #7987, #9634, #9576, #9612, #9635, #8593, #7544, #8529, #9338, #5794, #9535, #3646, #617, #8026, #8480, #8881, #9366, #8251, #7673, #8983, #8369, #8897, #8070, #9550, #9057, #9629, #8836, #8960, #8941, #9565, #9589, #5248, #8918, #9568, #9620, #1042, #9557, #7863, #5647, #9610, #5395, #9580, #9529, #4426, #9607, #9592, #8097, #9559, #9560, #4218, #9602, #9528, #9530, #9423, #9400, #1407, #9598, #9597.\\r\\n\\r\\nI'd like to mention that for the above tickets, a *huge* amount of them were closed by one of our newest contributors, **Thomas Miedema**, who went through the bug tracker and confirmed or closed a large majority of them. I lost track of how many. Thanks Thomas!\\r\\n\\r\\n[1] https://github.com/ghc/ghc/commit/9f7e3633c692dce75c27607131bd386178fb0fcf\\r\\n[2] https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14","publish_time":1412107671,"version_time":1412107671,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc"},
{"name":"weekly20140930","version":2,"title":"GHC Weekly News - 2014/09/30","body":"Hi *,\\r\\n\\r\\nHere's some news for y'all! Apologizes about the unavailability last week; the internet wasn't exactly a very fun place for a system administrator...\\r\\n\\r\\nSo without delay, here's the current recap of the past two weeks:\\r\\n\\r\\n - Lots of merged code and code reviews have gone in, and a lot of commits: in the past two weeks since the last update, `ghc.git` has seen just over 100 commits, from about a dozen different developers.\\r\\n\\r\\n - As part of those patches, a significant amount of them have gone towards implementing the \"Burning Bridges Proposal\" or BBP for the `base` library. This is a set of changes to `base` that have generalized many parts of the API, by putting `Traversable` and `Foldable` in the Prelude. This required a bit of shoveling by Herbert, but now this is all now in GHC HEAD, and will be part of 7.10:\\r\\n   - `Prelude` combinators, like `mapM`, have been generalized to the `Traversable` and `Foldable` classes.\\r\\n   - Several other modules, like `Control.Monad` and `Data.List`, have been generalized to `Traversable` and `Foldable` where applicable.\\r\\n   - `Control.Monad` combinators generalized to `Applicative` where possible.\\r\\n   - Similarly, `MonadPlus` combinators like `guard` are generalized to `Alternative`.\\r\\n   - `Foldable` has been extended with new methods, like `length` and `null`.\\r\\n\\r\\n - But also, GHC's compiler is now tab-free! That's right, after what seemed like a million years, a very large portion of the code has been detabbed, and `-fwarn-tabs` is now on by default in the GHC build.\\r\\n\\r\\n - There are an assortment of other changes: GHC's linker is not as loud[1], and various documentation improvements.\\r\\n\\r\\n - The windows build is broken *again* unfortunately, this time due to what seems to be a Cabal update, I think. Austin is once again on the case.\\r\\n\\r\\n - The HCAR draft for October has seen some nice improvements. If you're a developer, please amend things. If you're a user, read with eager anticipation of all the new features![2]\\r\\n\\r\\n - It turns out the new Applicative/Monad changes have unfortunately broken the `haskell98` and `haskell2010` packages, with an unclear migration strategy for the future: see #9590. For GHC 7.10, it seems the `haskell2010` packages will need to change to accomodate these standard deviations.\\r\\n If any users of the `haskell98` or `haskell2010` packages would speak up to help, that would be fantastic. The discussion will surely continue for a little bit - 7.10 is still a ways off.\\r\\n\\r\\nIn miscellaneous news:\\r\\n\\r\\n - ghc.haskell.org may have been temporarily unavailable during this weekend due to an emergency downtime with our provider for a security update, but the window was quite small.\\r\\n\\r\\n - Relatedly (but not the exact same scenario), the internet also caught fire in several other places, requiring quite a lot of careful watching and remediation after the Bash \"ShellShock\" bug hit last week.\\r\\n\\r\\nAnd I think that sums it up quite nicely, folks!\\r\\n\\r\\nClosed tickets for the past two weeks include (there are a lot of them!): #9650, #7068, #5190, #5880, #8374, #9603, #3303, #3470, #3509, #781, #8115, #9641, #9191, #9515, #9326, #7987, #9634, #9576, #9612, #9635, #8593, #7544, #8529, #9338, #5794, #9535, #3646, #617, #8026, #8480, #8881, #9366, #8251, #7673, #8983, #8369, #8897, #8070, #9550, #9057, #9629, #8836, #8960, #8941, #9565, #9589, #5248, #8918, #9568, #9620, #1042, #9557, #7863, #5647, #9610, #5395, #9580, #9529, #4426, #9607, #9592, #8097, #9559, #9560, #4218, #9602, #9528, #9530, #9423, #9400, #1407, #9598, #9597.\\r\\n\\r\\nI'd like to mention that for the above tickets, a *huge* amount of them were closed by one of our newest contributors, **Thomas Miedema**, who went through the bug tracker and confirmed or closed a large majority of them. I lost track of how many. Thanks Thomas!\\r\\n\\r\\n[1] https://github.com/ghc/ghc/commit/9f7e3633c692dce75c27607131bd386178fb0fcf\\r\\n[2] https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14","publish_time":1412107671,"version_time":1412107710,"version_comment":"Add news category.","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20140915","version":2,"title":"GHC Weekly News - 2014/09/15","body":"Hi *,\\r\\n\\r\\nHere's a new thing: Blog posts! That's right. A while back, we started a new set of emails on the developers list containing weekly updates, from GHC HQ. But we eventually decided it should be more broad and encompass the work GHC sees as a project - including all the things our contributors do.\\r\\n\\r\\nSo now it's the weekly GHC news - and we (or, well, I) have decided to blogify the weekly emails!\\r\\n\\r\\nSo without further adieu, here's the current recap. The original mailing list copy is available [https://www.haskell.org/pipermail/ghc-devs/2014-September/006309.html here].\\r\\n\\r\\n - As Gabor mentioned on the list earlier today, I (Austin) accidentally broke the Windows build. Sorry. :( We really need to get Phab building Windows too ASAP... I'm working on a fix this morning.\\r\\n\\r\\n - I sent out the HCAR draft this morning. Please edit it! I think we have a few weeks of lead time however, so we're not in a rush like last time. But I will send reminders. :)\\r\\n\\r\\n - The server migration for ghc.haskell.org seems to have gone pretty smoothly in the past week. It's had plenty of traffic so far. The full migration is still ongoing and I want to complete it this week.\\r\\n\\r\\n - I've finished reorganizing some of the Git and Repository pages after some discussion. We now have the Repositories![1] page, linked to on the left side, which details some notes on the repositories we use, and links to other various pages. I'm thinking of replacing this side-bar \"root\" with a link to the main Git![2] page, perhaps.\\r\\n\\r\\n - Miscellaneous: ghc.haskell.org and phabricator.haskell.org now sets the `Strict-Transport-Security` header. This just means you always use SSL now when you visit those pages (so you can't be connection-hijacked via a 503 redirect).\\r\\n\\r\\n - I'm merging some patches at the moment, although the windows fix is currently what I'll push first: Phab:D205, Phab:D204, Phab:D203, Phab:D199, Phab:D194, Phab:D179, Phab:D174. Do let me know if there's anything you want me to look at.\\r\\n\\r\\n - GHC works on Wine apparently for all you Linux users - thanks Mikolaj!![3]\\r\\n\\r\\n - Jan had some questions about infrastructure which I just followed up on this morning. In particular: does anyone feel strongly about his first question?![4]\\r\\n\\r\\n - Herbert committed the first part of the Traversable/Foldable changes, by moving the typeclasses to Prelude. This is part of an ongoing series of patches. Things like adding Bifunctor will finally come after this.![5]\\r\\n\\r\\nAlso, added bonus: we'll start including some of the tickets we closed\\r\\nthis week.\\r\\n\\r\\nClosed tickets for the past week include: #9585, #9545, #9581, #6086, #9558, and #3658.\\r\\n\\r\\nPlease let me know if you have any questions.\\r\\n\\r\\n![1] https://ghc.haskell.org/trac/ghc/wiki/Repositories [[BR]]\\r\\n![2] https://ghc.haskell.org/trac/ghc/wiki/WorkingConventions/Git [[BR]]\\r\\n![3] https://www.haskell.org/pipermail/ghc-devs/2014-September/006283.html [[BR]]\\r\\n![4] https://www.haskell.org/pipermail/ghc-devs/2014-September/006275.html [[BR]]\\r\\n![5] https://phabricator.haskell.org/D209","publish_time":1410788849,"version_time":1412107792,"version_comment":"Add news category.","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20140930","version":3,"title":"GHC Weekly News - 2014/09/30","body":"Hi *,\\r\\n\\r\\nHere's some news for y'all! Apologizes about the unavailability last week; the internet wasn't exactly a very fun place for a system administrator...\\r\\n\\r\\nSo without delay, here's the current recap of the past two weeks:\\r\\n\\r\\n - Lots of merged code and code reviews have gone in, and a lot of commits: in the past two weeks since the last update, `ghc.git` has seen just over 100 commits, from about a dozen different developers.\\r\\n\\r\\n - As part of those patches, a significant amount of them have gone towards implementing the \"Burning Bridges Proposal\" or BBP for the `base` library. This is a set of changes to `base` that have generalized many parts of the API, by putting `Traversable` and `Foldable` in the Prelude. This required a bit of shoveling by Herbert, but now this is all in GHC HEAD, and will be part of 7.10:\\r\\n   - `Prelude` combinators, like `mapM`, have been generalized to the `Traversable` and `Foldable` classes.\\r\\n   - Several other modules, like `Control.Monad` and `Data.List`, have been generalized to `Traversable` and `Foldable` where applicable.\\r\\n   - `Control.Monad` combinators generalized to `Applicative` where possible.\\r\\n   - Similarly, `MonadPlus` combinators like `guard` are generalized to `Alternative`.\\r\\n   - `Foldable` has been extended with new methods, like `length` and `null`.\\r\\n\\r\\n - But also, GHC's compiler is now tab-free! That's right, after what seemed like a million years, a very large portion of the code has been detabbed, and `-fwarn-tabs` is now on by default in the GHC build.\\r\\n\\r\\n - There are an assortment of other changes: GHC's linker is not as loud![1], and various documentation improvements.\\r\\n\\r\\n - The windows build is broken *again* unfortunately, this time due to what seems to be a Cabal update, I think. Austin is once again on the case.\\r\\n\\r\\n - The HCAR draft for October has seen some nice improvements. If you're a developer, please amend things. If you're a user, read with eager anticipation of all the new features!![2]\\r\\n\\r\\n - It turns out the new Applicative/Monad changes have unfortunately broken the `haskell98` and `haskell2010` packages, with an unclear migration strategy for the future: see #9590. For GHC 7.10, it seems the `haskell2010` packages will need to change to accomodate these standard deviations.\\r\\n If any users of the `haskell98` or `haskell2010` packages would speak up to help, that would be fantastic. The discussion will surely continue for a little bit - 7.10 is still a ways off.\\r\\n\\r\\nIn miscellaneous news:\\r\\n\\r\\n - ghc.haskell.org may have been temporarily unavailable during this weekend due to an emergency downtime with our provider for a security update, but the window was quite small.\\r\\n\\r\\n - Relatedly (but not the exact same scenario), the internet also caught fire in several other places, requiring quite a lot of careful watching and remediation after the Bash \"ShellShock\" bug hit last week.\\r\\n\\r\\nAnd I think that sums it up quite nicely, folks!\\r\\n\\r\\nClosed tickets for the past two weeks include (there are a lot of them!): #9650, #7068, #5190, #5880, #8374, #9603, #3303, #3470, #3509, #781, #8115, #9641, #9191, #9515, #9326, #7987, #9634, #9576, #9612, #9635, #8593, #7544, #8529, #9338, #5794, #9535, #3646, #617, #8026, #8480, #8881, #9366, #8251, #7673, #8983, #8369, #8897, #8070, #9550, #9057, #9629, #8836, #8960, #8941, #9565, #9589, #5248, #8918, #9568, #9620, #1042, #9557, #7863, #5647, #9610, #5395, #9580, #9529, #4426, #9607, #9592, #8097, #9559, #9560, #4218, #9602, #9528, #9530, #9423, #9400, #1407, #9598, #9597.\\r\\n\\r\\nI'd like to mention that for the above tickets, a *huge* amount of them were closed by one of our newest contributors, **Thomas Miedema**, who went through the bug tracker and confirmed or closed a large majority of them. I lost track of how many. Thanks Thomas!\\r\\n\\r\\n![1] https://github.com/ghc/ghc/commit/9f7e3633c692dce75c27607131bd386178fb0fcf [[BR]]\\r\\n![2] https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14","publish_time":1412107671,"version_time":1412108917,"version_comment":"","version_author":"MikolajKonarski","author":"thoughtpolice","categories":"ghc news"},
{"name":"simonpj/StaticPointers","version":18,"title":"Static pointers and serialisation","body":"This longish post gives Simon's reflections on the implementation of Cloud-Haskell-style static pointers and serialiation.  See also\\r\\n * [wiki:StaticPointers]\\r\\n * [wiki:Typeable]\\r\\n\\r\\nMuch of what is suggested here is implemented, in some form, in two existing projects\\r\\n * '''Cloud Haskell libraries''' [https://hackage.haskell.org/package/distributed-static distributed-static] and [https://hackage.haskell.org/package/rank1dynamic rank1dynamic].  Background in the paper [http://research.microsoft.com/en-us/um/people/simonpj/papers/parallel/ Towards Haskell in the Cloud].\\r\\n\\r\\n * '''HdpH libraries''' [https://hackage.haskell.org/package/hdph hdph] and [https://hackage.haskell.org/package/hdph-closure hdph-closure]. Background in the paper [http://www.dcs.gla.ac.uk/~pmaier/papers/Maier_Trinder_IFL2011_XT.pdf Implementing a high-level distributed-memory parallel Haskell in Haskell]\\r\\n\\r\\nMy goal here is to identify the smallest possible extension to GHC, with\\r\\nthe smallest possible trusted code base, that would enable these\\r\\nlibraries to be written in an entirely type-safe way.\\r\\n\\r\\n-----------------------------\\r\\n= Background =\\r\\n\\r\\n== Background: the trusted code base ==\\r\\n\\r\\nThe implementation `Typeable` class, and its associated functions, in\\r\\nGHC offers a '''type-safe''' abstraction, in the classic sense that\\r\\n\"well typed programs won't go wrong\".  For example, we in `Data.Typeable` we have\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\n}}}\\r\\nWe expect `cast` to be type-safe: if `cast` returns a value `Just x` then we really do know\\r\\nthat `x :: b`.  Let's remind ourselves of class `Typeable`:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n}}}\\r\\n(It's not ''quite'' this, but close.)  The `proxy a` argument is\\r\\njust a proxy for ''type'' argument; its value is never inspected\\r\\nand you can always pass bottom.\\r\\n\\r\\nUnder the hood, `cast` uses `typeRep` to get the runtime `TypeRep` for\\r\\n`a` and `b`, and compares them, thus:\\r\\n{{{\\r\\ncast :: forall a b. (Typeable a, Typeable b) => a -> Maybe b\\r\\ncast x = if typeRep (Proxy :: Proxy a) == typeRep (Proxy :: Proxy b)\\r\\n           then Just (unsafeCoerce x)\\r\\n           else Nothing\\r\\n}}}\\r\\nAlthough `cast` is written in Haskell, it uses `unsafeCoerce`.  For it\\r\\nto truly be type-safe, it must trust the `Typeable` instances.  If the\\r\\nuser could write a `Typeable` instance, they could write a bogus one, and\\r\\ndefeat type safety.  So only GHC is allowed write `Typeable` instances.\\r\\n\\r\\nIn short, `cast` and the `Typeable` instances are part of the '''trusted code base''', or '''TCB''':\\r\\n * The TCB should be as small as possible\\r\\n * The TCB should have a small, well-defined, statically-typed API used by client code\\r\\n * Client code is un-trusted; if the client code is well-typed, and the TCB is implemented correctly, nothing can go wrong\\r\\n\\r\\n== Background `Typeable a` and `TypeRep` ==\\r\\n\\r\\nI'll use the `Typeable a` type class and values of type `TypeRep` more or less interchangeably. As you can see from the definition of class `Typeable` above, its payload is simply a constant function returning a `TypeRep`.  So you can think of a `Typeable a` as simply a type-tagged version of `TypeRep`.\\r\\n\\r\\nOf course, a `Typeable a` is a type class thing, which is hard to pass around explicitly like a value, but that is easily fixed using the \"Dict Trick\",\\r\\nwell known in Haskell folk lore:\\r\\n{{{\\r\\ndata Dict (c :: Constraint) where\\r\\n  Dict :: forall c. c => Dict c\\r\\n}}}\\r\\nNow a value of type `Dict (Typeable a)` is an ordinary value that embodies a `Typeable a` dictionary.  For example:\\r\\n{{{\\r\\nf :: Dict (Typeable a) -> Dict (Typeable b) -> a -> Maybe b\\r\\nf Dict Dict val = cast val\\r\\n}}}\\r\\nThe pattern-matches against the `Dict` constructor brings the `Typeable` dictionaries\\r\\ninto scope, so they can be used to discharge the constraint arising from the call to `cast`.\\r\\n\\r\\n== Background: serialisation ==\\r\\n\\r\\nI'm going to assume a a type class `Serialisable`, something like this:\\r\\n{{{\\r\\nclass Serialisable a where\\r\\n  encode :: a -> ByteString\\r\\n  decode :: ByteString -> Maybe (a, ByteString)\\r\\n}}}\\r\\n'll use \"encode\" and \"decode\" as synonyms for \"serialise\" and \"deserialise\", because the former are easier to pronounce.\\r\\n\\r\\nHere's an interesting question: are instances of `Serialisable` part of the TCB?  No, they are not.\\r\\nHere is a tricky case:\\r\\n{{{\\r\\n  decode (encode [True,False]) :: Maybe (Int, ByteString)\\r\\n}}}\\r\\nHere I have encode a `[Bool]` into a `ByteString`, and then decoded an `Int` from that `ByteString`.  This may\\r\\nbe naughty or undesirable, but it cannot seg-fault: it is type-safe in the sense above.   You can\\r\\nthink of it like this: a decoder is simply a parser for the bits in the `ByteString`, so a decoder\\r\\nfor (say) `Int` can fail to parse a full `Int` (returning `Nothing`), but it can't return a non-`Int`.\\r\\n\\r\\nFor the naughtiness, one could imagine that a Cloud Haskell library\\r\\nmight send fingerprints or `TypeReps` or whatnot to eliminate\\r\\npotential naughtiness. But even then it is very valuable if the\\r\\ntype-safety of the system does not rely on the CH library.  Type\\r\\nsafety depends only on the correctness of the (small) TCB;\\r\\nnaughtiness-safety might additionally depend on the correctness of the\\r\\nCH library.\\r\\n   \\r\\n== Background: static pointers ==\\r\\n\\r\\nI'm taking for granted the basic design of the Cloud Haskell paper.\\r\\nThat is,\\r\\n\\r\\n * A type constructor `StaticPtr :: * -> *`. Intuitively, a value of type `StaticPtr t` is represented by a static code pointer to a value of type `t`.  Note \"code pointer\" not \"heap pointer\".  That's the point!\\r\\n\\r\\n * A language construct `static <expr>`, whose type is `StaticPtr t` if `<expr>` has type `t`.  \\r\\n\\r\\n * In `static <expr>`, the free variables of `<expr>` must all be bound at top level. The implementation almost certainly works by giving `<expr>` a top-level definition with a new name, `static34 = <expr>`.\\r\\n\\r\\n * A function `unStatic :: StaticPtr a -> a`, to unwrap a static pointer.\\r\\n\\r\\n * `Static` values are serialisable.  Something like `instance Serialisable (StaticPtr a)`.  (This will turn out to be not quite right.)  Operationally this works by serialising the code pointer, or top-level name (e.g `\"Foo.static34\"`).\\r\\n\\r\\nAll of this is built-in.  It is OK for the implementation of `StaticPtr` to be part of the TCB.\\r\\nBut our goal is that ''no other code need be in the TCB''.\\r\\n\\r\\n'''A red herring'''.  I'm not going to address the question of how to serialise a static pointer.  One method would be to serialise a machine address, but that only works if the encoding and decoding ends are running identical binaries.  But that's easily fixed: encode a static as the ''name'' of the static value e.g. \"function `foo` from module `M` in package `p`\".  Indeed, I'll informally assume an implementation of this latter kind.\\r\\n\\r\\nIn general, I will say that what we ultimately serialise is a `StaticName`. You can think of a `StaticName` as package/module/function triple, or something like that. The implementation of `StaticName` is certainly not part of the client-visible API for `StaticPtr`; indeed, the type `StaticName` is not part of the API either.  But it gives us useful vocabulary.\\r\\n\\r\\n-------------------------------------\\r\\n= Serialising static pointers =\\r\\n\\r\\nWe can see immediately that we cannot expect to have `instance Serialisable (Static a)`,\\r\\nwhich is what the Cloud Haskell paper proposed.  If we had such an instance we would have\\r\\n{{{\\r\\nencodeStatic :: forall a. StaticPtr a -> ByteString\\r\\ndecodeStatic :: forall a. ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nAnd it's immediately apparent that `decodeStatic` ''cannot'' be right. \\r\\nI could get a `ByteString` from anywhere, apply `decodeStatic` to it,\\r\\nand thereby get a `StaticPtr a`.  Then use\\r\\n`unStatic` and you have a value of type `a`, for, ''for any type `a`''!!\\r\\n\\r\\nPlainly, what we need is (just in the case of `cast`) to do a dynamic typecheck, thus:\\r\\n{{{\\r\\ndecodeStatic :: forall a. Typeable a \\r\\n                       => ByteString -> Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\nLet's think operationally for a moment:\\r\\n\\r\\n * GHC collects all the `StaticPtr` values in a table, the '''static pointer table''' or '''SPT'''.  Each row contains\\r\\n   * The `StaticName` of the value\\r\\n   * A pointer to closure for the value itself\\r\\n   * A pointer to its `TypeRep`\\r\\n\\r\\n * `decodeStatic` now proceeds like this:\\r\\n    * Parse a `StaticName` from the `ByteString` (failure => `Nothing`)\\r\\n    * Look it up in table (not found => `Nothing`)\\r\\n    * Compare the `TypeRep` passed to `decodeStatic` (via the `Typeable a` dictionary) with the one ine the table (not equal => `Nothing`)\\r\\n    * Return the value\\r\\n\\r\\n'''Side note.''' Another possibility is for `decodeStatic` not to take a `Typeable a` context but instead for `unStatic` to do so:: `unStatic :: Typeable a => StaticPtr a -> Maybe a`.  But that seems a mess.  Apart from anything else, it would mean that a value of type `StaticPtr a` might or might not point to a value of type `a`, so there's no point in having the type parameter in the first place. '''End of side note.'''\\r\\n\\r\\nThis design has some useful consequences that are worth calling out:\\r\\n\\r\\n * A `StaticPtr` is serialised simply to the `StaticName`; ''the serialised form does not need to contain a `TypeRep`''.  Indeed it would not even be type-safe to serialise a `StaticPtr` to a pair of a `StaticName` and a `TypeRep`, trusting that the `TypeRep` described the type of the named function. Why not?  Think back to \"Background: serialisation\" above, and imagine we said\\r\\n{{{\\r\\ndecode (encode [\"wibble\", \"wobble\"]) \\r\\n  :: Typeable a => Maybe (StaticPtr a, ByteString)\\r\\n}}}\\r\\n   Here we create an essentially-garbage `ByteString` by encoding a `[String]`, and try to decode it.  If, by chance, we successfully parse a valid `StaticName` and `TypeRep`, there is absolutely no reason to suppose that the `TypeRep` will describe the type of the function. [[BR]][[BR]]\\r\\n   Instead, the `TypeRep` of the static pointer lives in the SPT, securely put there when the SPT was created.  Not only is this type-safe, but it also saves bandwidth by not transmitting`TypeReps`.\\r\\n\\r\\n * Since clients can effectively fabricate a `StaticName` (by supplying `decodeStatic` with a bogus `ByteString`, a `StaticName` is untrusted.  That gives the implementation a good deal of wiggle room for how it chooses to implement static names.  Even a simple index in the range 0..N would be type-safe! [[BR]][[BR]]\\r\\n   The motivation for choosing a richer representation for `StaticName` (eg package/module/name) is not type-safety but rather resilience to change.  For example, the Haskell programs at the two ends could be quite different, provided only that they agreed about what to call the static pointers that they want to exchange.\\r\\n\\r\\n== Statics and existentials ==\\r\\n\\r\\nHere is something very reasonable:\\r\\n{{{\\r\\ndata StaticApp b where\\r\\n  SA :: StaticPtr (a->b) -> StaticPtr a -> StaticApp b\\r\\n\\r\\nunStaticApp :: StaticApp a -> a\\r\\nunStaticApp (SA f a) = unStatic f (unStatic a)\\r\\n}}}\\r\\n(We might want to add more constructors, but I'm going to focus only on `SA`.)\\r\\nA `SA` is just a pair of `StaticPtr`s, one for a function and one for an argument.  We can securely unwrap it with `unStaticApp`.\\r\\n\\r\\nNow, here is the question: can we serialise `StaticApp`s?  Operationally, of course yes: to serialise a `SA`, just serialise the two `StaticPtrs` it contains, and dually for deserialisation.   But, as before, deserialisation is the hard bit.  We seek:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\n}}}\\r\\nBut how can we write `decodeSA`?  Here is the beginning of an attempt:\\r\\n{{{\\r\\ndecodeSA :: Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = case decodeStatic bs :: Maybe (StaticPtr (a->b)) of\\r\\n      Nothing -> Nothing\\r\\n      Just (fun, bs1) -> ...\\r\\n}}}\\r\\nand you can immediately see that we are stuck.  Type variable `b` is not in scope.\\r\\nMore concretely, we need a `Typeable (a->b)` to pass in to `decodeStatic`, \\r\\nbut we only have a `Typeable b` to hand.  \\r\\n\\r\\nWhat can we do?  Tantalisingly, we know that if `decodeStatic` succeeds in parsing a static `StaticName` from `bs` then, when we look up that `StaticName` in the Static Pointer Table, we'll find a `TypeRep` for the value.  So rather than passing a `Typeable` dictionary into `decodeStatic`, we'd like to get one out!\\r\\n\\r\\nWith that in mind, here is a new type signature for `decodeStatic` that returns\\r\\nboth pieces:\\r\\n{{{\\r\\ndata DynStaticPtr where\\r\\n  DSP :: Typeable a => StaticPtr a -> DynStaticPtr\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n}}}\\r\\n(The name `DynStaticPtr` comes from the fact that this data type is extremely similar to the library definition of `Dynamic`.)\\r\\n\\r\\nOperationally, `decodeStaticK bs fail cont` works like this;\\r\\n * Parse a `StaticName` from `bs` (failure => return Nothing)\\r\\n * Look it up in the SPT (not found => return Nothing)\\r\\n * Return the `TypeRep` and  the value found in the SPT, paired up with `DSP`. (Indeed the SPT could contain the `DynStaticPtr` values directly.)\\r\\n\\r\\nFor the construction of `DynStaticPtr` to be type-safe, we need to know that the\\r\\n`TypeRep` passed really is a `TypeRep` for the value; so the construction\\r\\nof the SPT is (unsurprisingly) part of the TCB.\\r\\n\\r\\nNow we can write `decodeSA` (the monad is just the `Maybe` monad, nothing fancy):\\r\\n{{{\\r\\ndecodeSA :: forall b. Typeable b => ByteString -> Maybe (StaticApp b, ByteString)\\r\\ndecodeSA bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (DSP (arg :: StaticPtr targ), bs2) <- decodeStatic bs1\\r\\n            -- At this point we have \\r\\n            --     Typeable b      (from caller)\\r\\n            --     Typeable tfun   (from first DSP)\\r\\n            --     Typeable targ   (from second DSP)\\r\\n       ; fun' :: StaticPtr (targ->b) <- cast fun   \\r\\n       ; return (SA fun' arg, bs2) }\\r\\n}}}\\r\\nThe call to `cast` needs `Typeable tfun`, and `Typeable (targ->b)`. The\\r\\nformer is bound by the first `DSP` pattern match.  The latter is\\r\\nconstructed automatically from `Typeable targ` and `Typeable b`, both\\r\\nof which we have.  Bingo!\\r\\n\\r\\nNotice that ''`decodeSA` is not part of the TCB''.  Clients can freely write code like `decodeSA` and be sure that it is type-safe.\\r\\n\\r\\n----------------------------\\r\\n= From static pointers to closures =\\r\\n\\r\\nThe original Cloud Haskell paper defines closures like this:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> ByteString -> Closure a\\r\\n}}}\\r\\nIt is easy to define\\r\\n{{{\\r\\nunClo :: Closure a -> a\\r\\nunClo (Clo s e) = unStatic s e\\r\\n}}}\\r\\n\\r\\n== Side note on HdpH ==\\r\\n\\r\\nHdpH refines the Cloud Haskell `Closure` in (at least) two ways.   I think (but I am not certain) that this declaration captures the essence:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString -> a) -> Put () -> a -> Closure a\\r\\n}}}\\r\\nThe refinements are:\\r\\n * The extra argument of type 'a' to avoid costs when we build a closure and then unwrap it with `unClo` locally, or repeatedly.\\r\\n\\r\\n * The use of `Put ()` rather than a `ByteString` for the serialised environment, to avoid repeated copying when doing nested serialisation.\\r\\n\\r\\nBoth are importnat, but they are orthogonal to the discussion about static types, so I'll use the CH definition from here on.\\r\\n\\r\\n== Serialising closures ==\\r\\n\\r\\nJust as in the case of `StaticPtr`, it is immediately clear that we\\r\\ncannot expect to have\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (Closure a, ByteString)\\r\\n}}}\\r\\nInstead we must play the same trick, and attempt to define\\r\\n{{{\\r\\ndata DynClosure where\\r\\n  DC :: Typeable a => Closure a -> DynClosure\\r\\n\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\n}}}\\r\\nBut there's an immediate problem in writing `decodeClo`:\\r\\n{{{\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr tfun), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                         <- decodeByteString bs1\\r\\n       ; return (DC (Clo fun env), bs2) }  -- WRONG\\r\\n}}}\\r\\nThis won't typecheck because `DC` needs `Typeable `a`, but we only have `Typeable (ByteString -> a)`.\\r\\n\\r\\nThis is Jolly Annoying.  I can see three ways to make progress:\\r\\n * '''Plan A''': Provide some (type-safe) way to decompose `TypeReps`, to get from `Typeable (a->b)` to `Typeable b` (and presumably `Typeable a` as well).\\r\\n * '''Plan C''': Serialise a `TypeRep a` with every `Closure a`.\\r\\n * '''Plan C''': Generalise `StaticPtr`\\r\\n\\r\\nI like Plan C best.  They are each discussed next.\\r\\n\\r\\n=== Plan A: Decomposing `TypeRep` ===\\r\\n\\r\\nAt the moment, GHC provides statically-typed ways to ''construct'' and ''compare'' a `TypeRep` (via `cast`), but no way to ''decompose'' one, at least not in a type-safe way.  \\r\\nIt is tempting to seek this function as part of the TCB:\\r\\n{{{\\r\\nclass Typeable a where\\r\\n  typeRep :: proxy a -> TypeRep\\r\\n  decomposeTypeRep :: DecompTR a\\r\\n\\r\\ndata DecompTR a where\\r\\n  TRApp :: (Typeable p, Typeable q) => DecompTR (p q)\\r\\n  TRCon :: TyCon -> DecompTR a\\r\\n}}}\\r\\nThis isn't a bad idea, but it does mean that `Typeable a` ''must'' be implemented (and presumably serialised) using a tree, whereas the current API would allow an implementation consisting only of a fingerprint.\\r\\n\\r\\n(Oct 2014) I now think that Plan A is the right path.  See [wiki:Typeable] for a design of `Typeable` that properly supports it.\\r\\n\\r\\n(Thought experiment: maybe a `Typeable a`, and `Dict (Typeable a)` can be represented as a tree, but a `TypeRep` could be just a fingerprint?)\\r\\n\\r\\n=== Plan B: serialise `TypeRep` with `Closure` ===\\r\\n\\r\\nSince we need a `Typeable a` at the far end, we could just serialise it directly\\r\\nwith the `Closure`, like this:\\r\\n{{{\\r\\nencodeClo :: forall a. Typeable a => Closure a -> ByteString\\r\\nencodeClo (Clo fun env) \\r\\n  =  encodeTypeable (proxy :: a)\\r\\n  ++ encodeStatic fun\\r\\n  ++ encodeByteString env\\r\\n}}}\\r\\nHere I am assuming (as part of the TBC)\\r\\n{{{\\r\\nencodeTypeable :: Typeable a => proxy a -> ByteString\\r\\ndecodeTypeable :: ByteString -> Maybe (DynTypeable, ByteString)\\r\\n\\r\\ndata DynTypeable where\\r\\n  DT :: Typeable a => proxy a -> DynTypeable\\r\\n}}}\\r\\nwhich serialises a `TypeRep`.  (Or, operationally, perhaps just its fingerprint.)\\r\\nNow I think we can write `decodeClo`:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DT (_ :: Proxy a),           bs1)  <- decodeTypeable\\r\\n       ; (DSP (fun :: StaticPtr tfun), bs2)  <- decodeStatic bs1\\r\\n       ; (env, bs3)                          <- decodeByteString bs2\\r\\n       ; fun' :: StaticPtr (ByteString -> a) <- cast fun\\r\\n       ; return (DC (Clo fun' env), bs2) }  -- WRONG\\r\\n}}}\\r\\nBut this too is annoying: we have to send these extra `TypeRep`s when morally they are already sitting there in the SPT.\\r\\n\\r\\n=== Plan C: Generalising `StaticPtr` ===\\r\\n\\r\\nOur difficulty is that we are deserialising `StaticPtr (ByteString -> a)` but we want to be given `Typeable a` not `Typeable (ByteString -> a)`.  So perhaps we can decompose the type into a type constructor and type argument, like this:\\r\\n{{{\\r\\ndata StaticPtr (f :: *->*) (a :: *)\\r\\n\\r\\nunStatic :: StaticPtr f a -> f a\\r\\n\\r\\ndecodeStatic :: ByteString -> Maybe (DynStaticPtr, ByteString)\\r\\n\\r\\ndata DynStaticPtr where\\r\\n  DS :: (Typeable f, Typeable a) => StaticPtr (f a) -> DynStaticPtr\\r\\n}}}\\r\\nEach row of the SPT contains:\\r\\n * The `StaticName`\\r\\n * The value of type `f a`\\r\\n * The `Typeable f` dictionary\\r\\n * The `Typeable a` dictionary\\r\\n\\r\\nNow we can define closures thus:\\r\\n{{{\\r\\ndata Closure a where\\r\\n  Clo :: StaticPtr (ByteString ->) a -> ByteString -> Closure a\\r\\n}}}\\r\\nand these are easy to deserialise:\\r\\n{{{\\r\\ndecodeClo :: ByteString -> Maybe (DynClosure, ByteString)\\r\\ndecodeClo bs\\r\\n  = do { (DSP (fun :: StaticPtr f a), bs1) <- decodeStatic bs\\r\\n       ; (env, bs2)                        <- decodeByteString bs1\\r\\n           -- Here we have Typeable f, Typeable a\\r\\n\\r\\n       ; fun' :: StaticPtr (ByteString ->) a <- cast fun\\r\\n           -- This cast checks that f ~ (ByteString ->)\\r\\n           -- Needs Typeable f, Typealbe (ByteString ->)\\r\\n\\r\\n       ; return (DC (Clo fun env), bs2) } \\r\\n           -- DC needs Typeable a\\r\\n}}}\\r\\n\\r\\nI like this a lot better, but it has knock on effects.  \\r\\n\\r\\n * The old `StaticPtr a` is now `StaticPtr Id a`.\\r\\n\\r\\n * What becomes of our data type for `StaticApply`?   Perhpas\\r\\n{{{\\r\\ndata StaticApp f b where\\r\\n  SA :: StaticPtr f (a->b) -> StaticPtr f b -> StaticApp f b\\r\\n\\r\\nunStaticApp :: Applicative => StaticApp f b -> f b\\r\\n}}} \\r\\n\\r\\n'''Bottom line: I have not yet followed through all the details, and I think Plan A is better'''\\r\\n\\r\\n== Applying closures ==\\r\\n\\r\\nCan we write `closureApply`?  I'm hoping for a structure like this:\\r\\n{{{\\r\\nclosureApply :: Closure (a->b) -> Closure a -> Closure b\\r\\nclosureApply fun arg = Clo (static caStatic) (fun, arg)\\r\\n\\r\\ncaStatic :: ByteString -> b  -- WRONG\\r\\ncaStatic bs = do { ((fun,arg), bs1) <- decode bs\\r\\n                 ; return (unClo fun (unClo arg), bs1) }\\r\\n}}}\\r\\nThis is obviously wrong. `caStatic` clearly cannot have that type.  It would\\r\\nat least need to be\\r\\n{{{\\r\\ncaStatic :: Typeable b => ByteString -> b\\r\\n}}}\\r\\nand now there is the thorny question of where the `Typeable b` dictionary comes from.\\r\\n\\r\\n'''ToDo: ...I have stopped here for now'''\\r\\n\\r\\n---------------------------------------\\r\\n= Polymorphism and serialisation =\\r\\n\\r\\nFor this section I'll revert to the un-generalised single-parameter `StaticPtr`.\\r\\n\\r\\n== Parametric polymorphism ==\\r\\n\\r\\nConsider these definitions:\\r\\n{{{\\r\\nrs1 :: Static ([Int] -> [Int])\\r\\nrs1 = static reverse\\r\\n\\r\\nrs2 :: Static ([Bool] -> [Bool])\\r\\nrs2 = static reverse\\r\\n\\r\\nrs3 :: forall a. Typeable a => Static ([a] -> [a])\\r\\nrs3 = static reverse\\r\\n}}}\\r\\n\\r\\nThe first two are clearly fine. The SPT will get one row for each of the two monomorphic calls to reverse, one with a `TypeRep` of `[Int] -> [Int]` and one with a `TypeRep` of `[Bool] -> [Bool]`.\\r\\n\\r\\nBut ''both will have the same code pointer'', namely the code for the polymorpic `reverse` function.  Could we share just one `StaticName` for all instantiations of `reverse`, perhaps including `rs3` as well?\\r\\n\\r\\nI think we can.  The story would be this:\\r\\n\\r\\n * The SPT has a row for `reverse`, containing\\r\\n   * The `StaticName` for `reverse`\\r\\n   * A pointer to the code for `reverse` (or, more precisely, its static closure).\\r\\n   * A function of type `TypeRep -> TypeRep` that, given the `TypeRep` for `a` returns a `TypeRep` for `[a] -> [a]`.\\r\\n\\r\\n * When we serialise a `StaticPtr` we send \\r\\n   * The `StaticName` of the (polymorphic) function\\r\\n   * A list of the `TypeRep`s of the type arguments of the function\\r\\n\\r\\n * The rule for `static <expr>` becomes this: the free ''term'' variables `<expr>` must all be top level, but it may have free ''type'' variables, provided they are all `Typeable`.\\r\\n\\r\\nAll of this is part of the TCB, of course.\\r\\n\\r\\n== Type-class polymorphism ==\\r\\n\\r\\nConsider `static sort` where `sort :: Ord a => [a] -> [a]`.  Can we make such a `StaticPtr`.  After all, `sort` gets an implicit value argument, namely an `Ord a` dictionary.  If that dictionary can be defined at top level, well and good, so this should be OK:\\r\\n{{{\\r\\nss1 :: StaticPtr ([Int] -> [Int])\\r\\nss1 = static sort\\r\\n}}}\\r\\nBut things go wrong as soon as you have polymorphism:\\r\\n{{{\\r\\nss2 :: forall a. Ord a => StaticPtr ([a] -> [a])\\r\\nss2 = static sort  -- WRONG\\r\\n}}}\\r\\nNow, clearly, the dictionary is a non-top-level free variable of the call to `sort`.\\r\\n\\r\\nWe might consider letting you write this:\\r\\n{{{\\r\\nss3 :: forall a. StaticPtr (Ord a => [a] -> [a])\\r\\nss3 = static sort   -- ???\\r\\n}}}\\r\\nso now the `static` wraps a function expeting a dictionary.  But that edges us uncomforatbly close to impredicative types, which is known to contain many dragons.\\r\\n\\r\\nA simpler alternative is to use the Dict Trick (see Background above):\\r\\n{{{\\r\\nss4 :: forall a. StaticPtr (Dict (Ord a) -> [a] -> [a])\\r\\nss4 = static sortD\\r\\n\\r\\nsortD :: forall a. Dict (Ord a) -> [a] -> [a]\\r\\nsortD Dict xs = sort xs\\r\\n}}}\\r\\nNow, at the call side, when we unwrap the `StaticPtr`, we need to supply an explicit `Ord` dictionary, like this:\\r\\n{{{\\r\\n...(unStatic ss4 Dict)....\\r\\n}}}\\r\\nFor now, I propose to deal with type classes via the Dict Trick, which is entirely end-user programmable, leaving only parametric polymorphism for built-in support.\\r\\n\\r\\n","publish_time":1410442463,"version_time":1412678605,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"weekly20141020","version":1,"title":"GHC Weekly News - 2014/10/20","body":"Hi *,\\r\\n\\r\\nIt's been a few weeks since the last message - and I apologize! We actually are changing the posting time to be **Friday** now, so hopefully this situation will be corrected preeeeetty quickly from this point forward, and hopefully will give better context over the course of a weekly discussion.\\r\\n\\r\\nThat said, let's begin!\\r\\n\\r\\n - We've seen plenty of changes to GHC itself in the past few weeks. Some of the highlights include:\\r\\n   - Some changes to help make `Prelude` combinators fuse better. David Feuer has been leading a lot of this work, and it's been quite fruitful, with several new things now fusing (like `takeWhile`, `scanl`, `scanr`, and `mapAccumL`.\\r\\n   - Relatedly, `Data.List.Inits` should be far faster thanks to David Feuer (ref: Phab:D329).\\r\\n   - The testsuite driver now has preliminary support for Python 3 - which should be useful for platforms out there that sport it, and ones that will use it as the default eventually (such as Fedora 22, possibly).\\r\\n   - Some of the initial work by Edward Yang to remove `HEAP_ALLOCED` from the GHC runtime system has landed. Briefly, `HEAP_ALLOCED` is a check the RTS uses to determine if some address is part of the dynamic heap - but the check is a bit costly. Edward's full patchset hopes to remove this with an 8% speedup or so on average.\\r\\n   - GHC now has a new macro, `__GLASGOW_HASKELL_PATCHLEVEL__`, which will allow you to determine the point-level release of the GHC you're using. This has been a requested feature in the past we were a little hesitant of adding, but Herbert went through and did it for us. (Ref: Phab:D66)\\r\\n   - Template Haskell now supports `LINE` pragmas, thanks to Eric Mertens (ref: Phab:D299).\\r\\n   - Sergei Trofimovich revived `libbfd` debugging support for the runtime system linker, which should be of use to several daring souls out there (ref: Phab:D193).\\r\\n   - Several patches from Gintautas Miliauskas has improved the usability of msys and the testsuite on Windows - and he's not done yet!\\r\\n   - A few improvements to the x86 code generator were committed by Reid Barton and Herbert Valerio Riedel, improving size/space for certain cases (ref: Phab:D320, Phab:D163).\\r\\n and more besides that, including some linker improvements, and general cleanups as usual.\\r\\n\\r\\n - The mailing list has been busy (as usual), with some discussions including:\\r\\n   - Austin posted some discussion about the tentative 7.10.1 plans - we're still hoping these are accurate, so take note! **We hope to freeze mid-November, and release Feburary 2015**! [1]\\r\\n   - Austin also called for some feedback: GHC HQ has become convinced a 7.8.4 release is needed to fix some showstoppers - so please let him know soon if you're totally incapable of using 7.8 for something! [2]\\r\\n   - Alan Zimmerman has asked for some feedback on his proposed \"AST Annotations\", which will hopefully allow GHC API clients to add richer annotations to GHC's syntactic representations. The motivation is for refactoring tools like HaRe - and I'm sure all input would be appreciated. [3]\\r\\n   - Chris done sparked off a discussion about making GHCi awesomer, and I'm sure everyone can appreciate that! In particular, Chris wanted to discuss programmatic means of controlling GHCi itself, and naturally we need to ask - is the current API not enough, and why? [4]\\r\\n   - Yuras Shumovich has implemented a proposal for allowing the Haskell FFI to support C structures natively as return values - this involves interfacing with C ABI rules to properly support structure layout. While Yuras has an initial implementation in Phab:D252, some questions about the feature - including its implementation complexity - remain before it gets merged. [5]\\r\\n   - Richard Eisenberg made a modest request: can Phabricator patches have a 'roadmap', so people can instruct reviewers **how** to read a diff? The answer: yes, and it should be relatively easy to implement, and Austin can do so Real Soon Now™. [6]\\r\\n   - Ben Gamari started a big discussion about one-shot event semantics in the I/O manager, with a lot of replies concerning not only the bug, but machines to test the actual change on. With any luck, Ben's fix for the I/O manager and a test machine should come quickly enough. [7]\\r\\n   - Herbert Valerio Riedel opened an RFC: Should we look into using AsciiDoc for GHC? Historically, GHC's documentation has been written using DocBook, a verbose but very precise and unambiguous documentation format. However, AsciiDoc offers a much nicer markup language, while retaining DocBook support. In short, it looks like GHC may get a much more clean user manual soon. [8]\\r\\n   - Yuras opened another discussion: Should we namespace proposals we create on our wiki? What seems uncontroversial can lead to surprising discussion, and the results were mixed this time it seems. [9]\\r\\n   - Geoff Mainland stepped up and fixed Data Parallel Haskell to work with a new version of `vector` and GHC. Austin had disabled DPH a few weeks prior due to its difficulty to upgrade, and divergent source trees. With 7.10, GHC will hopefully ship a more modern `vector` and `dph` to boot.\\r\\n   - Austin asks: can we warn on tabs by default for GHC 7.10? It's an easy change and a minor one - but we should at least ask first. Vote now! [10] \\r\\n   - Philip Hölzenspies opens up a discussion about Uniques in GHC, and their impact on the compilers current design. Philip has a hopeful design to redo `Unique` values in GHC, and a patch to support it: Phab:D323. [11]\\r\\n   - Richard Eisenberg asks: can we somehow integrate GitHub into our development process? While GitHub doesn't have as many nice tools as something like Phabricator, it has a very high inertia factor, and Richard is interested in making the 'first step' as easy as possible for newbies. Discussions about Phab<->GitHub integrations were afoot, as well as general discussion about contributor needs. There were a lot of points brought up, but the conversation has slightly dried up now - but will surely be revived again. [12]\\r\\n\\r\\nAnd now, look at all these tickets we closed! Including: #9658, #9094, #9356, #9604, #9678, #9680, #9689, #9670, #9345, #9695, #9639, #9296, #9377, #9184, #9684.\\r\\n\\r\\n[1] http://www.haskell.org/pipermail/ghc-devs/2014-October/006518.html [[BR]]\\r\\n[2] http://www.haskell.org/pipermail/ghc-devs/2014-October/006713.html [[BR]]\\r\\n[3] http://www.haskell.org/pipermail/ghc-devs/2014-October/006482.html [[BR]]\\r\\n[4] http://www.haskell.org/pipermail/ghc-devs/2014-October/006771.html [[BR]]\\r\\n[5] http://www.haskell.org/pipermail/ghc-devs/2014-October/006616.html [[BR]]\\r\\n[6] http://www.haskell.org/pipermail/ghc-devs/2014-October/006719.html [[BR]]\\r\\n[7] http://www.haskell.org/pipermail/ghc-devs/2014-October/006682.html [[BR]]\\r\\n[8] http://www.haskell.org/pipermail/ghc-devs/2014-October/006599.html [[BR]]\\r\\n[9] http://www.haskell.org/pipermail/ghc-devs/2014-October/006730.html [[BR]]\\r\\n[10] http://www.haskell.org/pipermail/ghc-devs/2014-October/006769.html [[BR]]\\r\\n[11] http://www.haskell.org/pipermail/ghc-devs/2014-October/006546.html [[BR]]\\r\\n[12] http://www.haskell.org/pipermail/ghc-devs/2014-October/006523.html [[BR]]","publish_time":1413814463,"version_time":1413814463,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141020","version":2,"title":"GHC Weekly News - 2014/10/20","body":"Hi *,\\r\\n\\r\\nIt's been a few weeks since the last message - and I apologize! We actually are changing the posting time to be **Friday** now, so hopefully this situation will be corrected preeeeetty quickly from this point forward, and hopefully will give better context over the course of a weekly discussion.\\r\\n\\r\\nThat said, let's begin!\\r\\n\\r\\n - We've seen plenty of changes to GHC itself in the past few weeks. Some of the highlights include:\\r\\n   - Some changes to help make `Prelude` combinators fuse better. David Feuer has been leading a lot of this work, and it's been quite fruitful, with several new things now fusing (like `takeWhile`, `scanl`, `scanr`, and `mapAccumL`.\\r\\n   - Relatedly, `Data.List.Inits` should be far faster thanks to David Feuer (ref: Phab:D329).\\r\\n   - The testsuite driver now has preliminary support for Python 3 - which should be useful for platforms out there that sport it, and ones that will use it as the default eventually (such as Fedora 22, possibly).\\r\\n   - Some of the initial work by Edward Yang to remove `HEAP_ALLOCED` from the GHC runtime system has landed. Briefly, `HEAP_ALLOCED` is a check the RTS uses to determine if some address is part of the dynamic heap - but the check is a bit costly. Edward's full patchset hopes to remove this with an 8% speedup or so on average.\\r\\n   - GHC now has a new macro, `__GLASGOW_HASKELL_PATCHLEVEL__`, which will allow you to determine the point-level release of the GHC you're using. This has been a requested feature in the past we were a little hesitant of adding, but Herbert went through and did it for us. (Ref: Phab:D66)\\r\\n   - Template Haskell now supports `LINE` pragmas, thanks to Eric Mertens (ref: Phab:D299).\\r\\n   - Sergei Trofimovich revived `libbfd` debugging support for the runtime system linker, which should be of use to several daring souls out there (ref: Phab:D193).\\r\\n   - Several patches from Gintautas Miliauskas has improved the usability of msys and the testsuite on Windows - and he's not done yet!\\r\\n   - A few improvements to the x86 code generator were committed by Reid Barton and Herbert Valerio Riedel, improving size/space for certain cases (ref: Phab:D320, Phab:D163).\\r\\n and more besides that, including some linker improvements, and general cleanups as usual.\\r\\n\\r\\n - The mailing list has been busy (as usual), with some discussions including:\\r\\n   - Austin posted some discussion about the tentative 7.10.1 plans - we're still hoping these are accurate, so take note! **We hope to freeze mid-November, and release Feburary 2015**! [1]\\r\\n   - Austin also called for some feedback: GHC HQ has become convinced a 7.8.4 release is needed to fix some showstoppers - so please let him know soon if you're totally incapable of using 7.8 for something! [2]\\r\\n   - Alan Zimmerman has asked for some feedback on his proposed \"AST Annotations\", which will hopefully allow GHC API clients to add richer annotations to GHC's syntactic representations. The motivation is for refactoring tools like HaRe - and I'm sure all input would be appreciated. [3]\\r\\n   - Chris done sparked off a discussion about making GHCi awesomer, and I'm sure everyone can appreciate that! In particular, Chris wanted to discuss programmatic means of controlling GHCi itself, and naturally we need to ask - is the current API not enough, and why? [4]\\r\\n   - Yuras Shumovich has implemented a proposal for allowing the Haskell FFI to support C structures natively as return values - this involves interfacing with C ABI rules to properly support structure layout. While Yuras has an initial implementation in Phab:D252, some questions about the feature - including its implementation complexity - remain before it gets merged. [5]\\r\\n   - Richard Eisenberg made a modest request: can Phabricator patches have a 'roadmap', so people can instruct reviewers **how** to read a diff? The answer: yes, and it should be relatively easy to implement, and Austin can do so Real Soon Now™. [6]\\r\\n   - Ben Gamari started a big discussion about one-shot event semantics in the I/O manager, with a lot of replies concerning not only the bug, but machines to test the actual change on. With any luck, Ben's fix for the I/O manager and a test machine should come quickly enough. [7]\\r\\n   - Herbert Valerio Riedel opened an RFC: Should we look into using AsciiDoc for GHC? Historically, GHC's documentation has been written using DocBook, a verbose but very precise and unambiguous documentation format. However, AsciiDoc offers a much nicer markup language, while retaining DocBook support. In short, it looks like GHC may get a much more clean user manual soon. [8]\\r\\n   - Yuras opened another discussion: Should we namespace proposals we create on our wiki? What seems uncontroversial can lead to surprising discussion, and the results were mixed this time it seems. [9]\\r\\n   - Geoff Mainland stepped up and fixed Data Parallel Haskell to work with a new version of `vector` and GHC. Austin had disabled DPH a few weeks prior due to its difficulty to upgrade, and divergent source trees. With 7.10, GHC will hopefully ship a more modern `vector` and `dph` to boot.\\r\\n   - Austin asks: can we warn on tabs by default for GHC 7.10? It's an easy change and a minor one - but we should at least ask first. Vote now! [10] \\r\\n   - Philip Hölzenspies opens up a discussion about Uniques in GHC, and their impact on the compilers current design. Philip has a hopeful design to redo `Unique` values in GHC, and a patch to support it: Phab:D323. [11]\\r\\n   - Richard Eisenberg asks: can we somehow integrate GitHub into our development process? While GitHub doesn't have as many nice tools as something like Phabricator, it has a very high inertia factor, and Richard is interested in making the 'first step' as easy as possible for newbies. Discussions about Phab<->GitHub integrations were afoot, as well as general discussion about contributor needs. There were a lot of points brought up, but the conversation has slightly dried up now - but will surely be revived again. [12]\\r\\n\\r\\nAnd now, look at all these tickets we closed! Including: #9658, #9094, #9356, #9604, #9680, #9689, #9670, #9345, #9695, #9639, #9296, #9377, #9184, #9684.\\r\\n\\r\\n[1] http://www.haskell.org/pipermail/ghc-devs/2014-October/006518.html [[BR]]\\r\\n[2] http://www.haskell.org/pipermail/ghc-devs/2014-October/006713.html [[BR]]\\r\\n[3] http://www.haskell.org/pipermail/ghc-devs/2014-October/006482.html [[BR]]\\r\\n[4] http://www.haskell.org/pipermail/ghc-devs/2014-October/006771.html [[BR]]\\r\\n[5] http://www.haskell.org/pipermail/ghc-devs/2014-October/006616.html [[BR]]\\r\\n[6] http://www.haskell.org/pipermail/ghc-devs/2014-October/006719.html [[BR]]\\r\\n[7] http://www.haskell.org/pipermail/ghc-devs/2014-October/006682.html [[BR]]\\r\\n[8] http://www.haskell.org/pipermail/ghc-devs/2014-October/006599.html [[BR]]\\r\\n[9] http://www.haskell.org/pipermail/ghc-devs/2014-October/006730.html [[BR]]\\r\\n[10] http://www.haskell.org/pipermail/ghc-devs/2014-October/006769.html [[BR]]\\r\\n[11] http://www.haskell.org/pipermail/ghc-devs/2014-October/006546.html [[BR]]\\r\\n[12] http://www.haskell.org/pipermail/ghc-devs/2014-October/006523.html [[BR]]","publish_time":1413814463,"version_time":1413815031,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141121","version":2,"title":"GHC Weekly News - 2014/11/21","body":"Hi *,\\r\\n\\r\\nTo get things back on track, we have a short post following up the earlier one this week. It's been busy today so I'll keep it short:\\r\\n\\r\\n  - The STABLE freeze Austin announced two weeks ago is happening now, although at this point a few things we wanted to ship are just 98% ready. So it may wait until Monday.\\r\\n\\r\\n  - Gergo Erdi merged the implementation of pattern synonym type signatures: https://www.haskell.org/pipermail/ghc-devs/2014-November/007369.html\\r\\n\\r\\n  - HEAD now has support for using the 'deriving' clause for arbitrary classes (see #5462).\\r\\n\\r\\n  - HEAD now has a new flag `-fwarn-missing-exported-sigs`, which fixes #2526. See https://phabricator.haskell.org/D482\\r\\n\\r\\n  - HEAD now has 64bit iOS and SMP support for ARM64, thanks to Luke Iannini. See #7942.\\r\\n\\r\\n  - HEAD no longer ships `haskell98`, `haskell2010`, `old-locale` or `old-time`, per our decision to drop support for `haskell98` and `haskell2010`. GHC 7.10 compatible releases of `old-locale` and `old-time` have been released on hackage. See https://www.haskell.org/pipermail/ghc-devs/2014-November/007357.html and https://www.haskell.org/pipermail/ghc-devs/2014-November/007383.html\\r\\n\\r\\n  - HEAD has been very busy the past two days as many things are now trying to merge as closely to the window as possible. \\r\\n\\r\\n  - `base` now exports a new module for Natural numbers called `Numeric.Natural` following Herbert Valerio Riedel's recent proposal.\\r\\n\\r\\n  - HEAD should finally be compatible with LLVM 3.5, AKA #9142. The patch from Ben Gamari is at https://phabricator.haskell.org/D155\\r\\n\\r\\n  - Your author has been busy and delayed due to some bad travel experiences the past week, so the 7.8.4 RC1 hasn't landed this past week. Hopefully it will be out by the end of this week still.\\r\\n\\r\\nSince the last update was only a few days ago, you'd think we haven't closed a lot of tickets, but we have! Thomas Miedema has been very very adamant about closing tickets and cleaning them up, which is greatly appreciated: #9810, #8324, #8310, #9396, #9626, #9776, #9807, #9698, #7942, #9703, #8584, #8968, #8174, #9812, #9209, #9220, #9151, #9201, #9318, #9109, #9126, #8406, #8102, #8093, #8085, #8068, #8094, #9590, #9368, #2526, #9569, #8149, #9815, #5462, #9647, #8568, #9293, #7484, #1476, #9824, #9628, #7942","publish_time":1416616428,"version_time":1416616465,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141024","version":1,"title":"GHC Weekly News - 2014/10/24","body":"Hi *,\\r\\n\\r\\nWelcome to the weekly GHC news. This one will be short this week, as the preceding one occurred only on Monday - but we'll be going with Fridays from now on, so next week we'll hopefully see a longer list.\\r\\n\\r\\n - GHC 7.8.4 tickets have been in waiting, and the RC will be soon after Austin finishes some final merges and tests on his branch. **We have no committed for the release after the RC**, but we would like people to **please test** and immediately report any major showstoppers - or alerts us of ones we missed.\\r\\n - For the [[https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14 | GHC 7.10 release]], one of the major features we planned to try and merge was DWARF debugging information. This is actually a small component of larger ongoing work, including adding stack traces to Haskell executables. Unfortunately, while not all the work was merge, we talked with Peter, and made a plan: our hope is to get Phab:D169 merged, which lays all the groundwork, followed by DWARF debugging information in the code generators. This will allow tools like `gdb` or other extensible debuggers to analyze C-- IR accurately for compiled executables.\\r\\n Peter has written up a wiki page, available at SourceNotes, describing the design. We hope to land all the core infrastructure in Phab:D169 soon, followed by DWARF information for the Native Code Generator, all for 7.10.1\\r\\n - This past week, a discussion sort of organically started on the `#ghc` IRC channel about the future of the LLVM backend. GHC's backend is buggy, has no control over LLVM versions, and breaks frequently with new versions. This all significantly impacts users, and relegates the backend to a second class citizen. After some discussion, Austin wrote up a [[https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend | proposal for a improved backend]], and wrangled several other people to help. The current plan is to try an execute this by GHC 7.12, with the goal of making the LLVM backend Tier 1 for major supported platforms.\\r\\n - You may notice https://ghc.haskell.org is now responds slightly faster in some cases - we've activated a caching layer (CloudFlare) on the site, so hopefully things should be a little more smooth.\\r\\n\\r\\nClosed tickets this week: #9684, #9692, #9038, #9679, #9537, #1473.","publish_time":1414194219,"version_time":1414194219,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141024","version":2,"title":"GHC Weekly News - 2014/10/24","body":"Hi *,\\r\\n\\r\\nWelcome to the weekly GHC news. This one will be short this week, as the preceding one occurred only on Monday - but we'll be going with Fridays from now on, so next week we'll hopefully see a longer list.\\r\\n\\r\\n - GHC 7.8.4 tickets have been in waiting, and the RC will be soon after Austin finishes some final merges and tests on his branch. **We have not committed for the release after the RC**, but nevertheless we would like people to **please seriously test** and immediately report any major showstoppers - or alert us of ones we missed.\\r\\n - For the [[https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14 | GHC 7.10 release]], one of the major features we planned to try and merge was DWARF debugging information. This is actually a small component of larger ongoing work, including adding stack traces to Haskell executables. While, unfortunately, not all the work can be merged, we talked with Peter, and made a plan: our hope is to get Phab:D169 merged, which lays all the groundwork, followed by DWARF debugging information in the code generators. This will allow tools like `gdb` or other extensible debuggers to analyze C-- IR accurately for compiled executables.\\r\\n Peter has written up a wiki page, available at SourceNotes, describing the design. We hope to land all the core infrastructure in Phab:D169 soon, followed by DWARF information for the Native Code Generator, all for 7.10.1\\r\\n - This past week, a discussion sort of organically started on the `#ghc` IRC channel about the future of the LLVM backend. GHC's backend is buggy, has no control over LLVM versions, and breaks frequently with new versions. This all significantly impacts users, and relegates the backend to a second class citizen. After some discussion, Austin wrote up a [[https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend | proposal for a improved backend]], and wrangled several other people to help. The current plan is to try an execute this by GHC 7.12, with the goal of making the LLVM backend Tier 1 for major supported platforms.\\r\\n - You may notice https://ghc.haskell.org is now responds slightly faster in some cases - we've activated a caching layer (CloudFlare) on the site, so hopefully things should be a little more smooth.\\r\\n\\r\\nClosed tickets this week: #9684, #9692, #9038, #9679, #9537, #1473.","publish_time":1414194219,"version_time":1414194863,"version_comment":"","version_author":"MikolajKonarski","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141024","version":3,"title":"GHC Weekly News - 2014/10/24","body":"Hi *,\\r\\n\\r\\nWelcome to the weekly GHC news. This one will be short this week, as the preceding one occurred only on Monday - but we'll be going with Fridays from now on, so next week we'll hopefully see a longer list.\\r\\n\\r\\n - GHC 7.8.4 tickets have been in waiting, and the RC will be soon after Austin finishes some final merges and tests on his branch. **We have not committed for the release after the RC**, yet we would like people to **please seriously test** and immediately report any major showstoppers - or alert us of ones we missed.\\r\\n - For the [[https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14 | GHC 7.10 release]], one of the major features we planned to try and merge was DWARF debugging information. This is actually a small component of larger ongoing work, including adding stack traces to Haskell executables. While, unfortunately, not all the work can be merged, we talked with Peter, and made a plan: our hope is to get Phab:D169 merged, which lays all the groundwork, followed by DWARF debugging information in the code generators. This will allow tools like `gdb` or other extensible debuggers to analyze C-- IR accurately for compiled executables.\\r\\n Peter has written up a wiki page, available at SourceNotes, describing the design. We hope to land all the core infrastructure in Phab:D169 soon, followed by DWARF information for the Native Code Generator, all for 7.10.1\\r\\n - This past week, a discussion sort of organically started on the `#ghc` IRC channel about the future of the LLVM backend. GHC's backend is buggy, has no control over LLVM versions, and breaks frequently with new versions. This all significantly impacts users, and relegates the backend to a second class citizen. After some discussion, Austin wrote up a [[https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend | proposal for a improved backend]], and wrangled several other people to help. The current plan is to try an execute this by GHC 7.12, with the goal of making the LLVM backend Tier 1 for major supported platforms.\\r\\n - You may notice https://ghc.haskell.org is now responds slightly faster in some cases - we've activated a caching layer (CloudFlare) on the site, so hopefully things should be a little more smooth.\\r\\n\\r\\nClosed tickets this week: #9684, #9692, #9038, #9679, #9537, #1473.","publish_time":1414194219,"version_time":1414194927,"version_comment":"","version_author":"MikolajKonarski","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141024","version":4,"title":"GHC Weekly News - 2014/10/24","body":"Hi *,\\r\\n\\r\\nWelcome to the weekly GHC news. This one will be short this week, as the preceding one occurred only on Monday - but we'll be going with Fridays from now on, so next week we'll hopefully see a longer list.\\r\\n\\r\\n - GHC 7.8.4 tickets have been in waiting, and the RC will be soon after Austin finishes some final merges and tests on his branch. **We have not committed a time for the release after the RC**, yet we would like people to **please seriously test** and immediately report any major showstoppers - or alert us of ones we missed.\\r\\n - For the [[https://ghc.haskell.org/trac/ghc/wiki/Status/Oct14 | GHC 7.10 release]], one of the major features we planned to try and merge was DWARF debugging information. This is actually a small component of larger ongoing work, including adding stack traces to Haskell executables. While, unfortunately, not all the work can be merged, we talked with Peter, and made a plan: our hope is to get Phab:D169 merged, which lays all the groundwork, followed by DWARF debugging information in the code generators. This will allow tools like `gdb` or other extensible debuggers to analyze C-- IR accurately for compiled executables.\\r\\n Peter has written up a wiki page, available at SourceNotes, describing the design. We hope to land all the core infrastructure in Phab:D169 soon, followed by DWARF information for the Native Code Generator, all for 7.10.1\\r\\n - This past week, a discussion sort of organically started on the `#ghc` IRC channel about the future of the LLVM backend. GHC's backend is buggy, has no control over LLVM versions, and breaks frequently with new versions. This all significantly impacts users, and relegates the backend to a second class citizen. After some discussion, Austin wrote up a [[https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend | proposal for a improved backend]], and wrangled several other people to help. The current plan is to try an execute this by GHC 7.12, with the goal of making the LLVM backend Tier 1 for major supported platforms.\\r\\n - You may notice https://ghc.haskell.org is now responds slightly faster in some cases - we've activated a caching layer (CloudFlare) on the site, so hopefully things should be a little more smooth.\\r\\n\\r\\nClosed tickets this week: #9684, #9692, #9038, #9679, #9537, #1473.","publish_time":1414194219,"version_time":1414195140,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141031","version":1,"title":"GHC Weekly News - 2014/10/31 (Halloween Edition)","body":"Hello *,\\r\\n\\r\\nWelcome to the GHC Weekly news. And it's just in time before you go out and eat lots of candy and food.\\r\\n\\r\\n  * David Feuer and Joachim Brietner spent some time this past week talking about more optimizations for Haskell code for fusing code, and creating better consumers and producers. This work includes optimizations of \"One shot lambdas\" (lambdas used at most once) and Call Arity, which was implemented by Joachim at Microsoft Research. The thread is here - https://www.haskell.org/pipermail/ghc-devs/2014-October/006901.html\\r\\n The current situation is that Call Arity and One shot analysis tends to have good combined results for exploiting more fusion opportunities, but sometimes these backfire. As a result, Joachim and David have worked on improving the situation - particularly by letting programmers help with a new `oneShot` primitive (in Phab:D392 & Phab:D393).\\r\\n  * Herbert Valerio Riedel opened up a discussion about the origins of code contributions. In short, we'd like to have some stronger ground to stand on in the face of contributions from contributors - the origin of a change and its legal status is a bit nebulous. The thread is here: https://www.haskell.org/pipermail/ghc-devs/2014-October/006959.html\\r\\n Overall, there's been a lot of separate points made, including CLAs (unlikely), \"Developer Certificates of Origin\" a la the Linux Kernel, and reworking how we mark up header files, and keep track of GHC's long history of authors.\\r\\n If you work on a big project where some of these concerns are real, we'd like to hear what you have to say!\\r\\n  * Gintautas Milauskas has done some fantastic work for GHC on Windows lately, including fixing tests, improving the build, and making things a lot more reasonable to use. With his work, we hope GHC 7.10 will finally ship an updated MinGW compiler (a long requested feature), and have a lot of good fixes for windows. Thank you, Gintautas!\\r\\n  * And on that note, the call for Windows developers rages on - it looks like Gintautaus, Austin, Simon, and others will be meeting to discuss the best way to tackle our current woes. Are you a Windows user? Please give us input - having input is a crucial part of the decision making process, so let us know.\\r\\n  * Jan Stolarek had a question about core2core - a lot of questions, in fact. What's the difference between demand, strictness, and cardinality analylsis? Does the demand analyzer change things? And what's going on in some of the implementation? A good read if you're interested in deep GHC optimization magic: https://www.haskell.org/pipermail/ghc-devs/2014-October/006968.html\\r\\n  * Peter Wortmann has put up the new DWARF generation patches for review, in Phab:D396. This is one of the major components we still plan on landing in 7.10, and with a few weeks to spare, it looks like we can make sure it's merged for the STABLE freeze!\\r\\n  * There have been a lot of good changes in the tree this past week:\\r\\n Thanks to Michael Orlitzky, we plan on adding doctest examples to more modules in 7.10, and increase that coverage further. This is *really* important work, but very low fruit - thanks a ton Michael!\\r\\n\\r\\n `Data.Bifunctor` is now inside base! (Phab:D336)\\r\\n\\r\\n `atomicModifyIORef'` has been optimized with excellent speedups (as much as 1.7x to 1.4x, depending on the RTS used), thanks to some older work by Patrick Palka (Phab:D315).\\r\\n GHC's internals have been reworked to unwire `Integer` from GHC, leading not only to a code cleanup, but laying the foundation for further GMP (and non-GMP!) related `Integer` improvements (Phab:D351).\\r\\n\\r\\n David Feuer and Joachim have been relentless in improving fusion opportunities, including the performance of `take`, `isSuffixOf`, and more prelude improvements, spread over nearly half a dozen patches. And this doesn't even include the work on improving `oneShot` or Call Arity!\\r\\n\\r\\n In a slight change to `base` semantics, David Feuer also finally fixed #9236. This is a change that can expose latent bugs in your program (as it did for Haddock), so be sure to test thoroughly with 7.10 (Phab:D327).\\r\\n\\r\\n GHC now has support for a new `__GLASGOW_HASKELL_TH__` macro, primarily useful for testing bootstrap compilers, or compilers which don't support GHCi.\\r\\n\\r\\nAnd there have been many closed tickets: #9549, #9593, #9720, #9031, #8345, #9439, #9435, #8825, #9006, #9417, #9727, #2104, #9676, #2628, #9510, #9740, #9734, #9367, #9726, #7984, #9230, #9681, #9747, and #9236.\\r\\n","publish_time":1414799829,"version_time":1414799829,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141107","version":1,"title":"GHC Weekly News - 2014/11/07","body":"Hello *,\\r\\n\\r\\nIt's that time again, so get ready for some good ol' fashion news about your favorite compiler.\\r\\n\\r\\n  - Austin announced the 7.10 STABLE freeze date earlier today, which is two weeks from the time of this posting: November 21st, 2014. If you're a developer and have a feature you want, you'd better get it reviewed and checked soon! https://www.haskell.org/pipermail/ghc-devs/2014-November/007206.html\\r\\n  - Austin also opened a discussion about a possible LTS branch for GHC, spawned off from a suggestion by John Lato a few weeks email. This discussion has been brought up several times before this, but for the most part has fizzled out a bit. But maybe with a different focus - on a separate branch with a team of maintainers - we can hash out a plan of action, and just give it a whirl.\\r\\n  - This past week, Simon PJ, Austin, Gintautas Miliauskas, and several others met over a video chat to discuss the future of windows builds. And it went pretty well! We've scribed up some notes, and sort of laid out what we think will be happening for Windows in the near future. Austin is planning to send out an email to the existing discussion[1] rehashing the details soon. https://www.haskell.org/pipermail/ghc-devs/2014-October/006897.html\\r\\n  - Gergo Erdi opened up an RFC about type signatures for pattern synonyms, which is one of the last pieces of the pattern synonyms implementation we've been missing. https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n  - Simon PJ pushed a major overhaul of the constraint solver, just in time for GHC 7.10. This was the result of a few months of work that Simon has been glad to get off his plate, and hopefully should make the type checker faster, leaner, and more modular (as usual).\\r\\n  - Jan Stolarek talked about his planned improvements to the users guide, which is ticket #9358. Hopefully for 7.10 the resulting documentation will be *much* more clear and up to date. https://www.haskell.org/pipermail/ghc-devs/2014-November/007169.html\\r\\n  - Alan Zimmerman has got some more patches up for adding annotations to the GHC Abstract Syntax Tree (AST). The hope is this new representation will make it much easier for tools to enrich the AST with their own custom metadata. Alan has been working on this for several weeks now, so a good review is in order! tps://www.haskell.org/pipermail/ghc-devs/2014-November/007133.html\\r\\n  - Mateusz Lenik, a new contributor, has discussed improving the 'Ticky Ticky' profiling code and resurrecting some of the older features; luckily Jan inspired this work and had some comments. Thanks Mateusz! https://www.haskell.org/pipermail/ghc-devs/2014-November/007078.html\\r\\n  - Alexander Berntsen asked an question about abstracting over constraints in GHC. Richard replied, but it seems this work might be quite difficult! https://www.haskell.org/pipermail/ghc-devs/2014-November/007165.html\\r\\n  - Austin Seipp brought up a question about Windows support: can we officially drop support for XP, now that Microsoft has done the same? And what minimum version requirements should we endorse? Vista or Windows 7 would give improvements due to API improvements, with Windows 7 offering even more. If you're a GHC on Windows user, please let us know! https://www.haskell.org/pipermail/ghc-devs/2014-November/007199.html\\r\\n\\r\\nAnd this weeks closed tickets include quite a long list, thanks to everyone cleaning up the bug tracker: #9747, #9236, #9753, #9752, #9262, #8953, #9084, #9738, #8571, #8295, #8261, #9754, #110, #9345, #8849, #8819, #9658, #8960, #9395, #9705, #9433, #9633, #9359, #9081, #8482, #3376, #9712, #9739, #9211, #9728, #9750, #9768, #9773, #9741, #9284, #9358, #9774, #9771, #9001, #8626, #8986, #9268, #8975, #8962, #8921, #8089, #8843, #8829, #9295, #7913, #2528, #9779.","publish_time":1415397312,"version_time":1415397312,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141107","version":2,"title":"GHC Weekly News - 2014/11/07","body":"Hello *,\\r\\n\\r\\nIt's that time again, so get ready for some good ol' fashion news about your favorite compiler.\\r\\n\\r\\n  - Austin announced the 7.10 STABLE freeze date earlier today, which is two weeks from the time of this posting: November 21st, 2014. If you're a developer and have a feature you want, you'd better get it reviewed and checked soon! https://www.haskell.org/pipermail/ghc-devs/2014-November/007206.html\\r\\n  - Austin also opened a discussion about a possible LTS branch for GHC, spawned off from a suggestion by John Lato a few weeks email. This discussion has been brought up several times before this, but for the most part has fizzled out a bit. But maybe with a different focus - on a separate branch with a team of maintainers - we can hash out a plan of action, and just give it a whirl.\\r\\n  - This past week, Simon PJ, Austin, Gintautas Miliauskas, and several others met over a video chat to discuss the future of windows builds. And it went pretty well! We've scribed up some notes, and sort of laid out what we think will be happening for Windows in the near future. Austin is planning to send out an email to the existing discussion[1] rehashing the details soon. https://www.haskell.org/pipermail/ghc-devs/2014-October/006897.html\\r\\n  - Gergo Erdi opened up an RFC about type signatures for pattern synonyms, which is one of the last pieces of the pattern synonyms implementation we've been missing. https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n  - Simon PJ pushed a major overhaul of the constraint solver, just in time for GHC 7.10. This was the result of a few months of work that Simon has been glad to get off his plate, and hopefully should make the type checker faster, leaner, and more modular (as usual).\\r\\n  - Jan Stolarek talked about his planned improvements to the users guide, which is ticket #9358. Hopefully for 7.10 the resulting documentation will be *much* more clear and up to date. https://www.haskell.org/pipermail/ghc-devs/2014-November/007169.html\\r\\n  - Alan Zimmerman has got some more patches up for adding annotations to the GHC Abstract Syntax Tree (AST). The hope is this new representation will make it much easier for tools to enrich the AST with their own custom metadata. Alan has been working on this for several weeks now, so a good review is in order! tps://www.haskell.org/pipermail/ghc-devs/2014-November/007133.html\\r\\n  - Mateusz Lenik, a new contributor, has discussed improving the 'Ticky Ticky' profiling code and resurrecting some of the older features; luckily Jan inspired this work and had some comments. Thanks Mateusz! https://www.haskell.org/pipermail/ghc-devs/2014-November/007078.html\\r\\n  - Alexander Berntsen asked an question about abstracting over constraints in GHC. Richard replied, but it seems this work might be quite difficult! https://www.haskell.org/pipermail/ghc-devs/2014-November/007165.html\\r\\n  - Austin Seipp brought up a question about Windows support: can we officially drop support for XP, now that Microsoft has done the same? And what minimum version requirements should we endorse? Vista or Windows 7 would give improvements due to API improvements, with Windows 7 offering even more. If you're a GHC on Windows user, please let us know! https://www.haskell.org/pipermail/ghc-devs/2014-November/007199.html\\r\\n\\r\\nAnd this weeks closed tickets include quite a long list, thanks to everyone cleaning up the bug tracker: #9747, #9236, #9753, #9752, #9262, #8953, #9084, #9738, #8571, #8295, #8261, #9754, #110, #9345, #8849, #8819, #9658, #8960, #9395, #9705, #9433, #9633, #9359, #9081, #8482, #3376, #9712, #9739, #9211, #9728, #9750, #9768, #9773, #9741, #9284, #9774, #9771, #9001, #8626, #8986, #9268, #8975, #8962, #8921, #8089, #8843, #8829, #9295, #7913, #2528, #9779.","publish_time":1415397312,"version_time":1415397395,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141107","version":3,"title":"GHC Weekly News - 2014/11/07","body":"Hello *,\\r\\n\\r\\nIt's that time again, so get ready for some good ol' fashion news about your favorite compiler.\\r\\n\\r\\n  - Austin announced the 7.10 STABLE freeze date earlier today, which is two weeks from the time of this posting: November 21st, 2014. If you're a developer and have a feature you want, you'd better get it reviewed and checked soon! https://www.haskell.org/pipermail/ghc-devs/2014-November/007206.html\\r\\n  - Austin also opened a discussion about a possible LTS branch for GHC, spawned off from a suggestion by John Lato a few weeks email. This discussion has been brought up several times before this, but for the most part has fizzled out a bit. But maybe with a different focus - on a separate branch with a team of maintainers - we can hash out a plan of action, and just give it a whirl. https://www.haskell.org/pipermail/ghc-devs/2014-November/007207.html\\r\\n  - This past week, Simon PJ, Austin, Gintautas Miliauskas, and several others met over a video chat to discuss the future of windows builds. And it went pretty well! We've scribed up some notes, and sort of laid out what we think will be happening for Windows in the near future. Austin is planning to send out an email to the existing discussion[1] rehashing the details soon. https://www.haskell.org/pipermail/ghc-devs/2014-October/006897.html\\r\\n  - Gergo Erdi opened up an RFC about type signatures for pattern synonyms, which is one of the last pieces of the pattern synonyms implementation we've been missing. https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n  - Simon PJ pushed a major overhaul of the constraint solver, just in time for GHC 7.10. This was the result of a few months of work that Simon has been glad to get off his plate, and hopefully should make the type checker faster, leaner, and more modular (as usual).\\r\\n  - Jan Stolarek talked about his planned improvements to the users guide, which is ticket #9358. Hopefully for 7.10 the resulting documentation will be *much* more clear and up to date. https://www.haskell.org/pipermail/ghc-devs/2014-November/007169.html\\r\\n  - Alan Zimmerman has got some more patches up for adding annotations to the GHC Abstract Syntax Tree (AST). The hope is this new representation will make it much easier for tools to enrich the AST with their own custom metadata. Alan has been working on this for several weeks now, so a good review is in order! tps://www.haskell.org/pipermail/ghc-devs/2014-November/007133.html\\r\\n  - Mateusz Lenik, a new contributor, has discussed improving the 'Ticky Ticky' profiling code and resurrecting some of the older features; luckily Jan inspired this work and had some comments. Thanks Mateusz! https://www.haskell.org/pipermail/ghc-devs/2014-November/007078.html\\r\\n  - Alexander Berntsen asked an question about abstracting over constraints in GHC. Richard replied, but it seems this work might be quite difficult! https://www.haskell.org/pipermail/ghc-devs/2014-November/007165.html\\r\\n  - Austin Seipp brought up a question about Windows support: can we officially drop support for XP, now that Microsoft has done the same? And what minimum version requirements should we endorse? Vista or Windows 7 would give improvements due to API improvements, with Windows 7 offering even more. If you're a GHC on Windows user, please let us know! https://www.haskell.org/pipermail/ghc-devs/2014-November/007199.html\\r\\n\\r\\nAnd this weeks closed tickets include quite a long list, thanks to everyone cleaning up the bug tracker: #9747, #9236, #9753, #9752, #9262, #8953, #9084, #9738, #8571, #8295, #8261, #9754, #110, #9345, #8849, #8819, #9658, #8960, #9395, #9705, #9433, #9633, #9359, #9081, #8482, #3376, #9712, #9739, #9211, #9728, #9750, #9768, #9773, #9741, #9284, #9774, #9771, #9001, #8626, #8986, #9268, #8975, #8962, #8921, #8089, #8843, #8829, #9295, #7913, #2528, #9779.","publish_time":1415397312,"version_time":1415397562,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141107","version":4,"title":"GHC Weekly News - 2014/11/07","body":"Hello *,\\r\\n\\r\\nIt's that time again, so get ready for some good ol' fashion news about your favorite compiler.\\r\\n\\r\\n  - Austin announced the 7.10 STABLE freeze date earlier today, which is two weeks from the time of this posting: November 21st, 2014. If you're a developer and have a feature you want, you'd better get it reviewed and checked soon! https://www.haskell.org/pipermail/ghc-devs/2014-November/007206.html\\r\\n  - Austin also opened a discussion about a possible LTS branch for GHC, spawned off from a suggestion by John Lato a few weeks email. This discussion has been brought up several times before this, but for the most part has fizzled out a bit. But maybe with a different focus - on a separate branch with a team of maintainers - we can hash out a plan of action, and just give it a whirl. https://www.haskell.org/pipermail/ghc-devs/2014-November/007207.html\\r\\n  - This past week, Simon PJ, Austin, Gintautas Miliauskas, and several others met over a video chat to discuss the future of windows builds. And it went pretty well! We've scribed up some notes, and sort of laid out what we think will be happening for Windows in the near future. Austin is planning to send out an email to the existing discussion rehashing the details soon. https://www.haskell.org/pipermail/ghc-devs/2014-October/006897.html\\r\\n  - Gergo Erdi opened up an RFC about type signatures for pattern synonyms, which is one of the last pieces of the pattern synonyms implementation we've been missing. https://www.haskell.org/pipermail/ghc-devs/2014-November/007066.html\\r\\n  - Simon PJ pushed a major overhaul of the constraint solver, just in time for GHC 7.10. This was the result of a few months of work that Simon has been glad to get off his plate, and hopefully should make the type checker faster, leaner, and more modular (as usual).\\r\\n  - Jan Stolarek talked about his planned improvements to the users guide, which is ticket #9358. Hopefully for 7.10 the resulting documentation will be *much* more clear and up to date. https://www.haskell.org/pipermail/ghc-devs/2014-November/007169.html\\r\\n  - Alan Zimmerman has got some more patches up for adding annotations to the GHC Abstract Syntax Tree (AST). The hope is this new representation will make it much easier for tools to enrich the AST with their own custom metadata. Alan has been working on this for several weeks now, so a good review is in order! tps://www.haskell.org/pipermail/ghc-devs/2014-November/007133.html\\r\\n  - Mateusz Lenik, a new contributor, has discussed improving the 'Ticky Ticky' profiling code and resurrecting some of the older features; luckily Jan inspired this work and had some comments. Thanks Mateusz! https://www.haskell.org/pipermail/ghc-devs/2014-November/007078.html\\r\\n  - Alexander Berntsen asked an question about abstracting over constraints in GHC. Richard replied, but it seems this work might be quite difficult! https://www.haskell.org/pipermail/ghc-devs/2014-November/007165.html\\r\\n  - Austin Seipp brought up a question about Windows support: can we officially drop support for XP, now that Microsoft has done the same? And what minimum version requirements should we endorse? Vista or Windows 7 would give improvements due to API improvements, with Windows 7 offering even more. If you're a GHC on Windows user, please let us know! https://www.haskell.org/pipermail/ghc-devs/2014-November/007199.html\\r\\n\\r\\nAnd this weeks closed tickets include quite a long list, thanks to everyone cleaning up the bug tracker: #9747, #9236, #9753, #9752, #9262, #8953, #9084, #9738, #8571, #8295, #8261, #9754, #110, #9345, #8849, #8819, #9658, #8960, #9395, #9705, #9433, #9633, #9359, #9081, #8482, #3376, #9712, #9739, #9211, #9728, #9750, #9768, #9773, #9741, #9284, #9774, #9771, #9001, #8626, #8986, #9268, #8975, #8962, #8921, #8089, #8843, #8829, #9295, #7913, #2528, #9779.","publish_time":1415397312,"version_time":1415397607,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141121","version":3,"title":"GHC Weekly News - 2014/11/21","body":"Hi *,\\r\\n\\r\\nTo get things back on track, we have a short post following up the earlier one this week. It's been busy today so I'll keep it short:\\r\\n\\r\\n  - The STABLE freeze Austin announced two weeks ago is happening now, although at this point a few things we wanted to ship are just 98% ready. So it may wait until Monday.\\r\\n\\r\\n  - HEAD has been very busy the past two days as many things are now trying to merge as closely to the window as possible. Some notes follow.\\r\\n\\r\\n  - Gergo Erdi merged the implementation of pattern synonym type signatures: https://www.haskell.org/pipermail/ghc-devs/2014-November/007369.html\\r\\n\\r\\n  - HEAD now has support for using the 'deriving' clause for arbitrary classes (see #5462).\\r\\n\\r\\n  - HEAD now has a new flag `-fwarn-missing-exported-sigs`, which fixes #2526. See https://phabricator.haskell.org/D482\\r\\n\\r\\n  - HEAD now has 64bit iOS and SMP support for ARM64, thanks to Luke Iannini. See #7942.\\r\\n\\r\\n  - HEAD no longer ships `haskell98`, `haskell2010`, `old-locale` or `old-time`, per our decision to drop support for `haskell98` and `haskell2010`. GHC 7.10 compatible releases of `old-locale` and `old-time` have been released on hackage. See https://www.haskell.org/pipermail/ghc-devs/2014-November/007357.html and https://www.haskell.org/pipermail/ghc-devs/2014-November/007383.html\\r\\n\\r\\n  - `base` now exports a new module for Natural numbers called `Numeric.Natural` following Herbert Valerio Riedel's recent proposal.\\r\\n\\r\\n  - HEAD should finally be compatible with LLVM 3.5, AKA #9142. The patch from Ben Gamari is at https://phabricator.haskell.org/D155\\r\\n\\r\\n  - Your author has been busy and delayed due to some bad travel experiences the past week, so the 7.8.4 RC1 hasn't landed this past week. Hopefully it will be out by the end of this week still.\\r\\n\\r\\nSince the last update was only a few days ago, you'd think we haven't closed a lot of tickets, but we have! Thomas Miedema has been very very adamant about closing tickets and cleaning them up, which is greatly appreciated: #9810, #8324, #8310, #9396, #9626, #9776, #9807, #9698, #7942, #9703, #8584, #8968, #8174, #9812, #9209, #9220, #9151, #9201, #9318, #9109, #9126, #8406, #8102, #8093, #8085, #8068, #8094, #9590, #9368, #2526, #9569, #8149, #9815, #5462, #9647, #8568, #9293, #7484, #1476, #9824, #9628, #7942","publish_time":1416616428,"version_time":1416616489,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141121","version":4,"title":"GHC Weekly News - 2014/11/21","body":"Hi *,\\r\\n\\r\\nTo get things back on track, we have a short post following up the earlier one this week. It's been busy today so I'll keep it short:\\r\\n\\r\\n  - The STABLE freeze Austin announced two weeks ago is happening now, although at this point a few things we wanted to ship are just 98% ready. So it may wait until Monday.\\r\\n\\r\\n  - HEAD has been very busy the past two days as many things are now trying to merge as closely to the window as possible. Some notes follow.\\r\\n\\r\\n  - Gergo Erdi merged the implementation of pattern synonym type signatures: https://www.haskell.org/pipermail/ghc-devs/2014-November/007369.html\\r\\n\\r\\n  - HEAD now has support for using the 'deriving' clause for arbitrary classes (see #5462).\\r\\n\\r\\n  - HEAD now has a new flag `-fwarn-missing-exported-sigs`, which fixes #2526. See https://phabricator.haskell.org/D482\\r\\n\\r\\n  - HEAD now has 64bit iOS and SMP support for ARM64, thanks to Luke Iannini. See #7942.\\r\\n\\r\\n  - HEAD no longer ships `haskell98`, `haskell2010`, `old-locale` or `old-time`, per our decision to drop support for `haskell98` and `haskell2010`. GHC 7.10 compatible releases of `old-locale` and `old-time` have been released on hackage. See https://www.haskell.org/pipermail/ghc-devs/2014-November/007357.html and https://www.haskell.org/pipermail/ghc-devs/2014-November/007383.html\\r\\n\\r\\n  - `base` now exports a new module for Natural numbers called `Numeric.Natural` following Herbert Valerio Riedel's recent proposal.\\r\\n\\r\\n  - HEAD should finally be compatible with LLVM 3.5, AKA #9142. The patch from Ben Gamari is at https://phabricator.haskell.org/D155\\r\\n\\r\\n  - Your author has been busy and delayed due to some bad travel experiences the past week, so the 7.8.4 RC1 hasn't landed this past week. Hopefully it will be out by the end of this week still.\\r\\n\\r\\nSince the last update was only a few days ago, you'd think we haven't closed a lot of tickets, but we have! Thomas Miedema has been very very persistent about closing tickets and cleaning them up, which is greatly appreciated: #9810, #8324, #8310, #9396, #9626, #9776, #9807, #9698, #7942, #9703, #8584, #8968, #8174, #9812, #9209, #9220, #9151, #9201, #9318, #9109, #9126, #8406, #8102, #8093, #8085, #8068, #8094, #9590, #9368, #2526, #9569, #8149, #9815, #5462, #9647, #8568, #9293, #7484, #1476, #9824, #9628, #7942","publish_time":1416616428,"version_time":1416616507,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141201","version":1,"title":"GHC Weekly News - 2014/12/01","body":"Hi *,\\r\\n\\r\\nIt's that time again for some good ol' fashion GHC news, this time just after the holidays. Some of the things happening in the past week include:\\r\\n\\r\\n  - Partial Type Signatures has been merged into HEAD. Many thanks to Thomas Winant, who worked on this feature for several months!\\r\\n\\r\\n  - As mentioned last week, GHC 7.10 will no longer ship `haskell98` and `haskell2010`, nor `old-time` or `old-locale`.\\r\\n\\r\\n  - Neil Mitchell asked a very good question on `ghc-devs`: what's the process for getting your library synced for the GHC 7.10 release? As the maintainer of `filepath` he'd like to know, and Herbert responded quickly: https://www.haskell.org/pipermail/ghc-devs/2014-November/007394.html\\r\\n\\r\\n  - Yuras Shumovich has more questions about exception handling, primarily: why is `mask` used in `waitQSem`? Simon Marlow responds: https://www.haskell.org/pipermail/ghc-devs/2014-November/007394.html\\r\\n\\r\\n  - Carter Schonwald reports that GHC is having problems building on OS X with XCode 6, but Kazu Yamamoto replied he had no problem - perhaps some OS X wizards can help figure out the discrepancy: https://www.haskell.org/pipermail/ghc-devs/2014-November/007394.html\\r\\n\\r\\n  - Austin Seipp announced GHC 7.8.4 Release Candidate 1, with about a dozen bugfixes for major features: https://www.haskell.org/pipermail/ghc-devs/2014-November/007438.html\\r\\n\\r\\n  - Gergo Erdi asked about backporting pattern synonym type signatures to 7.8.4. The conclusion? Probably won't happen - it's a bit too late! https://www.haskell.org/pipermail/ghc-devs/2014-November/007440.html\\r\\n\\r\\n  - Carter Schonwald had some questions about the let-app invariant and primop code, which he was puzzling about to help with some code generation work. There are also some nice discussions of caches and prefetching in pure programs later on, too: https://www.haskell.org/pipermail/ghc-devs/2014-November/007440.html & https://www.haskell.org/pipermail/ghc-devs/2014-November/007410.html \\r\\n\\r\\n  - Ben Gamari talked about the current status of GHC and LLVM, GHC on ARM, and the future of our LLVM support on both the mailing lists, and his blog. A good read overall for those interested in the war-stories of GHC-on-ARM: https://www.haskell.org/pipermail/ghc-devs/2014-November/007469.html\\r\\n\\r\\nClosed tickets this week include: #9827, #7475, #9826, #7460, #7643, #8044, #8031, #7072, #3654, #7033, #9834, #6098, #6022, #5859, #5763, #9838, #9830, #7243, #9736, #9574, #5158, #9844, #9281, #9818, #4429, #8815, #2182, #4290, #9005, #9828, #9833, #9582, and #9850.\\r\\n\\r\\nAnother huge thanks to **Thomas Miedema** who closed an extraordinary amount of tickets for us - the above list is still not even complete, and he's made a huge impact on the amount of open tickets in the past month or so.","publish_time":1417447489,"version_time":1417447489,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141208","version":1,"title":"GHC Weekly News - 2014/12/08","body":"Hi *,\\r\\n\\r\\nOnce more, it's time for some news about GHC! This week's regularly scheduled programming (get it?) has brought you...\\r\\n\\r\\n  - As of last week, GHC officially has no more `.lhs` files in its source repository; instead, they've all been converted to `.hs` and are now much more consistent with each other: https://www.haskell.org/pipermail/ghc-devs/2014-December/007552.html\\r\\n\\r\\n  - Joachim Breitner has reported that the `linker_unload` test in GHC has been failing, but it's been surprisingly hard to reproduce reliably on our build machines! https://www.haskell.org/pipermail/ghc-devs/2014-December/007528.html\\r\\n\\r\\n  - Moritz Angermann posted a proposal about the \"Out of Process Template Haskell\" project, started by the GHCJS developers. In short, they want to work out how to get Template Haskell working in a stage2 GHC for things like iOS or Browser devices: https://www.haskell.org/pipermail/ghc-devs/2014-December/007555.html\\r\\n\\r\\n  - Lennart Augustsson has an inquiry about his program: why is it running out of memory? But the stranger thing: why does it only run out if heap profiling ''is not enabled''? Nobody has quite figured out, but if you're a guru, it may be a good chance to help out: https://www.haskell.org/pipermail/ghc-devs/2014-December/007582.html\\r\\n\\r\\n  - Yuras Shumovich tracked down some nasty bugs in the typechecker's linter, causing several programs to fail to work when compiled by GHC. A quick diagnosis, but no fix has been merged quite yet: https://www.haskell.org/pipermail/ghc-devs/2014-December/007580.html\\r\\n\\r\\n  - Richard Eisenberg wants feedback on a what he thinks is a design wart in the use of `-XStandaloneDeriving`, and he's not only proposed a solution, but wants to know what people think; typechecking fans are surely puzzling away already: https://www.haskell.org/pipermail/ghc-devs/2014-December/007589.html\\r\\n\\r\\n  - David Spies has run into an interesting situation: why does -O make his program **slower** instead of faster? Well, nobody has quite figured out why yet, but it's an interesting question - maybe on a lazy monday developer can help figure out: https://www.haskell.org/pipermail/ghc-devs/2014-December/thread.html\\r\\n\\r\\n  - Richard E. has another thread on the list, this time about development work flows: what do we do about painful merges? https://www.haskell.org/pipermail/ghc-devs/2014-December/007586.html\\r\\n\\r\\nClosed tickets this week include: #9850, #9005, #9828, #9833, #9582, #8935, #9186, #9480, #9497, #7908, #4347, #3977, #3859, #3844, #3814, #3771, #3739, #2182, #9812, #4921, #7947, #9240, #5401, #3625, #3517, #9444, #9142, #3447, #8894, #3065, #3191, #2697, #2836, #5443, #7736, #2489, #2456, #2204, #9777, #9859, #9869, #9808","publish_time":1418052813,"version_time":1418052813,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150324","version":2,"title":"GHC Weekly News - 2015/03/24","body":"Hi *,\\r\\n\\r\\nIt's time for the GHC weekly news. We've had an absence of the last one, mostly due to a lot of hustle to try and get 7.10 out the door (more on that shortly throughout this post). But now we're back and everything seems to be taken care of.\\r\\n\\r\\nThis week, in the wake of the GHC 7.10 release (which is occuring EOD,\\r\\nhopefully), GHC HQ met up for a brief chat and caught up:\\r\\n\\r\\n  - This week GHC HQ met for only a very short time to discuss the pending release - it looks like all the blocking bugs have been fixed, and we've got everything triaged appropriately. You'll hopefully see the 7.10 announcement shortly after reading this.\\r\\n\\r\\nWe've also had small amounts of list activity (the past 6-8 weeks have been very, very quiet it seems):\\r\\n\\r\\n  - Your editor sent out a call for developers to fill information in on the Status page about what they plan to do. If you're working on something, please add it there! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008661.html\\r\\n\\r\\n  - Herbert Valerio Riedel asked about a possible regression regarding identifiers containing unicode subscripts - but nobody has replied! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008503.html\\r\\n\\r\\n  - Doug Burke chimed in as a new contributor and wrote down some notes on what it took to write his first patch and submit it to us - and we really appreciate the feedback, Doug! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008526.html\\r\\n\\r\\n  - Yitzchak Gale revived a thread he started a while back, which puttered out: bootstrapping GHC 7.8 with GHC 7.10. The long and short of it is, it should just about work - although we still haven't committed to this policy, it looks like Yitz and some others are quite adamant about it. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008531.html\\r\\n\\r\\n  - Neil Mitchell uncovered a nasty bug in GHC 7.10.1 RC3, submitted it to us. He also wrote a fantastic [http://neilmitchell.blogspot.co.at/2015/03/finding-ghc-bug.html blog post explaining the issue]. And it was promply diagnosed, fixed, and taken care of by our own Joachim Breitner. Thank you for the fast response Joachim and Neil! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008532.html\\r\\n\\r\\n  - Mark Lentczner has announced Alpha releases of the Haskell Platform 2015.2.0.0, containing GHC 7.10.1 RC3: https://mail.haskell.org/pipermail/ghc-devs/2015-March/008597.html\\r\\n\\r\\n  - Simon Peyton Jones asks: what's the current state about having simultaneous installations of a package? Simon is a bit confused as to why this is still a problem when we have all the tools to solve it, it looks like! (But read on for more): https://mail.haskell.org/pipermail/ghc-devs/2015-March/008602.html\\r\\n\\r\\n  - Michael Snoyman asks: can we get a new feature patch in GHC 7.10.2? The answer seems to be an unfortunate 'no', but with some tips, Michael may end up backporting the changes from HEAD to GHC 7.10 himself. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008612.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past two weeks include:\\r\\n\\r\\n  - Commit 71fcc4c096ec0b575522e4c2d0104ef7a71a13c5 - GHC defaults to using the `gold` linker on ARM/Android and ARM/Linux targets.\\r\\n  - Commit 9dfdd16a61e79cb03c633d442190a81fe5c0b6b8 - Bump `ghc-prim` to version 0.4.0.0.\\r\\n  - Commit 42448e3757f25735a0a5b5e2b7ee456b5e8b0039 - GHC HEAD now always looks for LLVM 3.6 specifically.\\r\\n\\r\\nClosed tickets this past week include: #9122, #10099, #10081, #9886, #9722, #9619, #9920, #9691, #8976, #9873, #9541, #9619, #9799, #9823, #10156, #1820, #6079, #9056, #9963, #10164, #10138, #10166, #10115, #9921, #9873, #9956, #9609, #7191, #10165, #10011, #8379, #10177, #9261, #10176, #10151, #9839, #8078, #8727, #9849, #10146, #9194, #10158, #7788, #9554, #8550, #10079, #10139, #10180, #10181, #10170, #10186, #10038, #10164, and #8976.","publish_time":1427250019,"version_time":1427250115,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150414","version":1,"title":"GHC Weekly News - 2015/04/14","body":"Hi *,\\r\\n\\r\\nIt's been a few weeks since the last news bulletin - your editor\\r\\napologizes about that. It's actually been a relatively slow few weeks\\r\\nhere too, and busy-ness outside of GHC has attracted some of my\\r\\nattention. Despite that, GHC 7.10.1 was released, a new HP alpha is\\r\\nout, and things are moving along smoothly. Now that the release is\\r\\ndone, things are quitely moving along in `HEAD` - with people\\r\\ncommitting code with reckless abandon, of course.\\r\\n\\r\\nThis week, GHC HQ met up, but it's been very light since the 7.10.1\\r\\nrelease. Currently there isn't anything pushing us to do a 7.10.2\\r\\nrelease at least for a few more weeks it looks like - but see below.\\r\\n\\r\\n  - We puzzled a bit about the release status of 7.10.2, and thought: it's only holding up people who are depending on it. So, who's depending on it, and what do they need fixed? See below for more.\\r\\n\\r\\n  - We also talked a bit about performance - it seems the compiler has been getting much slower over time since the 7.8.x release series, and it's time to reign it in. Austin will be spending his week investigating a bit of this, and the causes.\\r\\n\\r\\n== 7.10.2 Status ==\\r\\n\\r\\nSo, you may be wondering when the 7.10.2 release is. The trick is it happens when you tell us it should happen!\\r\\n\\r\\nSo far, taking a look at milestone:7.10.2, we've fixed about half the bugs we currently have marked down to fix. But we're probably going to punt some of those - and we're not sure all the ones that are there should be.\\r\\n\\r\\nSo this is a call: **If you need something to be fixed during 7.10.2, please file a ticket, set the milestone, and alert us**. The sooner the better, because it'll inform us as to when we should release. Emailing `ghc-devs@haskell.org` is also a sure-fire way to get our attention.\\r\\n\\r\\nAnd remember: you can always find out the latest about the next\\r\\nrelease at the Status page (in this case, for 7.10.2) -\\r\\nhttps://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2\\r\\n\\r\\n== Call for help: DocBook to AsciiDoc ==\\r\\n\\r\\nThe GHC team needs some help. A few months ago, we put out a poll to convert our DocBook-based manual to AsciiDoc.\\r\\n\\r\\nThe poll had a mostly lukewarm reception, with the idea that it will A) make life easier for people who frequently modify the users guide, and B) make life easier for people who add things irregularly, as a lower barrier to entry.\\r\\n\\r\\nIt looks like we still **want** to do this - but alas, many of us don't have time!\\r\\n\\r\\nSo, we're asking the public: Is anyone willing to step up and help here? For example, it may be possible to get a long ways with just `pandoc`, but we need someone to finish it - and in return, we'll help along the way!\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n  - Austin Seipp announced GHC\\r\\n    7.10.1. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008700.html\\r\\n\\r\\n  - Mark Lentczner announced an alpha Haskell Platform\\r\\n    release. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008724.html\\r\\n\\r\\n  - David Macek announced MSYS2 packages for GHC on Windows, and also\\r\\n    asked for some help with continuous windows building - Windows\\r\\n    hackers should help out! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008735.html\\r\\n\\r\\n  - Jan Stolarek reports about increased memory usage with GHC 7.10.1.\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008751.html\\r\\n\\r\\n  - Thomas Miedema chimed into a thread started by Karel Gardas about\\r\\n    better parallelizing the GHC build - and hopefully we can get\\r\\n    something good out of\\r\\n    it. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008749.html\\r\\n\\r\\n  - Austin Seipp made a call for help on working on and improving the\\r\\n    GHC homepage, and luckily Sergey Bushnyak answered the call and\\r\\n    has helped out!\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008762.html\\r\\n\\r\\n  - Ozgun Ataman kicked off a thread about slower compilation times,\\r\\n    with some nasty numbers. It's becoming more clear compiler\\r\\n    performance should be a priority for 7.12, and we've let some\\r\\n    things slip away from us:\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008766.html\\r\\n\\r\\n  - A GHC user, Dave, asked the list about some questions with Cross\\r\\n    Compilation, as he's attempting to get GHC to work natively inside\\r\\n    the Open Embedded build environment. Unfortunately, things haven't\\r\\n    been going well so far, and any input from enterprising hackers is\\r\\n    appreciated:\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008774.html\\r\\n\\r\\n  - Dan Aloni has started a discussion about improving GHC's error\\r\\n    messages, spurred by a popular blog post he wrote and posted on\\r\\n    Reddit about some Happy/GHC improvements he's made. This is a\\r\\n    difficult area (error messages in general are hard) to work on, so\\r\\n    thanks to Dan for helping!\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008778.html\\r\\n\\r\\n  - Simon Peyton Jones started a discussion about\\r\\n    `GeneralizedNewtypeDeriving` and Safe Haskell, in particular,\\r\\n    whatever the current status, our documentation doesn't accurately\\r\\n    reflect it! Perhaps someone could help out writing the\\r\\n    documentation based on the current status quo?\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008783.html\\r\\n\\r\\n  - Tamar Christina started a thread about replacing `ghc-split`, an\\r\\n    old Perl script inside GHC, but he wanted to know: what do we do\\r\\n    about a regex replacement? Mikhail Glushenkov spoke up about a\\r\\n    similar decision the LLVM developers used: to use the OpenBSD\\r\\n    regex implementation. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008785.html\\r\\n\\r\\n  - Alan Zimmerman has posted several questions and threads about the\\r\\n    parser and the status of API annotations, which he's been\\r\\n    furiously working on now that GHC 7.10 is being used on\\r\\n    Hackage. Interested onlookers could learn a thing or two!\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008782.html\\r\\n    &\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008787.html\\r\\n    &\\r\\n    https://mail.haskell.org/pipermail/ghc-devs/2015-April/008794.html\\r\\n\\r\\n  - Gabor Greif has a question about some seemingly strange behavior\\r\\n    regarding the interaction between poly-kinded `data` types and\\r\\n    overlapping instances. Richard sez: this behavior is\\r\\n    expected. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008804.html\\r\\n\\r\\n== Noteworthy commits ==\\r\\n\\r\\n  - Commit de1160be047790afde4ec76de0a81ba3be0c73fa - refactor the\\r\\n    story around switch cases (with a code-size improvement)\\r\\n\\r\\n  - Commit 995e8c1c8692b60c907c7d2ccea179d52ca8e69e - drop old\\r\\n    `integer-gmp-0.5` source code.\\r\\n\\r\\n  - Commit 59f7a7b6091e9c0564f3f370d09398d8c9cd8ad5 - Restore unwind\\r\\n    information generation (fixes DWARF generation)\\r\\n\\r\\n  - Commit 9f0f99fd41ff82cc223d3b682703e508efb564d2 - Fix an old bug\\r\\n    in the demand analyzer (with some nice compiler performance\\r\\n    boosts).\\r\\n\\r\\n  - Commit a7524eaed33324e2155c47d4a705bef1d70a2b5b - Support for\\r\\n    multiple signature files in scope (Backpack).\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n#10222, #10219, #8057, #10226, #10220, #9723, #10230, #10208, #10236, #10213, #10231, #10240, #10243, #10237, #10224, #8811, #10197, #10252, #9958, #10253, #8248, #10207, #10214, #9964, #10194, #10251, #10188, #10257, #10247, #10247, #9160, #10259, #9965, #10265, #10264, #10286, #10282, #10290, #10291, #10300, #9929, #8276, #10218, #10148, #10232, #10274, #10275, #10195, and #10233.","publish_time":1429033468,"version_time":1429033468,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150511","version":1,"title":"GHC Weekly News - 2015/05/11","body":"Hi *,\\r\\n\\r\\nIt's been a few weeks since the last news bulletin - this is the result of mostly quietness on behalf of the list and developers, and some sickness on behalf of your editor for several days there. But now there's actually some things to write here!\\r\\n\\r\\nThe past few weeks, GHC HQ has been having some quiet meetings mostly about bugfixes for a 7.10.2 release - as well as noodling about compiler performance. Austin has begun compiling his preliminary notes on the wiki, under the [wiki:CompilerPerformance] page, where we'll be trying to keep track of the ongoing performance story. Hopefully, GHC 7.12.1 will boast a bit better performance numbers.\\r\\n\\r\\nThere are a lot of users who are interested in this particular pain point, so please file tickets and CC yourself on bugs (like #10370), or feel free to help out!\\r\\n\\r\\n== 7.10.2 status ==\\r\\n\\r\\nThere's been a bit of chatter about the lists about something on many peoples mind: the release of GHC 7.10.2. Most prominently, Mark Lentczner popped in to ask when the next GHC release will happen - in particular, he'd like to make a Haskell Platform release in lockstep with it (see below for a link to Mark's email).\\r\\n\\r\\nUntil recently, the actual desire for 7.10.2 wasn't totally clear, and at this point, GHC HQ hasn't firmly committed to the 7.10.2 release date. But if milestone:7.10.2 is any indicator, we've already closed over three dozen bugs, several of them high priority - and they keep coming in. So it seems likely people will want these fixes in their hands relatively soon.\\r\\n\\r\\nJust remember: '''if you need a fix for 7.10.2''', or have a bug you need us to look at, please email the `ghc-devs` list, file a ticket, and get our attention! Just be sure to set the milestone to 7.10.2.\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n  - Herbert Valerio Riedel opened an RFC about a regression in GHC 7.10 relating to the update to Unicode 7. Any input from users of international languages or unicode users would be appreciated! https://mail.haskell.org/pipermail/ghc-devs/2015-May/008930.html\\r\\n\\r\\n  - Herbert Valerio Riedel also asked about a new C pre-processor implementation for GHC - but in particular, adopting the extant `cpphs` into the GHC codebase for this task itself. https://mail.haskell.org/pipermail/ghc-devs/2015-May/008934.html\\r\\n\\r\\n  - Austin Seipp emailed `ghc-devs` about the HCAR report, for which the GHC entry is due May 17th! Developers should get their edits in quickly. https://mail.haskell.org/pipermail/ghc-devs/2015-May/008939.html\\r\\n\\r\\n  - Joachim Breitner asks if the branchless implementation for our literal cases are worth it for their complexity. There were some interesting responses, including some remarks on the V8 JavaScript compiler. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008852.html\\r\\n\\r\\n  - Niklas Hambüchen announced that he's backported the recent lightweight stack-trace support in GHC HEAD to GHC 7.10 and GHC 7.8 - meaning that users of these stable release can have informative call stack traces, even without profiling! FP Complete was interested in this feature, so they'd probably love to hear user input. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008862.html\\r\\n\\r\\n  - David Terei has written up a proposal on reconciling the existence of Roles with Safe Haskell, which caused us a lot of problems during the 7.8 release cycle. In particular, concerning the ability to break module abstractions and requiring programmers to safeguard abstractions through careful use of roles - and David's written a proposal to address that. https://mail.haskell.org/pipermail/ghc-devs/2015-April/008902.html\\r\\n\\r\\n  - Mark Lentczner started a thread about the 7.10.2 release schedule - because this time, he wants to do a concurrent Haskell Platform release! The thread ended up with a good amount of discussion concerning if 7.10.2 is even needed - but at this rate, it looks like it will ship sometime soon. https://mail.haskell.org/pipermail/ghc-devs/2015-May/008904.html\\r\\n\\r\\n  - Mateusz Kowalczyk posted to `ghc-devs` hoping to get some help with a tricky, long-standing issue: #4012, which concerns the determinism of GHC binaries. It turns out GHC isn't entirely deterministic when it calculates package IDs, meaning things get really bad when you mix prebuilt binary packages for systems. This in particular has become a real problem for the Nix package manager and users of Haskell applications. Mateusz asks if anyone would be willing to help look into it - and a lot of people would appreciate the help! https://mail.haskell.org/pipermail/ghc-devs/2015-May/008992.html\\r\\n== Noteworthy commits ==\\r\\n\\r\\n - Commit f2d1b7fcbbc55e33375a7321222a9f4ee189aa38 - Support unboxing for GADT product types.\\r\\n\\r\\n - Commit 51af102e5c6c56e0987432aa5a21fe10e24090e9 - Better hints when RTS options are not available.\\r\\n\\r\\n - Commit 524ddbdad5816f77b7b719cac0671eebd3473616 - Make sure `GHC.List.last` is memory-efficient.\\r\\n\\r\\n - Commit a1275a762ec04c1159ae37199b1c8f998a5c5499 - Improve improvement in the constraint solver.\\r\\n\\r\\n - Commit 4efa421327cf127ebefde59b2eece693e37dc3c6 - Permit empty closed type families.\\r\\n\\r\\n - Commit 477f514f6ebcf783810da93e2191e4b6ea65559b - rts: add \"-no-rtsopts-suggestions\" option\\r\\n\\r\\n - Commit cf7573b8207bbb17c58612f3345e0b17d74cfb58 - More accurate allocation stats for :set +s\\r\\n\\r\\n - Commit c4e8097ea8dd6e43eae7aadd6bae7e13272ba74d - Bump base version to `4.8.2.0`\\r\\n\\r\\n - Commit 0bbc2ac6dae9ce2838f23a75a6a989826c06f3f5 - Use the gold linker for aarch64/linux (#9673)\\r\\n\\r\\n - Commit 1e8c9b81a819da8eb54405a029fc33a9f5220321 - Enable SMP and GHCi support for AArch64\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n#10293, #10273, #10021, #10209, #10255, #10326, #9745, #10314, #8928, #8743, #10182, #10281, #10325, #10297, #10292, #10304, #10260, #9204, #10121, #10329, #9920, #10308, #10234, #10356, #10351, #10364, #9564, #10306, #10108, #9581, #10369, #9673, #10288, #10260, #10363, #10315, #10389, #9929, #10384, #10382, #10400, #10256, #10254, #10277, #10299, #10268, #10269, #10280, #10312, #10209, #10109, #10321, #10285, #9895, #10395, #10263, #10293, #10210, #10302, #10206, #9858, #10045, and #9840.","publish_time":1431355751,"version_time":1431355751,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150603","version":1,"title":"GHC Weekly News - 2015/06/03","body":"Hi *,\\r\\n\\r\\nIt's that time once again - to get some info on what's happening in the world of GHC! It's been a quiet few weeks as a UK Holiday punted one of GHC HQ's meetings off, and this week we were only partially there.\\r\\n\\r\\nThe main point of discussion was 7.10.2, and continuing work on compiler performance. The good news is, the past few weeks have seen good work on both these fronts!\\r\\n\\r\\n== 7.10.2 status ==\\r\\n\\r\\n7.10.2 is swimming along very nicely - the [https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2 status page] shows the current set of tickets we've fixed and plan on fixing.\\r\\n\\r\\nNot much has changed from last time, except we've fixed even more bugs! We're currently sitting at about 85 bugs fixed, some of them pretty important - code generation bugs, compiler performance fixes, some RTS and event manager work. Your author is actually quite happy with what GHC 7.10.2 looks like, at this rate.\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n  - Austin Seipp announced that GHC 7.10.2 will be release soon, and developers/users should get bugs they want fixed reported to us ASAP so we can do something. https://mail.haskell.org/pipermail/ghc-devs/2015-June/009150.html\\r\\n\\r\\n  - Mark Lentczner announced a Haskell Platform alpha featuring GHC 7.10.2 https://mail.haskell.org/pipermail/ghc-devs/2015-June/009128.html\\r\\n\\r\\n  - Facundo Dominguez asks: sometimes we want to create a `static` pointer in a function with a local definition, how can we do that? The current problem is the desugarer gets in the way and current approaches are currently rejected, but Facundo has some ideas/questions about a fix. https://mail.haskell.org/pipermail/ghc-devs/2015-May/009110.html\\r\\n\\r\\n  - David Macek has made great progress on getting native MSYS2 packages for windows working - which should be a great boon to all our Windows users! https://mail.haskell.org/pipermail/ghc-devs/2015-May/009089.html\\r\\n\\r\\n  - Joachim Breitner announced the new GHC performance dashboard, which can be used to track all of GHC's performance-based tests over time. Whoohoo! https://mail.haskell.org/pipermail/ghc-devs/2015-May/009032.html\\r\\n\\r\\n  - Joachim Breitner asked: is there a way to programmatically 'Raise a Concern' on a Phabricator commit? With the new https://perf.haskell.org/ghc/ work, it'd be nice if regressions could be automatically flagged. The current problem is there is no API endpoint, but one can be built. https://mail.haskell.org/pipermail/ghc-devs/2015-June/009128.html\\r\\n\\r\\n  - Adam Gundry asked ghc-devs about some input on changes to the new typechecker plugins API. After some discussion and elbow grease, the new changes have already landed in HEAD and will be in 7.12.1. https://mail.haskell.org/pipermail/ghc-devs/2015-May/009097.html\\r\\n\\r\\n== Noteworthy commits ==\\r\\n\\r\\n  - Commit 45d9a15c4b85a2ed89579106bdafd84accf2cb39 - Fix a huge space leak in the mighty simplifier\\r\\n\\r\\n  - Commit c89bd681d34d3339771ebdde8aa468b1d9ab042b - Fix quadratic behavior in `tidyOccName`\\r\\n\\r\\n  - Commit b03f074fd51adfb9bc4f5275294712ee62741aed - ghci: Allow `:back` and `:forward` to take counts\\r\\n\\r\\n  - Commit 8e4dc8fb63b8d3bfee485c1c830776f3ed704f4d - Greatly speed up `nativeCodeGen/seqBlocks` \\r\\n\\r\\n  - Commit c256357242ee2dd282fd0516260edccbb7617244 - Speed up `elimCommonBlocks` by grouping blocks also by outgoing labels\\r\\n\\r\\n  - Commit f5188f3acd73a07b648924a58b9882c2d0a3dbcb - Fix weird behavior of `-ignore-dot-ghci` and `-ghci-script`\\r\\n\\r\\n  - Commit 4fffbc34c024231c3c9fac7a2134896cc09c7fb7 - New handling of overlapping instances in Safe Haskell\\r\\n\\r\\n  - Commit f16ddcee0c64a92ab911a7841a8cf64e3ac671fd - Support stage 1 Template Haskell (non-quasi) quotes, fixes #10382\\r\\n\\r\\n  - Commit cf7573b8207bbb17c58612f3345e0b17d74cfb58 - More accurate allocation stats for `:set -s`\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n#10407, #10408, #10177, #10359, #10403, #10248, #9579, #10415, #10419, #10427, #10429, #10397, #10422, #10335, #10366, #10110, #10397, #10349, #10244, #8555, #8799, #9131, #10396, #10354, #10278, #9899, #3533, #9950, #10092, #9950, #10430, #9682, #9584, #10446, #10410, #10298, #10449, #10399, #7695, #10261, #8292, #10360, #10126, #10317, #10101, #10322, #10313, #10471, #10473, #7170, #10473, #10423, #10466, #8695, #10461, #10052, #10370, #10425, #10452, #10474, ","publish_time":1433315030,"version_time":1433315030,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141208","version":2,"title":"GHC Weekly News - 2014/12/08","body":"Hi *,\\r\\n\\r\\nOnce more, it's time for some news about GHC! This week's regularly scheduled programming (get it?) has brought you...\\r\\n\\r\\n  - As of last week, GHC officially has no more `.lhs` files in its source repository; instead, all files have been converted to `.hs` and are now much more consistent with each other: https://www.haskell.org/pipermail/ghc-devs/2014-December/007552.html\\r\\n\\r\\n  - Joachim Breitner has reported that the `linker_unload` test in GHC has been failing, but it's been surprisingly hard to reproduce reliably on our build machines! https://www.haskell.org/pipermail/ghc-devs/2014-December/007528.html\\r\\n\\r\\n  - Moritz Angermann posted a proposal about the \"Out of Process Template Haskell\" project, started by the GHCJS developers. In short, they want to work out how to get Template Haskell working in a stage2 GHC for things like iOS or Browser devices: https://www.haskell.org/pipermail/ghc-devs/2014-December/007555.html\\r\\n\\r\\n  - Lennart Augustsson has an inquiry about his program: why is it running out of memory? But the stranger thing: why does it only run out if heap profiling ''is not enabled''? Nobody has quite figured out, but if you're a guru, it may be a good chance to help out: https://www.haskell.org/pipermail/ghc-devs/2014-December/007582.html\\r\\n\\r\\n  - Yuras Shumovich tracked down some nasty bugs in the typechecker's linter, causing several programs to fail to work when compiled by GHC. A quick diagnosis, but no fix has been merged quite yet: https://www.haskell.org/pipermail/ghc-devs/2014-December/007580.html\\r\\n\\r\\n  - Richard Eisenberg wants feedback on a what he thinks is a design wart in the use of `-XStandaloneDeriving`, and he's not only proposed a solution, but wants to know what people think; typechecking fans are surely puzzling away already: https://www.haskell.org/pipermail/ghc-devs/2014-December/007589.html\\r\\n\\r\\n  - David Spies has run into an interesting situation: why does -O make his program **slower** instead of faster? Well, nobody has quite figured out why yet, but it's an interesting question - maybe on a lazy monday developer can help figure out: https://www.haskell.org/pipermail/ghc-devs/2014-December/thread.html\\r\\n\\r\\n  - Richard E. has another thread on the list, this time about development work flows: what do we do about painful merges? https://www.haskell.org/pipermail/ghc-devs/2014-December/007586.html\\r\\n\\r\\nClosed tickets this week include: #9850, #9005, #9828, #9833, #9582, #8935, #9186, #9480, #9497, #7908, #4347, #3977, #3859, #3844, #3814, #3771, #3739, #2182, #9812, #4921, #7947, #9240, #5401, #3625, #3517, #9444, #9142, #3447, #8894, #3065, #3191, #2697, #2836, #5443, #7736, #2489, #2456, #2204, #9777, #9859, #9869, #9808","publish_time":1418052813,"version_time":1418053259,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141216","version":1,"title":"GHC Weekly News - 2014/12/16","body":"Hi *, time for another piece of the GHC weekly news!\\r\\n\\r\\n  - Joachim Breitner has gotten the new GHC 7.8.4 package to tentatively build on ARM quite easily for Debian. Austin also took the liberty of merging all the needed patches; they'll be part of the 7.8.4 release https://www.haskell.org/pipermail/ghc-devs/2014-December/007608.html\\r\\n\\r\\n  - Greg Weber announced he's taken the time to set up a Docker image for GHC development - if you're on Linux, Greg's image should help you get up to speed with a GHC development environment in minutes! ttps://www.haskell.org/pipermail/ghc-devs/2014-December/007606.html\\r\\n\\r\\n  - Lennart Kolmodin has spent time working on autocompletion for GHC, and 7.10 will ship with bash completion scripts - which package maintainers and distributions can now ship for their users. Thank you Lennart! https://www.haskell.org/pipermail/ghc-devs/2014-December/007614.html\\r\\n\\r\\n  - Adam Gundry has a question about the new type checker plugin infrastructure; in particular - how do we deal with the serialization of type checker evidence, which plugins may want to create or pass around on their own? Richard, Simon and Iavor weigh in. https://www.haskell.org/pipermail/ghc-devs/2014-December/007626.html\\r\\n\\r\\n  - For the past few days, Richard Eisenberg has been hunting a performance regression in the compiler. After profiling, discussion on IRC and elsewhere, Richard has finally made some headway, and discovered one of the 'hot spots' in his patch. Unfortunately the battle isn't quite over just yet, and the hunt for a few more % increase remains. https://www.haskell.org/pipermail/ghc-devs/2014-December/007645.html\\r\\n\\r\\n  - David Spies has hit a very strange situation with GHC 7.8.3 running out of memory. But it turned out this was a change in 7.8, in relation to how stacks were managed. Phew! https://www.haskell.org/pipermail/ghc-devs/2014-December/007646.html\\r\\n\\r\\n  - Austin made a final call for 7.8.4 bugfixes. He plans on making the final release this week, if nobody has any other major complaints. https://www.haskell.org/pipermail/ghc-devs/2014-December/007684.html\\r\\n\\r\\nClosed tickets this week include: #9871, #9808, #9780, #9605, #9874, #9872, #9090, #9404, #8240, #9567, #9566, #9583, #9117, #9882, #9883, #9884, #9372, #7942, #8951, #9817, #9620, #9336, #9523, #9552, #8988, #9390, #9415, #9371, #7143, #9563, #8778, #4428, #4896, #9393, #9169, #7015, #8943, #8621, #9132, #9857, #8024, #9831, and #9888.","publish_time":1418763100,"version_time":1418763100,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141216","version":2,"title":"GHC Weekly News - 2014/12/16","body":"Hi *, time for another piece of the GHC weekly news!\\r\\n\\r\\n  - Joachim Breitner has gotten the new GHC 7.8.4 package to tentatively build on ARM quite easily for Debian. Austin also took the liberty of merging all the needed patches; they'll be part of the 7.8.4 release https://www.haskell.org/pipermail/ghc-devs/2014-December/007608.html\\r\\n\\r\\n  - Greg Weber announced he's taken the time to set up a Docker image for GHC development - if you're on Linux, Greg's image should help you get up to speed with a GHC development environment in minutes! https://www.haskell.org/pipermail/ghc-devs/2014-December/007606.html\\r\\n\\r\\n  - Lennart Kolmodin has spent time working on autocompletion for GHC, and 7.10 will ship with bash completion scripts - which package maintainers and distributions can now ship for their users. Thank you Lennart! https://www.haskell.org/pipermail/ghc-devs/2014-December/007614.html\\r\\n\\r\\n  - Adam Gundry has a question about the new type checker plugin infrastructure; in particular - how do we deal with the serialization of type checker evidence, which plugins may want to create or pass around on their own? Richard, Simon and Iavor weigh in. https://www.haskell.org/pipermail/ghc-devs/2014-December/007626.html\\r\\n\\r\\n  - For the past few days, Richard Eisenberg has been hunting a performance regression in the compiler. After profiling, discussion on IRC and elsewhere, Richard has finally made some headway, and discovered one of the 'hot spots' in his patch. Unfortunately the battle isn't quite over just yet, and the hunt for a few more % increase remains. https://www.haskell.org/pipermail/ghc-devs/2014-December/007645.html\\r\\n\\r\\n  - David Spies has hit a very strange situation with GHC 7.8.3 running out of memory. But it turned out this was a change in 7.8, in relation to how stacks were managed. Phew! https://www.haskell.org/pipermail/ghc-devs/2014-December/007646.html\\r\\n\\r\\n  - Austin made a final call for 7.8.4 bugfixes. He plans on making the final release this week, if nobody has any other major complaints. https://www.haskell.org/pipermail/ghc-devs/2014-December/007684.html\\r\\n\\r\\nClosed tickets this week include: #9871, #9808, #9780, #9605, #9874, #9872, #9090, #9404, #8240, #9567, #9566, #9583, #9117, #9882, #9883, #9884, #9372, #7942, #8951, #9817, #9620, #9336, #9523, #9552, #8988, #9390, #9415, #9371, #7143, #9563, #8778, #4428, #4896, #9393, #9169, #7015, #8943, #8621, #9132, #9857, #8024, #9831, and #9888.","publish_time":1418763100,"version_time":1418763108,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141216","version":3,"title":"GHC Weekly News - 2014/12/16","body":"Hi *, time for another piece of the GHC weekly news!\\r\\n\\r\\n  - Joachim Breitner has gotten the new GHC 7.8.4 package to tentatively build on ARM quite easily for Debian. Austin also took the liberty of merging all the needed patches; they'll be part of the 7.8.4 release https://www.haskell.org/pipermail/ghc-devs/2014-December/007608.html\\r\\n\\r\\n  - Greg Weber announced he's taken the time to set up a Docker image for GHC development - if you're on Linux, Greg's image should help you get up to speed with a GHC development environment in minutes! https://www.haskell.org/pipermail/ghc-devs/2014-December/007606.html\\r\\n\\r\\n  - Lennart Kolmodin has spent time working on autocompletion for GHC, and 7.10 will ship with bash completion scripts - which package maintainers and distributions can now ship for their users. Thank you Lennart! https://www.haskell.org/pipermail/ghc-devs/2014-December/007614.html\\r\\n\\r\\n  - Adam Gundry has a question about the new type checker plugin infrastructure; in particular - how do we deal with the serialization of type checker evidence, which plugins may want to create or pass around on their own? Richard, Simon and Iavor weigh in. https://www.haskell.org/pipermail/ghc-devs/2014-December/007626.html\\r\\n\\r\\n  - For the past few days, Richard Eisenberg has been hunting a performance regression in the compiler. After profiling, discussion on IRC and elsewhere, Richard has finally made some headway, and discovered one of the 'hot spots' in his patch. Unfortunately the battle isn't quite over just yet, and the hunt for a few more % increase remains. https://www.haskell.org/pipermail/ghc-devs/2014-December/007645.html\\r\\n\\r\\n  - David Spies has hit a very strange situation with GHC 7.8.3 running out of memory. But it turned out this was a change in 7.8, in relation to how stacks were managed. Phew! https://www.haskell.org/pipermail/ghc-devs/2014-December/007646.html\\r\\n\\r\\n  - Austin made a final call for 7.8.4 bugfixes. He plans on making the final release this week, if nobody has any other major complaints. https://www.haskell.org/pipermail/ghc-devs/2014-December/007684.html\\r\\n\\r\\nFinally, in a slight change, we'll also be covering some notes from this week's meeting between GHC HQ (Austin, Simon PJ, SimonM, Herbert and Mikolaj), including...\\r\\n\\r\\n  - The 7.10 RC1 looks like it's scheduled to occur this week still; all of our libraries and submodules are up-to-date, and we've taken the time to alert all of our maintainers about this. Thanks to Herbert for taking control of this!\\r\\n\\r\\n  - We'll soon be implementing a new 'push hook' for the `ghc.git` repository: no more trailing whitespace. Since we've recently detabbed, and de-lhs-ified the tree, a knock-on effect was deleting trailing whitespace. Now that we've done a lot of this, we should take the time to enforce it - so they can't slip back in.\\r\\n\\r\\n  - Austin will be landing Phab:D169 and Phab:D396 soon to get it into 7.10.1 RC1.\\r\\n\\r\\n  - This week, Austin managed to secure two sponsors for GHC/Haskell.org. We've been given a wonderful set of ARM buildbots (running in the cloud!) and a new, incredibly powerful POWER8 machine to use (with over 170 hardware threads available, for scalability testing). Hooray for our friends at Online.net and RunAbove.com for helping us out!\\r\\n\\r\\nClosed tickets this week include: #9871, #9808, #9780, #9605, #9874, #9872, #9090, #9404, #8240, #9567, #9566, #9583, #9117, #9882, #9883, #9884, #9372, #7942, #8951, #9817, #9620, #9336, #9523, #9552, #8988, #9390, #9415, #9371, #7143, #9563, #8778, #4428, #4896, #9393, #9169, #7015, #8943, #8621, #9132, #9857, #8024, #9831, and #9888.","publish_time":1418763100,"version_time":1418763467,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141216","version":4,"title":"GHC Weekly News - 2014/12/16","body":"Hi *, time for another piece of the GHC weekly news!\\r\\n\\r\\n  - Joachim Breitner has gotten the new GHC 7.8.4 package to tentatively build on ARM quite easily for Debian. Austin also took the liberty of merging all the needed patches; they'll be part of the 7.8.4 release https://www.haskell.org/pipermail/ghc-devs/2014-December/007608.html\\r\\n\\r\\n  - Greg Weber announced he's taken the time to set up a Docker image for GHC development - if you're on Linux, Greg's image should help you get up to speed with a GHC development environment in minutes! https://www.haskell.org/pipermail/ghc-devs/2014-December/007606.html\\r\\n\\r\\n  - Lennart Kolmodin has spent time working on autocompletion for GHC, and 7.10 will ship with bash completion scripts - which package maintainers and distributions can now ship for their users. Thank you Lennart! https://www.haskell.org/pipermail/ghc-devs/2014-December/007614.html\\r\\n\\r\\n  - Adam Gundry has a question about the new type checker plugin infrastructure; in particular - how do we deal with the serialization of type checker evidence, which plugins may want to create or pass around on their own? Richard, Simon and Iavor weigh in. https://www.haskell.org/pipermail/ghc-devs/2014-December/007626.html\\r\\n\\r\\n  - For the past few days, Richard Eisenberg has been hunting a performance regression in the compiler. After profiling, discussion on IRC and elsewhere, Richard has finally made some headway, and discovered one of the 'hot spots' in his patch. Unfortunately the battle isn't quite over just yet, and the hunt for a few more % increase remains. https://www.haskell.org/pipermail/ghc-devs/2014-December/007645.html\\r\\n\\r\\n  - David Spies has hit a very strange situation with GHC 7.8.3 running out of memory. But it turned out this was a change in 7.8, in relation to how stacks were managed. Phew! https://www.haskell.org/pipermail/ghc-devs/2014-December/007646.html\\r\\n\\r\\n  - Austin made a final call for 7.8.4 bugfixes. He plans on making the final release this week, if nobody has any other major complaints. https://www.haskell.org/pipermail/ghc-devs/2014-December/007684.html\\r\\n\\r\\nFinally, in a slight change, we'll also be covering some notes from this week's meeting between GHC HQ (Austin, Simon PJ, SimonM, Herbert and Mikolaj), including...\\r\\n\\r\\n  - The 7.10 RC1 looks like it's scheduled to occur this week still; all of our libraries and submodules are up-to-date, and we've taken the time to alert all of our maintainers about this. Thanks to Herbert for taking control of this!\\r\\n\\r\\n  - We'll soon be implementing a new 'push hook' for the `ghc.git` repository: no more trailing whitespace. Since we've recently detabbed, and de-lhs-ified the tree, a knock-on effect was deleting trailing whitespace. Now that we've done a lot of this, we should take the time to enforce it - so they can't slip back in.\\r\\n\\r\\n  - Austin will be landing Phab:D169 and Phab:D396 soon to get it into 7.10.1 RC1.\\r\\n\\r\\n  - This week, Austin managed to secure two sponsors for GHC/Haskell.org. We've been given a wonderful set of ARM buildbots (running in the cloud!) and a new, incredibly powerful POWER8 machine to use (with over 170 hardware threads available, for scalability testing). Hooray for our friends at Online.net and RunAbove.com for helping us out!\\r\\n\\r\\nClosed tickets this week include: #9871, #9808, #9870, #9605, #9874, #9872, #9090, #9404, #8240, #9567, #9566, #9583, #9117, #9882, #9883, #9884, #9372, #7942, #8951, #9817, #9620, #9336, #9523, #9552, #8988, #9390, #9415, #9371, #7143, #9563, #8778, #4428, #4896, #9393, #9169, #7015, #8943, #8621, #9132, #9857, #8024, #9831, and #9888.","publish_time":1418763100,"version_time":1418764023,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20141216","version":5,"title":"GHC Weekly News - 2014/12/16","body":"Hi *, time for another piece of the GHC weekly news!\\r\\n\\r\\n  - Joachim Breitner has gotten the new GHC 7.8.4 package to tentatively build on ARM quite easily for Debian. Austin also took the liberty of merging all the needed patches; they'll be part of the 7.8.4 release https://www.haskell.org/pipermail/ghc-devs/2014-December/007608.html\\r\\n\\r\\n  - Greg Weber announced he's taken the time to set up a Docker image for GHC development - if you're on Linux, Greg's image should help you get up to speed with a GHC development environment in minutes! https://www.haskell.org/pipermail/ghc-devs/2014-December/007606.html\\r\\n\\r\\n  - Lennart Kolmodin has spent time working on autocompletion for GHC, and 7.10 will ship with bash completion scripts - which package maintainers and distributions can now ship for their users. Thank you Lennart! https://www.haskell.org/pipermail/ghc-devs/2014-December/007614.html\\r\\n\\r\\n  - Adam Gundry has a question about the new type checker plugin infrastructure; in particular - how do we deal with the serialization of type checker evidence that plugins may want to create or pass around on their own? Richard, Simon and Iavor weigh in. https://www.haskell.org/pipermail/ghc-devs/2014-December/007626.html\\r\\n\\r\\n  - For the past few days, Richard Eisenberg has been hunting a performance regression in the compiler. After profiling, discussion on IRC and elsewhere, Richard has finally made some headway, and discovered one of the 'hot spots' in his patch. Unfortunately the battle isn't quite over just yet, and the hunt for a few more % increase remains. https://www.haskell.org/pipermail/ghc-devs/2014-December/007645.html\\r\\n\\r\\n  - David Spies has hit a very strange situation with GHC 7.8.3 running out of memory. But it turned out this was a change in 7.8, in relation to how stacks were managed. Phew! https://www.haskell.org/pipermail/ghc-devs/2014-December/007646.html\\r\\n\\r\\n  - Austin made a final call for 7.8.4 bugfixes. He plans on making the final release this week, if nobody has any other major complaints. https://www.haskell.org/pipermail/ghc-devs/2014-December/007684.html\\r\\n\\r\\nFinally, in a slight change, we'll also be covering some notes from this week's meeting between GHC HQ (Austin, Simon PJ, SimonM, Herbert and Mikolaj), including...\\r\\n\\r\\n  - The 7.10 RC1 looks like it's scheduled to occur this week still; all of our libraries and submodules are up-to-date, and we've taken the time to alert all of our maintainers about this. Thanks to Herbert for taking control of this!\\r\\n\\r\\n  - We'll soon be implementing a new 'push hook' for the `ghc.git` repository: no more trailing whitespace. Since we've recently detabbed, and de-lhs-ified the tree, a knock-on effect was deleting trailing whitespace. Now that we've done a lot of this, we should take the time to enforce it - so they can't slip back in.\\r\\n\\r\\n  - Austin will be landing Phab:D169 and Phab:D396 soon to get it into 7.10.1 RC1.\\r\\n\\r\\n  - This week, Austin managed to secure two sponsors for GHC/Haskell.org. We've been given a wonderful set of ARM buildbots (running in the cloud!) and a new, incredibly powerful POWER8 machine to use (with over 170 hardware threads available, for scalability testing). Hooray for our friends at Online.net and RunAbove.com for helping us out!\\r\\n\\r\\nClosed tickets this week include: #9871, #9808, #9870, #9605, #9874, #9872, #9090, #9404, #8240, #9567, #9566, #9583, #9117, #9882, #9884, #9372, #7942, #8951, #9817, #9620, #9336, #9523, #9552, #8988, #9390, #9415, #9371, #7143, #9563, #8778, #4428, #4896, #9393, #9169, #7015, #8943, #8621, #9132, #9857, #8024, #9831, and #9888.","publish_time":1418763100,"version_time":1418764123,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150107","version":1,"title":"GHC Weekly News - 2015/01/07","body":"Hi *, it's time for another GHC Weekly News! This week's edition will\\r\\nactually be covering the last two/three weeks, due to some slippage by\\r\\nme as I've been gone since Christmas as a small vacation. It's also our first news posting in 2015!\\r\\n\\r\\nSo let's get going without any further delay!\\r\\n\\r\\n  - Austin Seipp announced the GHC 7.8.4 release on behalf of the GHC\\r\\n    development\\r\\n    team. https://www.haskell.org/pipermail/haskell/2014-December/024395.html\\r\\n\\r\\n  - Austin Seipp ''also'' announced the GHC 7.10.1 RC on behalf of the\\r\\n    GHC team, as\\r\\n    well. https://www.haskell.org/pipermail/ghc-devs/2014-December/007781.html\\r\\n\\r\\n  - GHC 7.10 is coming close to a final release, planned in February;\\r\\n    to help keep track of everything, users and developers are\\r\\n    suggested to look at the GHC 7.10.1 status page as a source of\\r\\n    truth from GHC HQ:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.1\\r\\n\\r\\n  - Jan Stolark is currently working on injective type families for\\r\\n    GHC, but ran into a snag with Template Haskell while trying to\\r\\n    understand GHC's `DsMeta` module. Richard chimed in to help:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007719.html\\r\\n\\r\\n  - Austin Seipp opened a fun vote: what naming convention should we\\r\\n    use for GHC buildbots? After posting the vote before the holidays,\\r\\n    the results are in: GHC's buildbots will take their names from\\r\\n    famous logicians and computer scientists:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007723.html\\r\\n\\r\\n  - Carter Schonwald asked a simple question: are pattern synonyms\\r\\n    usable in GHCi? The answer is 'no', but it seems Gergo is on the\\r\\n    case to remidy that soon enough:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007724.html\\r\\n\\r\\n  - Anton Dessiatov has a question about GHC's heap profiler\\r\\n    information, but unfortunately his question has lingered. Can any\\r\\n    GHC/Haskell hackers out there help him out?\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007748.html\\r\\n\\r\\n  - Joachim Breitner made an exciting announcement: he's working on a\\r\\n    new performance dashboard for GHC, so we can more easily track and\\r\\n    look at performance results over time. The current prototype looks\\r\\n    great, and Joachim and Austin are working together to make this an\\r\\n    official piece of GHC's infrastructure:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007885.html\\r\\n\\r\\n  - Over the holiday, Simon went and implemented a nice new feature\\r\\n    for GHC: detection of redundant constraints. This means if you\\r\\n    mention `Ord` in a type signature, but actually use nothing which\\r\\n    requires that constraint, GHC can properly warn about it. This\\r\\n    will be going into 7.12:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007892.html\\r\\n\\r\\n  - Now that GHC 7.10 will feature support for DWARF based debugging\\r\\n    information, Johan Tibell opened a very obvious discussion thread:\\r\\n    what should we do about shipping GHC and its libraries with debug\\r\\n    support? Peter chimed in with some notes - hopefully this will all\\r\\n    be sorted out in time for 7.10.1 proper:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007851.html\\r\\n\\r\\nGHC HQ met this week after the Christmas break; some of our notes include:\\r\\n\\r\\n  - Austin is back, and will spend some time finishing up all the\\r\\n    remaining binary distributions for GHC 7.8.4 and GHC 7.10.1 RC1\\r\\n    (mostly, FreeBSD and OS X builds).\\r\\n\\r\\n  - We've found that 7.10.1 RC1 is working surprisingly well for users\\r\\n    so far; to help users accomodate the changes, Herbert has\\r\\n    conveniently written a migration guide for users for their most\\r\\n    common problems when upgrading to 7.10.1:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Migration/7.10\\r\\n\\r\\n  - We're aiming to release the 2nd Release Candidate for GHC 7.10.1\\r\\n    on January 19th. We're hoping this will be the last RC, with\\r\\n    7.10.1 final popping up in the middle of February.\\r\\n\\r\\n  - GHC HQ may tentatively be working to release **another** GHC 7.8\\r\\n    release, but only for a specific purpose: to allow it to compile\\r\\n    with 7.10.1. This will make it significantly easier to users to\\r\\n    compile old GHCs (perhaps on newer platforms). However, we're not\\r\\n    yet 100% decided on this, and we will likely only do a 'very minor\\r\\n    release' of the source tarball, should this be the case. Thanks to\\r\\n    Edward Yang for helping with this.\\r\\n\\r\\n  - For future GHC releases on Windows, we're looking into adopting\\r\\n    Neil Mitchell's new binary distribution of GHC, which is a nice\\r\\n    installer that includes Cabal, MSYS and GHC. This should\\r\\n    significantly lower the burden for Windows users to use GHC and\\r\\n    update, ship or create packages. While we're not 100% sure we'll\\r\\n    be able to have it ready for 7.10.1, it looks promising. Thanks\\r\\n    Neil! (For more info, read Neil's blog post here:\\r\\n    http://neilmitchell.blogspot.co.at/2014/12/beta-testing-windows-minimal-ghc.html )\\r\\n\\r\\nClosed tickets the past few weeks include: #8984, #9880, #9732, #9783,\\r\\n#9575, #9860, #9316, #9845, #9913, #9909, #8650, #9881, #9919, #9732,\\r\\n#9783, #9915, #9914, #9751, #9744, #9879, #9876, #9032, #7473, #9764,\\r\\n#9067, #9852, #9847, #9943, #9891, #8909, #9954, #9508, #9586, and\\r\\n#9939.\\r\\n","publish_time":1420671841,"version_time":1420671841,"version_comment":"Initial revision.","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150107","version":2,"title":"GHC Weekly News - 2015/01/07","body":"Hi *, it's time for another GHC Weekly News! This week's edition will\\r\\nactually be covering the last two/three weeks; your editor has missed the past few editions due to Holiday madness (and also some relaxation, which is not madness). It's also our first news posting in 2015!\\r\\n\\r\\nSo let's get going without any further delay!\\r\\n\\r\\n  - Austin Seipp announced the GHC 7.8.4 release on behalf of the GHC\\r\\n    development\\r\\n    team. https://www.haskell.org/pipermail/haskell/2014-December/024395.html\\r\\n\\r\\n  - Austin Seipp ''also'' announced the GHC 7.10.1 RC on behalf of the\\r\\n    GHC team, as\\r\\n    well. https://www.haskell.org/pipermail/ghc-devs/2014-December/007781.html\\r\\n\\r\\n  - GHC 7.10 is coming close to a final release, planned in February;\\r\\n    to help keep track of everything, users and developers are\\r\\n    suggested to look at the GHC 7.10.1 status page as a source of\\r\\n    truth from GHC HQ:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.1\\r\\n\\r\\n  - Jan Stolark is currently working on injective type families for\\r\\n    GHC, but ran into a snag with Template Haskell while trying to\\r\\n    understand GHC's `DsMeta` module. Richard chimed in to help:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007719.html\\r\\n\\r\\n  - Austin Seipp opened a fun vote: what naming convention should we\\r\\n    use for GHC buildbots? After posting the vote before the holidays,\\r\\n    the results are in: GHC's buildbots will take their names from\\r\\n    famous logicians and computer scientists:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007723.html\\r\\n\\r\\n  - Carter Schonwald asked a simple question: are pattern synonyms\\r\\n    usable in GHCi? The answer is 'no', but it seems Gergo is on the\\r\\n    case to remedy that soon enough:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007724.html\\r\\n\\r\\n  - Anton Dessiatov has a question about GHC's heap profiler\\r\\n    information, but unfortunately his question has lingered. Can any\\r\\n    GHC/Haskell hackers out there help him out?\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007748.html\\r\\n\\r\\n  - Joachim Breitner made an exciting announcement: he's working on a\\r\\n    new performance dashboard for GHC, so we can more easily track and\\r\\n    look at performance results over time. The current prototype looks\\r\\n    great, and Joachim and Austin are working together to make this an\\r\\n    official piece of GHC's infrastructure:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007885.html\\r\\n\\r\\n  - Over the holiday, Simon went and implemented a nice new feature\\r\\n    for GHC: detection of redundant constraints. This means if you\\r\\n    mention `Ord` in a type signature, but actually use nothing which\\r\\n    requires that constraint, GHC can properly warn about it. This\\r\\n    will be going into 7.12:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007892.html\\r\\n\\r\\n  - Now that GHC 7.10 will feature support for DWARF based debugging\\r\\n    information, Johan Tibell opened a very obvious discussion thread:\\r\\n    what should we do about shipping GHC and its libraries with debug\\r\\n    support? Peter chimed in with some notes - hopefully this will all\\r\\n    be sorted out in time for 7.10.1 proper:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007851.html\\r\\n\\r\\nGHC HQ met this week after the Christmas break; some of our notes include:\\r\\n\\r\\n  - Austin is back, and will spend some time finishing up all the\\r\\n    remaining binary distributions for GHC 7.8.4 and GHC 7.10.1 RC1\\r\\n    (mostly, FreeBSD and OS X builds).\\r\\n\\r\\n  - We've found that 7.10.1 RC1 is working surprisingly well for users\\r\\n    so far; to help users accomodate the changes, Herbert has\\r\\n    conveniently written a migration guide for users for their most\\r\\n    common problems when upgrading to 7.10.1:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Migration/7.10\\r\\n\\r\\n  - We're aiming to release the 2nd Release Candidate for GHC 7.10.1\\r\\n    on January 19th. We're hoping this will be the last RC, with\\r\\n    7.10.1 final popping up in the middle of February.\\r\\n\\r\\n  - GHC HQ may tentatively be working to release **another** GHC 7.8\\r\\n    release, but only for a specific purpose: to allow it to compile\\r\\n    with 7.10.1. This will make it significantly easier for users to\\r\\n    compile old GHCs (perhaps on newer platforms). However, we're not\\r\\n    yet 100% decided on this, and we will likely only do a 'very minor\\r\\n    release' of the source tarball, should this be the case. Thanks to\\r\\n    Edward Yang for helping with this.\\r\\n\\r\\n  - For future GHC releases on Windows, we're looking into adopting\\r\\n    Neil Mitchell's new binary distribution of GHC, which is a nice\\r\\n    installer that includes Cabal, MSYS and GHC. This should\\r\\n    significantly lower the burden for Windows users to use GHC and\\r\\n    update, ship or create packages. While we're not 100% sure we'll\\r\\n    be able to have it ready for 7.10.1, it looks promising. Thanks\\r\\n    Neil! (For more info, read Neil's blog post here:\\r\\n    http://neilmitchell.blogspot.co.at/2014/12/beta-testing-windows-minimal-ghc.html )\\r\\n\\r\\nClosed tickets the past few weeks include: #8984, #9880, #9732, #9783,\\r\\n#9575, #9860, #9316, #9845, #9913, #9909, #8650, #9881, #9919, #9732,\\r\\n#9783, #9915, #9914, #9751, #9744, #9879, #9876, #9032, #7473, #9764,\\r\\n#9067, #9852, #9847, #9891, #8909, #9954, #9508, #9586, and\\r\\n#9939.\\r\\n","publish_time":1420671841,"version_time":1420679676,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150107","version":3,"title":"GHC Weekly News - 2015/01/07","body":"Hi *, it's time for another GHC Weekly News! This week's edition will\\r\\nactually be covering the last two/three weeks; your editor has missed the past few editions due to Holiday madness (and also some relaxation, which is not madness). It's also our first news posting in 2015!\\r\\n\\r\\nSo let's get going without any further delay!\\r\\n\\r\\nGHC HQ met this week after the Christmas break; some of our notes include:\\r\\n\\r\\n  - Austin Seipp announced the GHC 7.8.4 release on behalf of the GHC\\r\\n    development\\r\\n    team. https://www.haskell.org/pipermail/haskell/2014-December/024395.html\\r\\n\\r\\n  - Austin Seipp ''also'' announced the GHC 7.10.1 RC on behalf of the\\r\\n    GHC team, as\\r\\n    well. https://www.haskell.org/pipermail/ghc-devs/2014-December/007781.html\\r\\n\\r\\n  - Since Austin is back, he'll be spending some time finishing up all the\\r\\n    remaining binary distributions for GHC 7.8.4 and GHC 7.10.1 RC1\\r\\n    (mostly, FreeBSD and OS X builds).\\r\\n\\r\\n  - We've found that 7.10.1 RC1 is working surprisingly well for users\\r\\n    so far; to help users accomodate the changes, Herbert has\\r\\n    conveniently written a migration guide for users for their most\\r\\n    common problems when upgrading to 7.10.1:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Migration/7.10\\r\\n\\r\\n  - We're aiming to release the 2nd Release Candidate for GHC 7.10.1\\r\\n    on January 19th. We're hoping this will be the last RC, with\\r\\n    7.10.1 final popping up in the middle of February.\\r\\n\\r\\n  - GHC HQ may tentatively be working to release **another** GHC 7.8\\r\\n    release, but only for a specific purpose: to allow it to compile\\r\\n    with 7.10.1. This will make it significantly easier for users to\\r\\n    compile old GHCs (perhaps on newer platforms). However, we're not\\r\\n    yet 100% decided on this, and we will likely only do a 'very minor\\r\\n    release' of the source tarball, should this be the case. Thanks to\\r\\n    Edward Yang for helping with this.\\r\\n\\r\\n  - For future GHC releases on Windows, we're looking into adopting\\r\\n    Neil Mitchell's new binary distribution of GHC, which is a nice\\r\\n    installer that includes Cabal, MSYS and GHC. This should\\r\\n    significantly lower the burden for Windows users to use GHC and\\r\\n    update, ship or create packages. While we're not 100% sure we'll\\r\\n    be able to have it ready for 7.10.1, it looks promising. Thanks\\r\\n    Neil! (For more info, read Neil's blog post here:\\r\\n    http://neilmitchell.blogspot.co.at/2014/12/beta-testing-windows-minimal-ghc.html )\\r\\n\\r\\nThere's also been some movement and chatter on the mailing lists, as usual.\\r\\n\\r\\n  - GHC 7.10 is coming close to a final release, planned in February;\\r\\n    to help keep track of everything, users and developers are\\r\\n    suggested to look at the GHC 7.10.1 status page as a source of\\r\\n    truth from GHC HQ:\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.1\\r\\n\\r\\n  - Jan Stolark is currently working on injective type families for\\r\\n    GHC, but ran into a snag with Template Haskell while trying to\\r\\n    understand GHC's `DsMeta` module. Richard chimed in to help:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007719.html\\r\\n\\r\\n  - Austin Seipp opened a fun vote: what naming convention should we\\r\\n    use for GHC buildbots? After posting the vote before the holidays,\\r\\n    the results are in: GHC's buildbots will take their names from\\r\\n    famous logicians and computer scientists:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007723.html\\r\\n\\r\\n  - Carter Schonwald asked a simple question: are pattern synonyms\\r\\n    usable in GHCi? The answer is 'no', but it seems Gergo is on the\\r\\n    case to remedy that soon enough:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007724.html\\r\\n\\r\\n  - Anton Dessiatov has a question about GHC's heap profiler\\r\\n    information, but unfortunately his question has lingered. Can any\\r\\n    GHC/Haskell hackers out there help him out?\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2014-December/007748.html\\r\\n\\r\\n  - Joachim Breitner made an exciting announcement: he's working on a\\r\\n    new performance dashboard for GHC, so we can more easily track and\\r\\n    look at performance results over time. The current prototype looks\\r\\n    great, and Joachim and Austin are working together to make this an\\r\\n    official piece of GHC's infrastructure:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007885.html\\r\\n\\r\\n  - Over the holiday, Simon went and implemented a nice new feature\\r\\n    for GHC: detection of redundant constraints. This means if you\\r\\n    mention `Ord` in a type signature, but actually use nothing which\\r\\n    requires that constraint, GHC can properly warn about it. This\\r\\n    will be going into 7.12:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007892.html\\r\\n\\r\\n  - Now that GHC 7.10 will feature support for DWARF based debugging\\r\\n    information, Johan Tibell opened a very obvious discussion thread:\\r\\n    what should we do about shipping GHC and its libraries with debug\\r\\n    support? Peter chimed in with some notes - hopefully this will all\\r\\n    be sorted out in time for 7.10.1 proper:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-January/007851.html\\r\\n\\r\\n\\r\\nClosed tickets the past few weeks include: #8984, #9880, #9732, #9783,\\r\\n#9575, #9860, #9316, #9845, #9913, #9909, #8650, #9881, #9919, #9732,\\r\\n#9783, #9915, #9914, #9751, #9744, #9879, #9876, #9032, #7473, #9764,\\r\\n#9067, #9852, #9847, #9891, #8909, #9954, #9508, #9586, and\\r\\n#9939.\\r\\n","publish_time":1420671841,"version_time":1420679856,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150119","version":1,"title":"GHC Weekly News - 2015/01/19","body":"Hi *,\\r\\n\\r\\nIt's time for some more GHC news! The GHC 7.10 release is closing in, which has been the primary place we're focusing our attention. In particular, we're hoping RC2 will be Real Soon Now.\\r\\n\\r\\nSome notes from the past GHC HQ meetings this week:\\r\\n\\r\\n  - GHC 7.10 is still rolling along smoothly, and it's expected that RC2 will be cut this Friday, January 23rd. Austin sent out an email about this to `ghc-devs`, so we can hopefully get all the necessary fixes in.\\r\\n\\r\\n  - Our status page for GHC 7.10 lists all the current bullet points and tickets we hope to address: https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.1\\r\\n\\r\\n  - Currently, GHC HQ isn't planning on focusing many cycles on any GHC 7.10 tickets that aren't '''highest priority'''. We're otherwise going to fix things as we see fit, at our leisure - but a highest priority bug is a showstopper for us. This means if you have something you consider a showstopper for the next release, you should bump the priority on the ticket and yell at us!\\r\\n\\r\\n  - We otherwise think everything looks pretty smooth for 7.10.1 RC2 - our libraries are updated, and most of the currently queued patches (with a few minor exceptions) are done and merged.\\r\\n\\r\\nSome notes from the mailing list include:\\r\\n\\r\\n  - Austin announced the GHC 7.10.1 RC2 cutoff, which will be on '''Friday the 23rd'''. https://www.haskell.org/pipermail/ghc-devs/2015-January/008026.html\\r\\n\\r\\n  - Austin has alerted everyone that soon, Phabricator will run all builds with `./validate --slow`, which will increase the time taken for most builds, but will catch a wider array of bugs in commits and submitted patches - there are many cases the default `./validate` script still doesn't catch. https://www.haskell.org/pipermail/ghc-devs/2015-January/008030.html\\r\\n\\r\\n  - Johan Tibell asked about some clarifications for the `HsBang` datatype inside GHC. In response, Simon came back with some clarifications, comments, and refactorings, which greatly helped Johan. ttps://www.haskell.org/pipermail/ghc-devs/2015-January/007905.html\\r\\n\\r\\n  - Jens Petersen announced a Fedora Copr repo for GHC 7.8.4: https://www.haskell.org/pipermail/ghc-devs/2015-January/007978.html\\r\\n\\r\\n  - Richard Eisenberg had a question about the vectoriser: can we disable it? DPH seems to have stagnated a bit recently, bringing into question the necessity of keeping it on. There hasn't been anything done yet, but it looks like the build will get lighter, with a few more modules soon: https://www.haskell.org/pipermail/ghc-devs/2015-January/007986.html\\r\\n\\r\\n  - Ben Gamari has an interesting email about trying to optimize `bytestring`, but he hit a snag with small literals being floated out causing very poor assembly results. Hopefully Simon (or anyone!) can follow up soon with some help: https://www.haskell.org/pipermail/ghc-devs/2015-January/007997.html\\r\\n\\r\\n  - Konrad Gądek asks: why does it seem the GHC API is slower at calling native code than a compiled executable is? Konrad asks as this issue of performance is particularly important for their work. https://www.haskell.org/pipermail/ghc-devs/2015-January/007990.html\\r\\n\\r\\n  - Jan Stolarek has a simple question: what English spelling do we aim for in GHC? It seems that while GHC supports an assortment of British and American english syntactic literals (e.g. `SPECIALIZE` and `SPECIALISE`), the compiler sports an assortment of British/American identifiers on its own! https://www.haskell.org/pipermail/ghc-devs/2015-January/007999.html\\r\\n\\r\\n  - Luis Gabriel has a question about modifying the compiler's profiling output, particularly adding a new CCS (Cost Centre Structure) field. He's hit a bug it seems, and is looking for help with his patch. https://www.haskell.org/pipermail/ghc-devs/2015-January/008015.html\\r\\n\\r\\nClosed tickets the past few weeks include: #9966, #9904, #9969, #9972, #9934, #9967, #9875, #9900, #9973, #9890, #5821, #9984, #9997, #9998, #9971, #10000,  #10002, #9243, #9889, #9384, #8624, #9922, #9878, #9999, #9957, #7298, and #9836.","publish_time":1421703335,"version_time":1421703335,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150127","version":1,"title":"GHC Weekly News - 2015/01/27","body":"Hi *,\\r\\n\\r\\nIt's time for some GHC Weekly news!\\r\\n\\r\\n  - Austin took the time the past week to check `./validate\\r\\n    --slow` failures, and is planning on filing bugs and fixes for the\\r\\n    remaining failures soon. Afterwords, we'll immediately begin\\r\\n    enabling `--slow` on Phabricator, so developers get their patches\\r\\n    tested more thoroughly.\\r\\n\\r\\n  - The 7.10 release looks like it will likely not have a 3rd Release\\r\\n    Candidate, and will be released in late Feburary of 2015, as we\\r\\n    originally expected.\\r\\n\\r\\n  - The 7.10 branch currently has two showstopping bugs we plan on\\r\\n    hitting before the final release. And we'd really like for users\\r\\n    to test so we can catch more!\\r\\n\\r\\n  - Austin Seipp will likely be gone for the coming week in a trip to\\r\\n    New York City from the 28th to the 4th, meaning (much to the\\r\\n    dismay of cheering crowds) you'd better catch him beforehand if\\r\\n    you need him! (Alternatively Austin will be held back due to an\\r\\n    intense snowstorm developing in NYC. So, we'll see!)\\r\\n\\r\\n  - Austin is planning on helping the LLVM support in\\r\\n    HEAD soon; after coordinating with Ben Gamari, we're hoping to\\r\\n    ship GHC 7.12 with (at least) LLVM 3.6 as an officially supported\\r\\n    backend, based on the documentation described in\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend - lots\\r\\n    of thanks to Ben for working with upstream to file bugs and\\r\\n    improve things!\\r\\n\\r\\nAnd in other news, through chatter on the mailing list and Phabricator, we have:\\r\\n\\r\\n  - Austin Seipp announced GHC 7.10.1 RC2: https://www.haskell.org/pipermail/ghc-devs/2015-January/008140.html\\r\\n\\r\\n  - Peter Trommler posted his first version of a native Linux/PowerPC\\r\\n    64bit code generator! There's still a lot more work to do, but\\r\\n    this is a significantly improved situation over the unregisterised\\r\\n    C backend. Curious developers can see the patch at Phab:D629.\\r\\n\\r\\n  - A long, ongoing thread started by Richard Eisenberg about the\\r\\n    long-term plans for the vectorisation code have been posted. The\\r\\n    worry is that the vectoriser as well as DPH have stagnated in\\r\\n    development, which costs other developers any time they need to\\r\\n    build GHC, make larger changes, or keep code clean. There have\\r\\n    been a lot of varied proposals in the thread from removing the\\r\\n    code to commenting it out, to keeping it. It's unclear what the\\r\\n    future holds, but the discussion still rages on. https://www.haskell.org/pipermail/ghc-devs/2015-January/007986.html\\r\\n\\r\\n  - Karel Gardas is working on reviving the SPARC native code\\r\\n    generator, but has hit a snag where double float load instructions\\r\\n    were broken. https://www.haskell.org/pipermail/ghc-devs/2015-January/008123.html\\r\\n\\r\\n  - Alexander Vershilov made a proposal to the GHC team: can we remove\\r\\n    the `transformers` dependency? It turns out to be a rather painful\\r\\n    dependency for users of the GHC API and of packages depending on\\r\\n    `transformers`, as you cannot link against any version other than\\r\\n    the one GHC ships, causing pain. The alternative proposal involves\\r\\n    splitting off the `transformers` dependency into a package of\\r\\n    Orphan instances. The final decision isn't yet clear, nor is a\\r\\n    winner in clear sight yet! https://www.haskell.org/pipermail/ghc-devs/2015-January/008058.html\\r\\n\\r\\n  - Konstantine Rybnikov has a simple question about GHC's error\\r\\n    messages: can they say `Error:` before anything else, to be more\\r\\n    consistent with warnings? It seems like a positive change - and it\\r\\n    looks like Konstantine is on the job to fix it, too. https://www.haskell.org/pipermail/ghc-devs/2015-January/008105.html\\r\\n\\r\\n  - Simon Marlow has started a long thread about the fate of records\\r\\n    in future GHC versions. Previously, Adam Gundry had worked on\\r\\n    `OverloadedRecordFields`. And now Nikita Volkov has introduced his\\r\\n    `records` library which sits in a slightly different spot in the\\r\\n    design space. But now the question is - how do we proceed? Despite\\r\\n    all prior historical precedent, it looks like there's finally some\\r\\n    convergence on a reasonable design that can hit GHC in the future. https://www.haskell.org/pipermail/ghc-devs/2015-January/008049.html\\r\\n\\r\\nClosed tickets the past two weeks include: #9889, #9384, #8624, #9922, #9878, #9999, #9957, #7298, #9836, #10008, #9856, #10009, #10011, #9975, #10013, #9949, #9953, #9856, #9955, #9867, #10015, #9961, #5364, #9928, and #10028.","publish_time":1422392580,"version_time":1422392580,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150127","version":2,"title":"GHC Weekly News - 2015/01/27","body":"Hi *,\\r\\n\\r\\nIt's time for some GHC Weekly news!\\r\\n\\r\\n  - Austin took the time the past week to check `./validate\\r\\n    --slow` failures, and is planning on filing bugs and fixes for the\\r\\n    remaining failures soon. Afterwords, we'll immediately begin\\r\\n    enabling `--slow` on Phabricator, so developers get their patches\\r\\n    tested more thoroughly.\\r\\n\\r\\n  - The 7.10 release looks like it will likely not have a 3rd Release\\r\\n    Candidate, and will be released in late Feburary of 2015, as we\\r\\n    originally expected.\\r\\n\\r\\n  - The 7.10 branch currently has two showstopping bugs we plan on\\r\\n    hitting before the final release. And we'd really like for users\\r\\n    to test so we can catch more!\\r\\n\\r\\n  - Austin Seipp will likely be gone for the coming week in a trip to\\r\\n    New York City from the 28th to the 4th, meaning (much to the\\r\\n    dismay of cheering crowds) you'd better catch him beforehand if\\r\\n    you need him! (Alternatively Austin will be held back due to an\\r\\n    intense snowstorm developing in NYC. So, we'll see!)\\r\\n\\r\\n  - Austin is planning on helping the LLVM support in\\r\\n    HEAD soon; after coordinating with Ben Gamari, we're hoping to\\r\\n    ship GHC 7.12 with (at least) LLVM 3.6 as an officially supported\\r\\n    backend, based on the documentation described in\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/ImprovedLLVMBackend - lots\\r\\n    of thanks to Ben for working with upstream to file bugs and\\r\\n    improve things!\\r\\n\\r\\nAnd in other news, through chatter on the mailing list and Phabricator, we have:\\r\\n\\r\\n  - Austin Seipp announced GHC 7.10.1 RC2: https://www.haskell.org/pipermail/ghc-devs/2015-January/008140.html\\r\\n\\r\\n  - Peter Trommler posted his first version of a native Linux/PowerPC\\r\\n    64bit code generator! There's still a lot more work to do, but\\r\\n    this is a significantly improved situation over the unregisterised\\r\\n    C backend. Curious developers can see the patch at Phab:D629.\\r\\n\\r\\n  - A long, ongoing thread started by Richard Eisenberg about the\\r\\n    long-term plans for the vectorisation code have been posted. The\\r\\n    worry is that the vectoriser as well as DPH have stagnated in\\r\\n    development, which costs other developers any time they need to\\r\\n    build GHC, make larger changes, or keep code clean. There have\\r\\n    been a lot of varied proposals in the thread from removing the\\r\\n    code to commenting it out, to keeping it. It's unclear what the\\r\\n    future holds, but the discussion still rages on. https://www.haskell.org/pipermail/ghc-devs/2015-January/007986.html\\r\\n\\r\\n  - Karel Gardas is working on reviving the SPARC native code\\r\\n    generator, but has hit a snag where double float load instructions\\r\\n    were broken. https://www.haskell.org/pipermail/ghc-devs/2015-January/008123.html\\r\\n\\r\\n  - Alexander Vershilov made a proposal to the GHC team: can we remove\\r\\n    the `transformers` dependency? It turns out to be a rather painful\\r\\n    dependency for users of the GHC API and of packages depending on\\r\\n    `transformers`, as you cannot link against any version other than\\r\\n    the one GHC ships, causing pain. The alternative proposal involves\\r\\n    splitting off the `transformers` dependency into a package of\\r\\n    Orphan instances. The final decision isn't yet clear, nor is a\\r\\n    winner in clear sight yet! https://www.haskell.org/pipermail/ghc-devs/2015-January/008058.html\\r\\n\\r\\n  - Konstantine Rybnikov has a simple question about GHC's error\\r\\n    messages: can they say `Error:` before anything else, to be more\\r\\n    consistent with warnings? It seems like a positive change - and it\\r\\n    looks like Konstantine is on the job to fix it, too. https://www.haskell.org/pipermail/ghc-devs/2015-January/008105.html\\r\\n\\r\\n  - Simon Marlow has started a long thread about the fate of records\\r\\n    in future GHC versions. Previously, Adam Gundry had worked on\\r\\n    `OverloadedRecordFields`. And now Nikita Volkov has introduced his\\r\\n    `records` library which sits in a slightly different spot in the\\r\\n    design space. But now the question is - how do we proceed? Despite\\r\\n    all prior historical precedent, it looks like there's finally some\\r\\n    convergence on a reasonable design that can hit GHC in the future. https://www.haskell.org/pipermail/ghc-devs/2015-January/008049.html\\r\\n\\r\\nClosed tickets the past two weeks include: #9889, #9384, #8624, #9922, #9878, #9999, #9957, #7298, #9836, #10008, #9856, #9975, #10013, #9949, #9953, #9856, #9955, #9867, #10015, #9961, #5364, #9928, and #10028.","publish_time":1422392580,"version_time":1422392594,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"FoldableTraversableDebate","version":1,"title":"GHC 7.10 Prelude: we need your opinion","body":"This post asks for your help in deciding how to proceed with some Prelude changes in GHC 7.10.  Please read on, but all the info is also at the survey link, here: [http://goo.gl/forms/XP1W2JdfpX].   Deadline is 21 Feb 2015.\\r\\n\\r\\nThe Core Libraries Committee (CLC) is responsible for developing the core libraries that ship with GHC. This is an important but painstaking task, and we owe the CLC a big vote of thanks for taking it on.\\r\\n\\r\\nFor over a year the CLC has been working on integrating the Foldable and Traversable classes (shipped in base in GHC 7.8) into the core libraries, and into the Prelude in particular. Detailed planning for GHC 7.10 started in the autumn of 2014, and the CLC went ahead with this integration. \\r\\n\\r\\nThen we had a failure of communication.  As these changes affect the Prelude, which is in scope for all users of Haskell, these changes should be held to a higher bar than the regular libraries@ review process.  However, the Foldable/Traversable changes were not particularly well signposted. Many people have only recently woken up to them, and some have objected (both in principle and detail).\\r\\n\\r\\nThis is an extremely unfortunate situation. On the one hand we are at RC2 for GHC 7.10, so library authors have invested effort in updating their libraries to the new Prelude. On the other, altering the Prelude is in effect altering the language, something we take pretty seriously. We should have had this debate back in 2014, but here we are, and it is unproductive to argue about whose fault it is. We all share responsibility.\\r\\nWe need to decide what to do now. A small group of us met by Skype and we've decided to do this:\\r\\n\\r\\n * Push back GHC 7.10's release by at least a month, to late March.  This delay also gives us breathing space to address an unrelated show-stopping bug, Trac #9858.\\r\\n\\r\\n * Invite input from the Haskell community on which of two approaches to adopt ([http://goo.gl/forms/XP1W2JdfpX this survey]).  The main questions revolve around impact on the Haskell ecosystem (commercial applications, teaching, libraries, etc etc), so we want to ask your opinion rather than guess it.\\r\\n\\r\\n * Ask Simon Marlow and Simon Peyton Jones to decide which approach to follow for GHC 7.10. \\r\\n\\r\\nWiki pages have been created summarizing these two primary alternatives, including many more points and counter-points and technical details: \\r\\n * [https://ghc.haskell.org/trac/ghc/wiki/Prelude710 Overall summary]\\r\\n * [https://ghc.haskell.org/trac/ghc/wiki/Prelude710/List Details of Plan List]\\r\\n * [https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP Details of Plan FTP]\\r\\n\\r\\nThis survey invites your input on which plan we should follow. Would you please\\r\\n * Read the details of the alternative plans on the three wiki pages above\\r\\n * Add your response to [http://goo.gl/forms/XP1W2JdfpX the survey]\\r\\n\\r\\nPlease do read the background.  Well-informed responses will help.  Thank you!\\r\\n\\r\\nDEADLINE: 21 February 2015\\r\\n\\r\\nSimon PJ\\r\\n","publish_time":1423583573,"version_time":1423583573,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"weekly20150210","version":1,"title":"GHC Weekly News - 2015/02/10","body":"Hi *,\\r\\n\\r\\nWelcome! This is the first GHC Weekly news of February 2015. You might be wondering what happened to the last one. Well, your author was just in New York for the past week attending [http://www.composeconference.org Compose Conference], making friends and talking a lot about Haskell (luckily we missed a snow storm that may have messed it up quite badly!)\\r\\n\\r\\nThe conference was great. I got to have some interesting discussions about GHC and Haskell with many friendly faces from all around at an incredibly well run conference with a stellar set of people. Many thanks to NY Haskell (organizing), Spotify (hosting space), and to all the speakers for a wonderful time. (And of course, your editor would like to thank his employer Well-Typed for sending him!)\\r\\n\\r\\nBut now, since your author has returned, GHC HQ met back up this week for some\\r\\ndiscussion, with some regularly scheduled topics. For the most part it was a short meeting this week - our goals are pretty well identified:\\r\\n\\r\\n  - GHC HQ and the Core Libraries Committee have posted a survey on the future of the 7.10 prelude and the FTP/BBP discussion. The deadline is February 20th, so please vote if the discussion is of interest to you. Simon Peyton-Jones and Simon Marlow will be making the final decision. https://www.haskell.org/pipermail/haskell-cafe/2015-February/118095.html\\r\\n\\r\\n  - It's likely GHC HQ will do a third 7.10.1 Release Candidate at the very end of February after the votes are included. We missed some patches in RC2 (such as Phab:D347) and incorporated even more bugfixes, so this is worth a test drive by users.\\r\\n\\r\\n  - For the most part, things for 7.10 have been going very smoothly other than the debates and a few bugs trickling in - there has not been much ticket activity the past two weeks, so things feel pretty good right now. Austin will mostly be focused on shipping 7.10 and keeping the normal review/patch/triaging cycles going until it's done. We're on track to fix all the major bugs we've assigned (see milestone:7.10.1).\\r\\n\\r\\nSince my last post, we've also had other random assorted chatter on the mailing lists by the dev team:\\r\\n\\r\\n  - In light of a recent large bug in GHC which can be used to derive\\r\\n    `unsafeCoerce`, GHC HQ '''has decided to push back the 7.10\\r\\n    release a bit longer to about March''', in order to fix this bug\\r\\n    and ferret out the little fallout afterwords. It turns out this\\r\\n    isn't a simple bug to fix, but luckily a fix is being worked on\\r\\n    already. https://www.haskell.org/pipermail/ghc-devs/2015-January/008189.html\\r\\n\\r\\n  - Luckily, Iavor has started work on fixing this nasty bug, and had\\r\\n    a few questions for the list:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-February/008269.html\\r\\n\\r\\n  - Iavor Diatchki has raised a new topic about a simpler\\r\\n    OverloadedRecordsField proposal. Adam swooped in to address some\\r\\n    points about the\\r\\n    design. https://www.haskell.org/pipermail/ghc-devs/2015-January/008183.html\\r\\n\\r\\n  - Herbert Valerio Riedel posted about a huge (76x) regression\\r\\n    between GHC 7.11 and GHC 7.10, but strangely nobody has picked up\\r\\n    as to why this is the case yet! https://www.haskell.org/pipermail/ghc-devs/2015-January/008207.html\\r\\n\\r\\n  - David Feuer has a question: why is `undefined` so special? In\\r\\n    particular, it seems as if `undefined` can be specially used as a\\r\\n    value with a type of kind `#` as well as `*`. It turns out GHC has\\r\\n    a special notion of subkinding, and `undefined` has a type more\\r\\n    special than meets the eye which allows this, as Adam Gundry\\r\\n    replied. https://www.haskell.org/pipermail/ghc-devs/2015-February/008222.html\\r\\n\\r\\n  - Merijn Verstraaten has started up a discussion about a new\\r\\n    proposal of his, ValidateMonoLiterals. The proposal revolves\\r\\n    around the idea of using GHC to enforce compile-time constraints\\r\\n    on monomorphic literals, whose type may have invariants enforced\\r\\n    on them. While this is doable with Template Haskell, Merijn would\\r\\n    like to see something inside GHC instead. https://www.haskell.org/pipermail/ghc-devs/2015-February/008239.html\\r\\n\\r\\n  - David Feuer asked: can we merge `FlexibleContexts` with\\r\\n    `FlexibleInstances`? The proposal seems to be relatively\\r\\n    undiscussed at the moment with a neutral future, but perhaps\\r\\n    someone would like to chime in on this minor issue. https://www.haskell.org/pipermail/ghc-devs/2015-February/008245.html\\r\\n\\r\\n  - Greg Weber opened up a discussion about 'Restricted Template\\r\\n    Haskell', which would hopefully make it easier for users to see\\r\\n    what a TH computation is actually doing. It turns out - as noted\\r\\n    by Simon - that Typed Template Haskell is perhaps closer to what\\r\\n    Greg wants. The proposal and discussion then resulted in us\\r\\n    realising that the typed TH documentation is rather poor!\\r\\n    Hopefully Greg or someone can swing in to improve things. https://www.haskell.org/pipermail/ghc-devs/2015-February/008232.html\\r\\n\\r\\nClosed tickets the past two weeks include: #10028, #10040, #10031, #9935, #9928, #2615, #10048, #10057, #10054, #10060, #10017, #10038, #9937, #8796, #10030, #9988, #10066, #7425, #7424, #7434, #10041, #2917, #4834, #10004, #10050, #10020, #10036, #9213, and #10047.","publish_time":1423610084,"version_time":1423610084,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150210","version":2,"title":"GHC Weekly News - 2015/02/10","body":"Hi *,\\r\\n\\r\\nWelcome! This is the first GHC Weekly news of February 2015. You might be wondering what happened to the last one. Well, your editor was just in New York for the past week attending [http://www.composeconference.org Compose Conference], making friends and talking a lot about Haskell (luckily we missed a snow storm that may have messed it up quite badly!)\\r\\n\\r\\nThe conference was great. I got to have some interesting discussions about GHC and Haskell with many friendly faces from all around at an incredibly well run conference with a stellar set of people. Many thanks to NY Haskell (organizing), Spotify (hosting space), and to all the speakers for a wonderful time. (And of course, your editor would like to thank his employer Well-Typed for sending him!)\\r\\n\\r\\nBut now, since your author has returned, GHC HQ met back up this week for some\\r\\ndiscussion, with some regularly scheduled topics. For the most part it was a short meeting this week - our goals are pretty well identified:\\r\\n\\r\\n  - GHC HQ and the Core Libraries Committee have posted a survey on the future of the 7.10 prelude and the FTP/BBP discussion. The deadline is February 20th, so please vote if the discussion is of interest to you. Simon Peyton-Jones and Simon Marlow will be making the final decision. https://www.haskell.org/pipermail/haskell-cafe/2015-February/118095.html\\r\\n\\r\\n  - It's likely GHC HQ will do a third 7.10.1 Release Candidate at the very end of February after the votes are included. We missed some patches in RC2 (such as Phab:D347) and incorporated even more bugfixes, so this is worth a test drive by users.\\r\\n\\r\\n  - For the most part, things for 7.10 have been going very smoothly other than the debates and a few bugs trickling in - there has not been much ticket activity the past two weeks, so things feel pretty good right now. Austin will mostly be focused on shipping 7.10 and keeping the normal review/patch/triaging cycles going until it's done. We're on track to fix all the major bugs we've assigned (see milestone:7.10.1).\\r\\n\\r\\nSince my last post, we've also had other random assorted chatter on the mailing lists by the dev team:\\r\\n\\r\\n  - In light of a recent large bug in GHC which can be used to derive\\r\\n    `unsafeCoerce`, GHC HQ '''has decided to push back the 7.10\\r\\n    release a bit longer to about March''', in order to fix this bug\\r\\n    and ferret out the little fallout afterwords. It turns out this\\r\\n    isn't a simple bug to fix, but luckily a fix is being worked on\\r\\n    already. https://www.haskell.org/pipermail/ghc-devs/2015-January/008189.html\\r\\n\\r\\n  - Luckily, Iavor has started work on fixing this nasty bug, and had\\r\\n    a few questions for the list:\\r\\n    https://www.haskell.org/pipermail/ghc-devs/2015-February/008269.html\\r\\n\\r\\n  - Iavor Diatchki has raised a new topic about a simpler\\r\\n    OverloadedRecordsField proposal. Adam swooped in to address some\\r\\n    points about the\\r\\n    design. https://www.haskell.org/pipermail/ghc-devs/2015-January/008183.html\\r\\n\\r\\n  - Herbert Valerio Riedel posted about a huge (76x) regression\\r\\n    between GHC 7.11 and GHC 7.10, but strangely nobody has picked up\\r\\n    as to why this is the case yet! https://www.haskell.org/pipermail/ghc-devs/2015-January/008207.html\\r\\n\\r\\n  - David Feuer has a question: why is `undefined` so special? In\\r\\n    particular, it seems as if `undefined` can be specially used as a\\r\\n    value with a type of kind `#` as well as `*`. It turns out GHC has\\r\\n    a special notion of subkinding, and `undefined` has a type more\\r\\n    special than meets the eye which allows this, as Adam Gundry\\r\\n    replied. https://www.haskell.org/pipermail/ghc-devs/2015-February/008222.html\\r\\n\\r\\n  - Merijn Verstraaten has started up a discussion about a new\\r\\n    proposal of his, ValidateMonoLiterals. The proposal revolves\\r\\n    around the idea of using GHC to enforce compile-time constraints\\r\\n    on monomorphic literals, whose type may have invariants enforced\\r\\n    on them. While this is doable with Template Haskell, Merijn would\\r\\n    like to see something inside GHC instead. https://www.haskell.org/pipermail/ghc-devs/2015-February/008239.html\\r\\n\\r\\n  - David Feuer asked: can we merge `FlexibleContexts` with\\r\\n    `FlexibleInstances`? The proposal seems to be relatively\\r\\n    undiscussed at the moment with a neutral future, but perhaps\\r\\n    someone would like to chime in on this minor issue. https://www.haskell.org/pipermail/ghc-devs/2015-February/008245.html\\r\\n\\r\\n  - Greg Weber opened up a discussion about 'Restricted Template\\r\\n    Haskell', which would hopefully make it easier for users to see\\r\\n    what a TH computation is actually doing. It turns out - as noted\\r\\n    by Simon - that Typed Template Haskell is perhaps closer to what\\r\\n    Greg wants. The proposal and discussion then resulted in us\\r\\n    realising that the typed TH documentation is rather poor!\\r\\n    Hopefully Greg or someone can swing in to improve things. https://www.haskell.org/pipermail/ghc-devs/2015-February/008232.html\\r\\n\\r\\nClosed tickets the past two weeks include: #10028, #10040, #10031, #9935, #9928, #2615, #10048, #10057, #10054, #10060, #10017, #10038, #9937, #8796, #10030, #9988, #10066, #7425, #7424, #7434, #10041, #2917, #4834, #10004, #10050, #10020, #10036, #9213, and #10047.","publish_time":1423610084,"version_time":1423610157,"version_comment":"","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150217","version":1,"title":"GHC Weekly News - 2015/02/17","body":"Hi *,\\r\\n\\r\\nIt's time for the GHC weekly news. It's been particularly quiet the past week still, and the `ghc-7.10` branch has been quite quiet. So the notes are relatively short this week.\\r\\n\\r\\nThis week, GHC HQ met up to discuss some new stuff:\\r\\n\\r\\n  - Most of the discussion this week was about particular bugs for GHC 7.10, including getting some tickets fixed like #10058, #8276, and #9968.\\r\\n  - Since the 7.10 release is getting close, we'll be starting up a new status page about GHC 7.12 (and probably get started writing things for the HCAR report in May) and what our plans are soon. Watch this space!\\r\\n\\r\\nAs usual, we've had a healthy amount of random assorted chatter on the mailing lists:\\r\\n\\r\\n  - Simon Peyton Jones opened the polls for the GHC 7.10 Prelude changes this week, following the discussions and delay of the 7.10 release, as to what the new Prelude should look like. Simon's email has all the details - and voting ends next week! https://mail.haskell.org/pipermail/ghc-devs/2015-February/008290.html\\r\\n  - Hengchu Zhang popped up on the list as an excited new contributor, and wanted to know about the process strategy for fixing a bug. Joachim was quick to respond with help - and welcome Hengchu! https://mail.haskell.org/pipermail/ghc-devs/2015-February/008324.html\\r\\n  - Francesco Mazzoli has a question about Template Haskell, specifically the semantics of reification since 7.8. In short, the semantics of `reify` changed in 7.8, and Francesco was wondering if the old behavior should be supported. But while it could be, it discussion seems to indicate that perhaps it shouldn't. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008327.html\\r\\n  - Darren Grant popped up on the list and asked: \"I notice there are a series of related long-standing issues subject to particular cygwin64 quirks, and I'd like to offer time to help resolve these if possible\". Darren wanted some pointers, and they were given! GHC on Windows crucially still needs dedicated developers; the email sparked up a bunch of chatter amongst Windows developers on the list as well, so hopefully life is coming back to it. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008333.html\\r\\n  - Jan Stolarek hit a confusing error when trying to install `vector` with HEAD and asked for help. The quick reply: you need support for the new `deepseq` package, which hasn't been merged upstream yet. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008349.html\\r\\n  - Francesco Mazzoli had a simple feature request: could we have anonymous FFI calls that don't require a name? https://mail.haskell.org/pipermail/ghc-devs/2015-February/008300.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past week include:\\r\\n\\r\\n  - Commit e22282e5d2a370395535df4051bdeb8213106d1c - GHC 7.12 will no longer ship with the `Typeable.h` header file.\\r\\n  - Commit 5d5abdca31cdb4db5303999778fa25c4a1371084 - The LLVM backend has been overhauled and updated to use LLVM 3.6 exclusively.\\r\\n\\r\\nClosed tickets the past week include: #10047, #10082, #10019, #10007, #9930, #10085, #10080, #9266, #10095, and #3649.","publish_time":1424232389,"version_time":1424232389,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150223","version":1,"title":"GHC Weekly News - 2015/02/23","body":"Hi *,\\r\\n\\r\\nIt's once again time for your sometimes-slightly-irregularly-scheduled GHC news! This past Friday marked the end of the FTP vote for GHC 7.10, there's an RC on the way (see below), we've closed out a good set of patches and tickets from users and pushed them into `HEAD`, and to top it off - it's your editor's birthday today, so that's nice!\\r\\n\\r\\nQuick note: as said above GHC HQ is expecting to make a '''third''' release candidate for GHC 7.10.1 soon in early March since the delay has allowed us to pick up some more changes and bugfixes. We plan on the final release being close to the end of March (previously end of February).\\r\\n\\r\\nThis week, GHC HQ met up again to discuss and write down our current priorities and thoughts:\\r\\n\\r\\n  - After discussing our current timetable - as we're currently hovering around the ICFP deadline - we're hoping to make our third GHC 7.10.1 release candidate on '''Friday, March 13th''', with the final release on '''Friday, March 27th'''. This was the main take away from our meeting today.\\r\\n\\r\\nWe've also had a little more list activity this week than we did before:\\r\\n\\r\\n  - The FTP debate has ended, and the results are in: GHC 7.10.1 will continue with the generalized Prelude, known as \"Plan FTP\". https://mail.haskell.org/pipermail/libraries/2015-February/025009.html\\r\\n\\r\\n  - Edward Kmett announced the `directory` package needed an active maintainer to step up - and luckily, Phil Ruffwind and Elliot Robinson did just that and stepped up as maintainers! https://mail.haskell.org/pipermail/ghc-devs/2015-February/008358.html\\r\\n\\r\\n  - Kazu Yamamoto asked about a behavioral change in `ghc-7.10` for `Data.Char` - it turns out this difference looks like it's caused by GHC 7.10 shipping an update to use Unicode 7.0 datasets. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008371.html\\r\\n\\r\\n  - Thomas Bereknyei asked about a fundamental change in the Arrow desugarer, and whether or not something like this was worth it. Jan Stolarek and Ross Paterson stepped in to speak up to some specifics Thomas had about. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008377.html\\r\\n\\r\\n  - Gabor Grief spoke up about strange behavior in the desugarer when using `RebindableSyntax` and `RankNTypes`, which Adam Gundry popped in to say may be a deeper issue due to the way typechecking and desugaring interact - https://mail.haskell.org/pipermail/ghc-devs/2015-February/008383.html\\r\\n\\r\\n   - Johan Tibell announced Cabal 1.22.1.0, which will ship with GHC 7.10. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008388.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past week include:\\r\\n\\r\\n  - Commit 1b82619bc2ff36341d916c56b0cd67a378a9c222 - The `hpc` commands now take a configurable verbosity level (merged to `ghc-7.10)\\r\\n\\r\\n  - Commit 0fa20726b0587530712677e50a56c2b03ba43095 - GHC now errors out on a module explicitly declared `Main` without a `main` export.\\r\\n\\r\\nClosed tickets the past week include: #9266, #10095, #9959, #10086, #9094, #9606, #9402, #10093, #9054, #10102, #4366, #7604, #9103, #10104, #7765, #7103, #10051, #7056, #9907, #10078, #10096, #10072, #10043, #9926, #10088, #10091, #8309, #9049, #9895, and #8539.","publish_time":1424735568,"version_time":1424735568,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150303","version":1,"title":"GHC Weekly News - 2015/03/03","body":"Hi *,\\r\\n\\r\\nIt's that time again! Today GHC HQ met on a Tuesday to avoid some\\r\\nscheduling conflicts, and that means it's time to send some news to\\r\\npeople.\\r\\n\\r\\nJust a quick reminder from last week: we're hoping to make our third\\r\\nGHC 7.10.1 release candidate on '''Friday, March 13th''', with the\\r\\nfinal release on '''Friday, March 27th'''.\\r\\n\\r\\nToday, GHC HQ met up and mostly discussed the current status of GHC 7.10 and its bugs, which you can find on the Status page: https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.1\\r\\n\\r\\nBut we've also had a little more list activity this week than we did before:\\r\\n\\r\\n  - Simon PJ showed up to tell everyone he'd be a bit busy due to upcoming ICFP deadlines! However, since it's passed as of last Friday, it looks like the coming weeks will be more normal. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008420.html\\r\\n\\r\\n  - Michael Snoyman started a thread about a serious bug that has eluded attention during the 7.10 RC period: `cabal haddock --hoogle` does not work! https://mail.haskell.org/pipermail/ghc-devs/2015-February/008412.html\\r\\n\\r\\n  - Jan Bracker is working on using the new type-checking plugins infrastructure, and had a question about the usage of what the typechecker calls `EvTerms`. Adam swooped in to respond. https://mail.haskell.org/pipermail/ghc-devs/2015-February/008414.html\\r\\n\\r\\n  - Ben Gamari has been working on #9661, but while trying to do so hit a very painful set of conditions due to the import dependency graph of the compiler, making his fix much more difficult. Simon responds with his thoughts. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008432.html\\r\\n\\r\\n  - After returning from an ICFP-writing-induced hiatus, Simon alerted us to a new paper of his describing his new, GADT-aware pattern matching checker. As usual, he'd love comments! The implementation will hopefully land in HEAD soon. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008437.html\\r\\n\\r\\n  - Nikita Karetnikov was kind enough to alert the list that he's gotten a nice, Nix/NixOS based solution to building GHC, which he's documented on the wiki. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008445.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past week include:\\r\\n\\r\\n  - Commit aead01902e1c41e85b758dbafd15e60d08956374 - the `-fwarn-unused-binds` warning was split into 3 warnings, fixing #17 (one of our oldest open tickets).\\r\\n\\r\\n  - Commit 5be8ed4da1963ed2d45a65fb61d761c977707cce - restores `integer-gmp` compatibility with GMP 4.x. This will be part of GHC 7.10.\\r\\n\\r\\n  - Commit 31d4f2e9c89e22a91f98b4a4aa0f80af6b07b60f - `make test` in the top-level directory now works as expected.\\r\\n\\r\\n  - Commit 5200bdeb26c5ec98739b14b10fc8907296bceeb9 - Replace Windows SEH handlers with VEH handlers, working uniformly across x86 and x86_64.\\r\\n\\r\\nClosed tickets the past week include: #9586, #10122, #10026, #8896, #10090, #10123, #10128, #10025, #10024, #10125, #9994, #9962, #10103, #10112, #10122, #9901, #10130, #10129, #9044, #8342, #8780, #10003, #17, #2530, #8274, and #10107.","publish_time":1425437541,"version_time":1425437541,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150310","version":1,"title":"GHC Weekly News - 2015/03/10","body":"Hi *,\\r\\n\\r\\nIt's that time again! Today GHC HQ met on a Tuesday to avoid some\\r\\nscheduling conflicts, and that means it's time to send some news to\\r\\npeople.\\r\\n\\r\\nJust a quick reminder from last week: we're hoping to make our third\\r\\nGHC 7.10.1 release candidate on '''Friday, March 13th''', with the\\r\\nfinal release on '''Friday, March 27th'''.\\r\\n\\r\\n  - Today, GHC HQ mostly talked about 7.10 bugs; HEAD is steaming along as usual with no impediments, but we've got several critical bugs we plan on landing fixes for this week; see milestone:7.10.1 for more.\\r\\n\\r\\nBut we've also had a little more list activity this week than we did before:\\r\\n\\r\\n  - Joachim Breitner asks: how do I extend the blocks in a C-- graph? Jan popped in with advice, but it looks like Joachim found a rather simple solution himself. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008467.html\\r\\n\\r\\n  - Karel Gardas wrote to the list about how to better parallelize the GHC build. For background, he's using a UltraSPARC T1-CPU/T2000 server with 32 hardware threads over 8 cores, where parallelism is a bigger win than raw single-threaded performance. But despite that, the performance is of the parallel GHC build is relatively abysmal - and Karel wants help brainstorming ideas to fix it. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008474.html\\r\\n\\r\\n  - Herbert Valerio Riedel noted that there are new git hooks in place for all developers on `git.haskell.org`, which will reject new kinds of pushes. In particular, Herbert took the time to implement commit message validation, and whitespace validation. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008480.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past week include:\\r\\n\\r\\n  - Commit eb3661f2b9f8472f3714774126ebe1183484dd85 - Re-export `<$>` from Prelude (#10113)\\r\\n\\r\\n  - Commit 479523f3c37894d63352f1718e06696f3ed63143 - Re-export `<$` from Prelude (#10113)\\r\\n\\r\\n  - Commit b359c886cd7578ed083bcedcea05d315ecaeeb54 - Custom `Typeable` solver, that keeps track of kinds (#9858)\\r\\n\\r\\n  - Commit 76b1e11943d794da61d342c072a783862a9e2a1a - Improve core linter so it catches `unsafeCoerce` problems (#9122)\\r\\n\\r\\n  - Commit 7a2d65a4d93273c89fbb1d19e282d5933c67c7ca - Define proper `MINIMAL` pragma for `class Ix` (#10142)\\r\\n\\r\\nClosed tickets the past week include: #7854, #10118, #10119, #3321, #10132, #9987, #10126, #9707, #10142, #10147, #10113, #9524, #10058, #10100, #2991, #10140, and #9122.","publish_time":1426011763,"version_time":1426011763,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150324","version":1,"title":"GHC Weekly News - 2015/03/24","body":"Hi *,\\r\\n\\r\\nIt's time for the GHC weekly news. We've had an absence of the last one, mostly due to a lot of hustle to try and get 7.10 out the door (more on that shortly throughout this post). But now we're back and everything seems to be taken care of.\\r\\n\\r\\nThis week, in the wake of the GHC 7.10 release (which is occuring EOD,\\r\\nhopefully), GHC HQ met up for a brief chat and caught up:\\r\\n\\r\\n  - This week GHC HQ met for only a very short time to discuss the pending release - it looks like all the blocking bugs have been fixed, and we've got everything triaged appropriately. You'll hopefully see the 7.10 announcement shortly after reading this.\\r\\n\\r\\nWe've also had small amounts of list activity (the past 6-8 weeks have been very, very quiet it seems):\\r\\n\\r\\n  - Your editor sent out a call for developers to fill information in on the Status page about what they plan to do. If you're working on something, please add it there! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008661.html\\r\\n\\r\\n  - Herbert Valerio Riedel asked about a possible regression regarding identifiers containing unicode subscripts - but nobody has replied! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008503.html\\r\\n\\r\\n  - Doug Burke chimed in as a new contributor and wrote down some notes on what it took to write his first patch and submit it to us - and we really appreciate the feedback, Doug! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008526.html\\r\\n\\r\\n  - Yitzchak Gale revived a thread he started a while back, which puttered out: bootstrapping GHC 7.8 with GHC 7.10. The long and short of it is, it should just about work - although we still haven't committed to this policy, it looks like Yitz and some others are quite adamant about it.\\r\\nhttps://mail.haskell.org/pipermail/ghc-devs/2015-March/008531.html\\r\\n\\r\\n  - Neil Mitchell uncovered a nasty bug in GHC 7.10.1 RC3, submitted it to us. He also wrote a fantastic [http://neilmitchell.blogspot.co.at/2015/03/finding-ghc-bug.html blog post explaining the issue]. And it was promply diagnosed, fixed, and taken care of by our own Joachim Breitner. Thank you for the fast response Joachim and Neil! https://mail.haskell.org/pipermail/ghc-devs/2015-March/008532.html\\r\\n\\r\\n  - Mark Lentczner has announced Alpha releases of the Haskell Platform 2015.2.0.0, containing GHC 7.10.1 RC3: https://mail.haskell.org/pipermail/ghc-devs/2015-March/008597.html\\r\\n\\r\\n  - Simon Peyton Jones asks: what's the current state about having simultaneous installations of a package? Simon is a bit confused as to why this is still a problem when we have all the tools to solve it, it looks like! (But read on for more): https://mail.haskell.org/pipermail/ghc-devs/2015-March/008602.html\\r\\n\\r\\n  - Michael Snoyman asks: can we get a new feature patch in GHC 7.10.2? The answer seems to be an unfortunate 'no', but with some tips, Michael may end up backporting the changes from HEAD to GHC 7.10 himself. https://mail.haskell.org/pipermail/ghc-devs/2015-March/008612.html\\r\\n\\r\\nSome noteworthy commits that went into `ghc.git` in the past two weeks include:\\r\\n\\r\\n  - Commit 71fcc4c096ec0b575522e4c2d0104ef7a71a13c5 - GHC defaults to using the `gold` linker on ARM/Android and ARM/Linux targets.\\r\\n  - Commit 9dfdd16a61e79cb03c633d442190a81fe5c0b6b8 - Bump `ghc-prim` to version 0.4.0.0.\\r\\n  - Commit 42448e3757f25735a0a5b5e2b7ee456b5e8b0039 - GHC HEAD now always looks for LLVM 3.6 specifically.\\r\\n\\r\\nClosed tickets this past week include: #9122, #10099, #10081, #9886, #9722, #9619, #9920, #9691, #8976, #9873, #9541, #9619, #9799, #9823, #10156, #1820, #6079, #9056, #9963, #10164, #10138, #10166, #10115, #9921, #9873, #9956, #9609, #7191, #10165, #10011, #8379, #10177, #9261, #10176, #10151, #9839, #8078, #8727, #9849, #10146, #9194, #10158, #7788, #9554, #8550, #10079, #10139, #10180, #10181, #10170, #10186, #10038, #10164, and #8976.","publish_time":1427250019,"version_time":1427250019,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150610","version":1,"title":"GHC Weekly News - 2015/06/10","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. The past week, GHC HQ met up for a quick catch up on 7.10.2 (which you'll want to read up on, see below), and some other technical nonsense about some work we've been doing. As a result the current weekly notes have been slow - the current priority is the next release though, which leads us to...\\r\\n\\r\\n== 7.10.2 status ==\\r\\n\\r\\n7.10.2 is '''going to be out soon''' - our current plan is to have a release candidate on '''the weekend of Saturday the 13th''', and the final release '''the next week'''. That means if you want something fixed, you'd better hollar ''very'' soon, or we're just not going to get to it!\\r\\n\\r\\nIf you're wondering what's currently been fixed/scheduled,  the [https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2 status page] shows the current set of tickets we've fixed and plan on fixing.\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n  - Edward Z. Yang has written up a new wiki page to clearly explain and document all the various confusion around package keys, package ids, etc as a result of all the new Backpack work. If you're interested in this, it's definitely worth a read. https://mail.haskell.org/pipermail/ghc-devs/2015-June/009173.html\\r\\n  \\r\\n  - Mark Lentczner sez: The Haskell Platform has finally outgrown Travis-CI, now going beyond the 50 minute build limit. Mark asks what alternatives we can use going forward. https://mail.haskell.org/pipermail/ghc-devs/2015-June/009174.html\\r\\n\\r\\n  - Jan Stolarek asks: in some cases, GHC will generate default instances or values, but that source code has no textual information location (for example, consider an `instance` clause without the `where`) - what do people think about fixing this, and are there anythings to look out for? https://mail.haskell.org/pipermail/ghc-devs/2015-June/009202.html\\r\\n\\r\\n  - David Luposchainsky has opened a new thread - about moving `fail` out of `Monad` and into its own typeclass, `MonadFail`. This change is a request that's very long in the tooth (older than the AMP or FTP changes by a landslide), but David's proposal has a clearly set out goal to tackle compatibility, warnings, and implementation. https://mail.haskell.org/pipermail/ghc-devs/2015-June/009186.html\\r\\n\\r\\n== Noteworthy commits ==\\r\\n\\r\\n  - Commit 19ec6a84d6344c2808d0d41da11956689a0e4ae9 - Fix for CAF retention when dynamically loading & unloading code\\r\\n\\r\\n  - Commit 4a0b7a10442eec3747d5f95ef186a79bb0648754 - Build: run autoreconf jobs in parallel\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n#10460, #7672, #9252, #9506, #10294, #5316, #10408, #10386, #9960, #10145, #9259, #10386, #9507, #8723, #10442, #5014, #4215, #10443, #8244, #10499, #10500, #10428, #10488, #10489, #10406, #10501, #10441, #10406, #10502, #9101, #9663, and #9945.","publish_time":1433972077,"version_time":1433972077,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20150706","version":1,"title":"GHC Weekly News - 2015/07/06","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News.  The past week, GHC HQ met up to discuss the status of the approaching 7.10.2 release.\\r\\n\\r\\n\\r\\n= 7.10.2 status =\\r\\n\\r\\nAfter quite some delay due to a number of tricky regressions in 7.10.1, 7.10.2 is nearing the finish line. Austin cut release candidate 2 on Friday and so far the only reports of trouble appear to be some validation issues, most of which have already been fixed thanks to Richard Eisenberg.\\r\\n\\r\\n7.10.2 will include a number of significant bug-fixes. These include,\\r\\n\\r\\n * #10521, where overlap of floating point STG registers weren't properly accounted for, resulting in incorrect results in some floating point computations. This was fixed by the amazing Reid Barton.\\r\\n * #10534, a type-safety hole enabling a user to write `unsafeCoerce` with data families and `coerce`. Fix due to the remarkably Richard Eisenberg.\\r\\n * #10538, where some programs would cause the simplifier to emit an empty case, resulting in runtime crashes. Fix due to the industrious Simon Peyton Jones.\\r\\n * #10527, where the simplifier would expend a great deal of effort simplifying arguments which were never demanded by the callee.\\r\\n * #10414, where a subtle point of the runtime system's black-holing mechanism resulting in hangs on a carefully constructed testcase.\\r\\n * #10236, where incorrect DWARF annotations would be generated, resulting in incorrect backtraces. Fixed by Peter Wortmann\\r\\n * #7450, where cached free variable information was being unnecessarily dropped by the specialiser, resulting in non-linear compile times for some programs.\\r\\n\\r\\nSee the [[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|status page]] for a complete listing of issues fixed in this release.\\r\\n\\r\\nIn the coming days we will being working with FP Complete to test the pre-release against Stackage. While Hackage tends to be too large to build in bulk, the selection of packages represented in Stackage is feasible to build and is likely to catch potential regressions. Hopefully this sort of large-scale validation will become common-place for future releases.\\r\\n\\r\\nIf all goes well, 7.10.2 will mark the end of the 7.10 series. However, there is always the small possibility that a major regression will be found. In this case we will cut a 7.10.3 release which will include a few [[https://ghc.haskell.org/trac/ghc/query?status=merge&milestone=7.10.3&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&report=19&order=priority|patches]] which didn't make it into 7.10.2.\\r\\n\\r\\n= Other matters =\\r\\n\\r\\nIt has been suggested in #10601 that GHC builds should ship with DWARF symbols for the base libraries and runtime system. While we all want to see this new capability in users' hands, 7.10.2 will, like 7.10.1, not be shipping with debug symbols. GHC HQ will be discussing the feasibility of including debug symbols with 7.12 in the future. In the meantime, we will be adding options to `build.mk` to make it easier for users to build their own compilers with debug-enabled libraries.\\r\\n\\r\\nIn this week's GHC meeting the effort to port GHC's build system to the [[Shake]] build system briefly came up. Despite the volume of updates on the [[https://ghc.haskell.org/trac/ghc/wiki/Building/Shake|Wiki]] Simon reports that the project is still moving along. The current state of the Shake-based build system can be found on [[https://github.com/snowleopard/shaking-up-ghc/tree/master|Github]].\\r\\n\\r\\nWhile debugging #7540 it became clear that there may be trouble lurking in the profiler. Namely when profiling GHC itself `lintAnnots` is showing up strongly where it logically should not. This was previously addressed in #10007, which was closed after a patch by Simon Marlow was merged. As it appears that this did not fully resolve the issue I'll be looking further into this.\\r\\n\\r\\n- Ben","publish_time":1436199930,"version_time":1436199930,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150706","version":2,"title":"GHC Weekly News - 2015/07/06","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News.  The past week, GHC HQ met up to discuss the status of the approaching 7.10.2 release.\\r\\n\\r\\n\\r\\n= 7.10.2 status =\\r\\n\\r\\nAfter quite some delay due to a number of tricky regressions in 7.10.1, 7.10.2 is nearing the finish line. Austin cut release candidate 2 on Friday and so far the only reports of trouble appear to be some validation issues, most of which have already been fixed thanks to Richard Eisenberg.\\r\\n\\r\\n7.10.2 will include a number of significant bug-fixes. These include,\\r\\n\\r\\n * #10521, where overlap of floating point STG registers weren't properly accounted for, resulting in incorrect results in some floating point computations. This was fixed by the amazing Reid Barton.\\r\\n * #10534, a type-safety hole enabling a user to write `unsafeCoerce` with data families and `coerce`. Fix due to the remarkably Richard Eisenberg.\\r\\n * #10538, where some programs would cause the simplifier to emit an empty case, resulting in runtime crashes. Fix due to the industrious Simon Peyton Jones.\\r\\n * #10527, where the simplifier would expend a great deal of effort simplifying arguments which were never demanded by the callee.\\r\\n * #10414, where a subtle point of the runtime system's black-holing mechanism resulting in hangs on a carefully constructed testcase.\\r\\n * #10236, where incorrect DWARF annotations would be generated, resulting in incorrect backtraces. Fixed by Peter Wortmann\\r\\n * #7450, where cached free variable information was being unnecessarily dropped by the specialiser, resulting in non-linear compile times for some programs.\\r\\n\\r\\nSee the [[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|status page]] for a complete listing of issues fixed in this release.\\r\\n\\r\\nIn the coming days we will being working with FP Complete to test the pre-release against Stackage. While Hackage tends to be too large to build in bulk, the selection of packages represented in Stackage is feasible to build and is likely to catch potential regressions. Hopefully this sort of large-scale validation will become common-place for future releases.\\r\\n\\r\\nIf all goes well, 7.10.2 will mark the end of the 7.10 series. However, there is always the small possibility that a major regression will be found. In this case we will cut a 7.10.3 release which will include a few [[https://ghc.haskell.org/trac/ghc/query?status=merge&milestone=7.10.3&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&report=19&order=priority|patches]] which didn't make it into 7.10.2.\\r\\n\\r\\n= Other matters =\\r\\n\\r\\nIt has been suggested in #10601 that GHC builds should ship with DWARF symbols for the base libraries and runtime system. While we all want to see this new capability in users' hands, 7.10.2 will, like 7.10.1, not be shipping with debug symbols. GHC HQ will be discussing the feasibility of including debug symbols with 7.12 in the future. In the meantime, we will be adding options to `build.mk` to make it easier for users to build their own compilers with debug-enabled libraries.\\r\\n\\r\\nIn this week's GHC meeting the effort to port GHC's build system to the [[Shake]] build system briefly came up. Despite the volume of updates on the [[https://ghc.haskell.org/trac/ghc/wiki/Building/Shake|Wiki]] Simon reports that the project is still moving along. The current state of the Shake-based build system can be found on [[https://github.com/snowleopard/shaking-up-ghc/tree/master|Github]].\\r\\n\\r\\nWhile debugging #7540 it became clear that there may be trouble lurking in the profiler. Namely when profiling GHC itself `lintAnnots` is showing up strongly where it logically should not. This was previously addressed in #10007, which was closed after a patch by Simon Marlow was merged. As it appears that this did not fully resolve the issue I'll be looking further into this.\\r\\n\\r\\n~ Ben","publish_time":1436199930,"version_time":1436217583,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150706","version":3,"title":"GHC Weekly News - 2015/07/06","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News.  The past week, GHC HQ met up to discuss the status of the approaching 7.10.2 release.\\r\\n\\r\\n\\r\\n= 7.10.2 status =\\r\\n\\r\\nAfter quite some delay due to a number of tricky regressions in 7.10.1, 7.10.2 is nearing the finish line. Austin cut release candidate 2 on Friday and so far the only reports of trouble appear to be some validation issues, most of which have already been fixed thanks to Richard Eisenberg.\\r\\n\\r\\n7.10.2 will include a number of significant bug-fixes. These include,\\r\\n\\r\\n * #10521, where overlap of floating point STG registers weren't properly accounted for, resulting in incorrect results in some floating point computations. This was fixed by the amazing Reid Barton.\\r\\n * #10534, a type-safety hole enabling a user to write `unsafeCoerce` with data families and `coerce`. Fix due to the remarkable Richard Eisenberg.\\r\\n * #10538, where some programs would cause the simplifier to emit an empty case, resulting in runtime crashes. Fix due to the industrious Simon Peyton Jones.\\r\\n * #10527, where the simplifier would expend a great deal of effort simplifying arguments which were never demanded by the callee.\\r\\n * #10414, where a subtle point of the runtime system's black-holing mechanism resulting in hangs on a carefully constructed testcase.\\r\\n * #10236, where incorrect DWARF annotations would be generated, resulting in incorrect backtraces. Fixed by Peter Wortmann\\r\\n * #7450, where cached free variable information was being unnecessarily dropped by the specialiser, resulting in non-linear compile times for some programs.\\r\\n\\r\\nSee the [[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|status page]] for a complete listing of issues fixed in this release.\\r\\n\\r\\nIn the coming days we will being working with FP Complete to test the pre-release against Stackage. While Hackage tends to be too large to build in bulk, the selection of packages represented in Stackage is feasible to build and is likely to catch potential regressions. Hopefully this sort of large-scale validation will become common-place for future releases.\\r\\n\\r\\nIf all goes well, 7.10.2 will mark the end of the 7.10 series. However, there is always the small possibility that a major regression will be found. In this case we will cut a 7.10.3 release which will include a few [[https://ghc.haskell.org/trac/ghc/query?status=merge&milestone=7.10.3&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&report=19&order=priority|patches]] which didn't make it into 7.10.2.\\r\\n\\r\\n= Other matters =\\r\\n\\r\\nIt has been suggested in #10601 that GHC builds should ship with DWARF symbols for the base libraries and runtime system. While we all want to see this new capability in users' hands, 7.10.2 will, like 7.10.1, not be shipping with debug symbols. GHC HQ will be discussing the feasibility of including debug symbols with 7.12 in the future. In the meantime, we will be adding options to `build.mk` to make it easier for users to build their own compilers with debug-enabled libraries.\\r\\n\\r\\nIn this week's GHC meeting the effort to port GHC's build system to the [[Shake]] build system briefly came up. Despite the volume of updates on the [[https://ghc.haskell.org/trac/ghc/wiki/Building/Shake|Wiki]] Simon reports that the project is still moving along. The current state of the Shake-based build system can be found on [[https://github.com/snowleopard/shaking-up-ghc/tree/master|Github]].\\r\\n\\r\\nWhile debugging #7540 it became clear that there may be trouble lurking in the profiler. Namely when profiling GHC itself `lintAnnots` is showing up strongly where it logically should not. This was previously addressed in #10007, which was closed after a patch by Simon Marlow was merged. As it appears that this did not fully resolve the issue I'll be looking further into this.\\r\\n\\r\\n~ Ben","publish_time":1436199930,"version_time":1436261706,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150721","version":1,"title":"GHC Weekly News - 2015/07/21","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. Today GHC HQ met\\r\\nto discuss the status of the imminent 7.10.2 release.\\r\\n\\r\\n= 7.10.2 Status =\\r\\n\\r\\nIn the past weeks we have been busily tracking down a number of regressions in\\r\\nthe `ghc-7.10` branch. At this point we have built up an impressive\\r\\n[[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|list]] of fixes.\\r\\nThanks to everyone who has helped in this process!\\r\\n\\r\\nIn addition resolving to a number of simplifier regressions and portability issues\\r\\n(some mentioned in the Weekly News from 6 July), GHC 7.10.2 should be the first\\r\\nrelease which works out-of-the-box with GHCJS, thanks to a fix from Luite Stegeman.\\r\\nMoreover, we will have support for running in even the most minimal container\\r\\nenvironment (#10623).\\r\\n\\r\\nAt this point we have successfully tested the pre-release against Stackage\\r\\n(thanks for Michael Snoyman and Herbert Valerio Riedel for making this possible)\\r\\nand have found no major issues. A source tarball will be finalized and sent to\\r\\nthe binary builders today. With luck we will have releasable binaries by the end of\\r\\nthe week.\\r\\n\\r\\n= 7.11 Things =\\r\\n\\r\\n== Testing ==\\r\\nThomas Miedema has been doing some amazing work fixing some long-standing\\r\\nvalidation failures on the ``master`` branch. Moreover, he has been examining\\r\\nthe viability of enabling\\r\\n[https://phabricator.haskell.org/D1074 larger swaths] of the testsuite in\\r\\nHarbormaster validations.\\r\\n\\r\\nIn addition, Thomas has been doing some great work smoothing over a variety of\\r\\nrough edges in the build system and generally keeping things running smoothly.\\r\\nThanks Thomas!\\r\\n\\r\\n== Typeable implementation ==\\r\\nAnother subject of discussion in this week's GHC call was\\r\\n[https://phabricator.haskell.org/D757 Phabricator D757], a long-languishing\\r\\nchange which moves the generation of `Typeable` instances from the use site to\\r\\nthe definition site. This change involves a trade-off as it moves compilation\\r\\neffort to the defining module, which will adversely affect compilation times of\\r\\nmodules defining many types. Moreover, in the event that `Typeable` is never actually used\\r\\nthis time is wasted effort. That being said, the current design of generating\\r\\n`Typeable` instances at the point of use makes the class a bit of a black sheep\\r\\nat the moment.\\r\\n\\r\\n== Runtime system matters ==\\r\\nThis week Simon Marlow will merge his [https://phabricator.haskell.org/D524 D524],\\r\\na rework of the runtime system's allocator which he reports has improved\\r\\nperformance significantly on his workload. This commit splits the concerns of\\r\\nreserving address space and asking for backing space from the operating system.\\r\\nWhile the former is relatively cheap, the latter can be quite expensive.\\r\\nConsequently, his rework allocates a large chunk of addressing space up front\\r\\nand then incrementally commits it as needed. Interested readers are encouraged\\r\\nto look at the patch, which offers a nice glimpse into the inner workings of\\r\\nGHC's memory allocator.\\r\\n\\r\\nSimon also Phab:D1076, which should improve garbage collector performance by\\r\\nreworking the logic responsible for scavenging static objects. This work will\\r\\nbe merged shortly.\\r\\n\\r\\nAlso discussed was the profiler mis-attribution issue (#10007) mentioned in the\\r\\nWeekly News from 6 July 2015. Peter Wortmann is currently looking at this issue,\\r\\nwhich ends up being due to an infelicity in the semantics implemented by the\\r\\nruntime system. Simon Marlow expressed that he did not know of a way to resolve\\r\\nthis that isn't quite invasive. We will have to see what Peter proposes.\\r\\n\\r\\n== Applicative `do` ==\\r\\n\\r\\nFor some time now Simon Marlow has been working on\\r\\n[https://phabricator.haskell.org/D729 implementing] the [[ApplicativeDo]]\\r\\nproposal. Today in the call we discussed the status of this work and concluded\\r\\nthat while some refactoring is likely possible, the work can be merged as-is.\\r\\nHopefully at some point in the next few weeks this work will land.\\r\\n\\r\\n== Haddock comments for GADT constructors ==\\r\\n\\r\\nIt came to our attention that the GHC parser was unable to parse Haddock\\r\\ncomments on GADT constructors. As it turns out, this is a rather long-standing\\r\\nproblem. Despite this fact, the [https://phabricator.haskell.org/D1086 fix]\\r\\nended up being quite straightforward and will be in 7.12.\\r\\n\\r\\n= Backwards Compatibility =\\r\\n\\r\\nIn general one should be able to compile the current GHC `master` branch with\\r\\nthe last two compiler releases. Recently, however, the reality is a bit less\\r\\nclear-cut: while the current `master` branch GHC will technically **build** with\\r\\nGHC 7.8 and 7.10, the tree does not necessarily pass the `validate` script due\\r\\nto a variety of imports rendered redundant by AMP and FTP. Moreover, the\\r\\nofficial policy on backwards compatibility is rather well-hidden on the\\r\\n[[Commentary/CodingStyle]] page.\\r\\n\\r\\nThis was discussed in today's meeting and it was decided that we will in the future\\r\\nmaintain full validation-compatibility with the previous two releases. To ease this\\r\\nwe will relax the use of `-Werror` when building the stage 1 compiler.\\r\\n\\r\\nOn a related note, this week Thomas Miedema\\r\\n[[https://phabricator.haskell.org/D904|ripped out]] some `#ifdefs` for GHC 7.6\\r\\ncompatibility from the `master` branch. Be aware that you will now need one of\\r\\nthese versions to build the `master` branch.\\r\\n\\r\\n= Mac OS X El Capitan support =\\r\\n\\r\\nIt is well-known that the next Mac OS X release, El Capitan, will default to\\r\\n\"root-less\" mode, a security feature which restricts the operations available to\\r\\neven the `root` user. As a result of this feature some system-calls fail with\\r\\n`EPERM` instead of the usual `EACCES` in the El Capitan developer preview. This\\r\\nchange uncovered a bug in the `unix` library where `EPERM` was not treated\\r\\nsimilarly to `EACCES`. This was\\r\\n[[https://github.com/haskell/unix/pull/18|fixed]] in November 2014, a fix which\\r\\nis included in GHC 7.10.1.\\r\\n\\r\\nHowever, there have been a\\r\\n[https://mail.haskell.org/pipermail/ghc-devs/2015-July/009403.html few calls]\\r\\nfor a bugfix release of the 7.8 series including the updated `unix`. We\\r\\ndiscussed this in the GHC call today and concluded that we would not make such a\\r\\nrelease. Given that El Capitan is not yet released, it seems to early to put\\r\\ndeveloper time into producing a new release. We would suggest that any El\\r\\nCapitan user unable to update to GHC 7.10.1 or newer disable root-less mode for\\r\\nthe time being. This can be accomplished with,\\r\\n\\r\\n{{{\\r\\nsudo nvram boot-args=\"rootless=0\"\\r\\n}}}\\r\\n\\r\\n\\r\\n= Infrastructure =\\r\\n\\r\\nRecently it came to our attention that one of the build machines used by\\r\\nHarbormaster (Phabricator's build mechanism) was still running GHC 7.6. If you\\r\\nhave seen strange validation issues on Differential's in the past, this is may\\r\\nbe the cause. As of today this is fixed; all Harbormaster validations are now\\r\\nbeing built with GHC 7.8.4.\\r\\n\\r\\nHarbormaster has historically had trouble working with Differentials which\\r\\nchanged submodule revisions. This has made testing revisions involving submodules quite tricky. Thanks to a\\r\\n[https://github.com/haskell-infra/phab-ghc-builder/pull/2 patch] from Adam \\r\\n\\r\\nHerbert Valerio Riedel has been making great strides improving the\\r\\nresponsiveness of Trac. A Trac upgrade, a move to Postresql, and some fiddling\\r\\nwith the WSGI configuration should result in a much better experience for\\r\\neveryone.\\r\\n\\r\\n~ Ben\\r\\n\\r\\n","publish_time":1437506438,"version_time":1437506438,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150721","version":2,"title":"GHC Weekly News - 2015/07/21","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. Today GHC HQ met\\r\\nto discuss the status of the imminent 7.10.2 release.\\r\\n\\r\\n= 7.10.2 Status =\\r\\n\\r\\nIn the past weeks we have been busily tracking down a number of regressions in\\r\\nthe `ghc-7.10` branch. At this point we have built up an impressive\\r\\n[[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|list]] of fixes.\\r\\nThanks to everyone who has helped in this process!\\r\\n\\r\\nIn addition to resolving a number of simplifier regressions and portability issues\\r\\n(some mentioned in the Weekly News from 6 July), GHC 7.10.2 should be the first\\r\\nrelease which works out-of-the-box with GHCJS, thanks to a fix from Luite Stegeman.\\r\\nMoreover, we will have support for running in even the most minimal container\\r\\nenvironment (#10623).\\r\\n\\r\\nAt this point we have successfully tested the pre-release against Stackage\\r\\n(thanks for Michael Snoyman and Herbert Valerio Riedel for making this possible)\\r\\nand have found no major issues. A source tarball will be finalized and sent to\\r\\nthe binary builders today. With luck we will have releasable binaries by the end of\\r\\nthe week.\\r\\n\\r\\n= 7.11 Things =\\r\\n\\r\\n== Testing ==\\r\\nThomas Miedema has been doing some amazing work fixing some long-standing\\r\\nvalidation failures on the ``master`` branch. Moreover, he has been examining\\r\\nthe viability of enabling\\r\\n[https://phabricator.haskell.org/D1074 larger swaths] of the testsuite in\\r\\nHarbormaster validations.\\r\\n\\r\\nIn addition, Thomas has been doing some great work smoothing over a variety of\\r\\nrough edges in the build system and generally keeping things running smoothly.\\r\\nThanks Thomas!\\r\\n\\r\\n== Typeable implementation ==\\r\\nAnother subject of discussion in this week's GHC call was\\r\\n[https://phabricator.haskell.org/D757 Phabricator D757], a long-languishing\\r\\nchange which moves the generation of `Typeable` instances from types' use sites to\\r\\ntheir definition sites. This change involves a trade-off as it moves compilation\\r\\neffort to the defining module, which will adversely affect compilation times of\\r\\nmodules defining many types. Moreover, in the event that `Typeable` is never actually used\\r\\nthis time is wasted effort. That being said, the current design of generating\\r\\n`Typeable` instances at the point of use makes the class a bit of a black sheep\\r\\nat the moment.\\r\\n\\r\\n== Runtime system matters ==\\r\\nThis week Simon Marlow will merge his [https://phabricator.haskell.org/D524 D524],\\r\\na rework of the runtime system's allocator which he reports has improved\\r\\nperformance significantly in his workloads. This commit splits the concerns of\\r\\nreserving address space and requesting backing memory for this address space. While the former is relatively cheap, the latter can be quite expensive due to page-table setup.\\r\\nConsequently, his rework allocates a large chunk of addressing space up front\\r\\nand then incrementally commits it as needed. Interested readers are encouraged\\r\\nto look at the patch, which offers a nice glimpse into the inner workings of\\r\\nGHC's memory allocator.\\r\\n\\r\\nSimon also has finished Phab:D1076, which should improve garbage collector performance by\\r\\nreworking the logic responsible for scavenging static objects. This work will\\r\\nbe merged shortly.\\r\\n\\r\\nAlso discussed was the profiler mis-attribution issue mentioned in the\\r\\nWeekly News from 6 July 2015 (#10007). Peter Wortmann is currently looking at this issue,\\r\\nwhich ends up being due to an infelicity in the semantics implemented by the\\r\\nruntime system. Simon Marlow expressed that he did not know of a way to resolve\\r\\nthis that isn't quite invasive. We will have to see what Peter proposes.\\r\\n\\r\\n== Applicative `do` ==\\r\\n\\r\\nFor some time now Simon Marlow has been working on\\r\\n[https://phabricator.haskell.org/D729 implementing] the [[ApplicativeDo]]\\r\\nproposal. Today in the call we discussed the status of this work and concluded\\r\\nthat while some refactoring is likely possible, the work can be merged as-is.\\r\\nHopefully at some point in the next few weeks this work will land.\\r\\n\\r\\n== Haddock comments for GADT constructors ==\\r\\n\\r\\nIt came to our attention that the GHC parser was unable to parse Haddock\\r\\ncomments attached to GADT constructors. As it turns out, this is a rather long-standing\\r\\nproblem. Despite this fact, the [https://phabricator.haskell.org/D1086 fix]\\r\\nended up being quite straightforward and will be in 7.12.\\r\\n\\r\\n= Backwards Compatibility =\\r\\n\\r\\nIn general one should be able to compile the current GHC `master` branch with\\r\\nthe last two compiler releases. Recently, however, the reality is a bit less\\r\\nclear-cut: while the current `ghc-7.10` branch GHC will technically **build** with\\r\\nGHC 7.6 and 7.8, the tree does not necessarily pass the `validate` script due\\r\\nto a variety of imports rendered redundant by AMP and FTP. Moreover, the\\r\\nofficial policy on backwards compatibility is rather well-hidden on the\\r\\n[[Commentary/CodingStyle]] page.\\r\\n\\r\\nThis was discussed in today's meeting and it was decided that we will in the future\\r\\nmaintain full validation-compatibility with the previous two releases. To ease this\\r\\nwe will relax the use of `-Werror` when building the stage 1 compiler.\\r\\n\\r\\nOn a related note, this week Thomas Miedema\\r\\n[https://phabricator.haskell.org/D904 ripped out] some `#ifdefs` for GHC 7.6\\r\\ncompatibility from the `master` branch. Be aware that you will now need GHC 7.8 or newer to build `master`.\\r\\n\\r\\n= Mac OS X El Capitan support =\\r\\n\\r\\nIt is well-known that the next Mac OS X release, El Capitan, will default to\\r\\n\"root-less\" mode, a security feature which restricts the operations available to\\r\\neven the `root` user. As a result of this feature some system calls in the El Capitan developer preview fail with\\r\\n`EPERM` instead of the usual `EACCES`. This\\r\\nchange uncovered a bug in the `unix` library where `EPERM` was not treated\\r\\nsimilarly to `EACCES`. This was\\r\\n[[https://github.com/haskell/unix/pull/18|fixed]] in November 2014, a fix which\\r\\nis included in GHC 7.10.1.\\r\\n\\r\\nHowever, there have been a\\r\\n[https://mail.haskell.org/pipermail/ghc-devs/2015-July/009403.html few calls]\\r\\non `ghc-devs` for a bugfix release of the 7.8 series including the updated `unix`. We\\r\\ndiscussed this in the call today and concluded that we would not make such a\\r\\nrelease. Given that El Capitan is not yet released and the issue is fixed in 7.10, it doesn't seem worthwhile to put more developer time into 7.8. We would suggest that any El\\r\\nCapitan user unable to update to GHC 7.10.1 or newer disable root-less mode for\\r\\nthe time being. This can be accomplished with,\\r\\n\\r\\n{{{\\r\\nsudo nvram boot-args=\"rootless=0\"\\r\\n}}}\\r\\n\\r\\n\\r\\n= Infrastructure =\\r\\n\\r\\nRecently it came to our attention that one of the build machines used by\\r\\nHarbormaster (Phabricator's build mechanism) was still running GHC 7.6. If you\\r\\nhave seen strange validation issues on Harbormaster builds in the past, this is may\\r\\nbe the cause. As of today this is fixed; all Harbormaster validations are now\\r\\nbeing built with GHC 7.8.4.\\r\\n\\r\\nHarbormaster has historically had trouble working with Differentials which\\r\\nchanged submodule revisions. This has made testing revisions involving submodules quite tricky. Thanks to a\\r\\n[https://github.com/haskell-infra/phab-ghc-builder/pull/2 patch] from Adam \\r\\n\\r\\nHerbert Valerio Riedel has been making great strides improving the\\r\\nresponsiveness of Trac. A Trac upgrade, a move to Postresql, and some fiddling\\r\\nwith the WSGI configuration should result in a much better experience for\\r\\neveryone.\\r\\n\\r\\nHave a great week!\\r\\n\\r\\n~ Ben\\r\\n\\r\\n","publish_time":1437506438,"version_time":1437507258,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150721","version":3,"title":"GHC Weekly News - 2015/07/21","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. Today GHC HQ met\\r\\nto discuss the status of the imminent 7.10.2 release.\\r\\n\\r\\n= 7.10.2 Status =\\r\\n\\r\\nIn the past weeks we have been busily tracking down a number of regressions in\\r\\nthe `ghc-7.10` branch. At this point we have built up an impressive\\r\\n[[https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-7.10.2|list]] of fixes.\\r\\nThanks to everyone who has helped in this process!\\r\\n\\r\\nIn addition to resolving a number of simplifier regressions and portability issues\\r\\n(some mentioned in the Weekly News from 6 July), GHC 7.10.2 should be the first\\r\\nrelease which works out-of-the-box with GHCJS, thanks to a fix from Luite Stegeman.\\r\\nMoreover, we will have support for running in even the most minimal container\\r\\nenvironment (#10623).\\r\\n\\r\\nAt this point we have successfully tested the pre-release against Stackage\\r\\n(thanks for Michael Snoyman and Herbert Valerio Riedel for making this possible)\\r\\nand have found no major issues. A source tarball will be finalized and sent to\\r\\nthe binary builders today. With luck we will have releasable binaries by the end of\\r\\nthe week.\\r\\n\\r\\n= 7.11 Things =\\r\\n\\r\\n== Testing ==\\r\\nThomas Miedema has been doing some amazing work fixing some long-standing\\r\\nvalidation failures on the ``master`` branch. Moreover, he has been examining\\r\\nthe viability of enabling\\r\\n[https://phabricator.haskell.org/D1074 larger swaths] of the testsuite in\\r\\nHarbormaster validations.\\r\\n\\r\\nIn addition, Thomas has been doing some great work smoothing over a variety of\\r\\nrough edges in the build system and generally keeping things running smoothly.\\r\\nThanks Thomas!\\r\\n\\r\\n== Typeable implementation ==\\r\\nAnother subject of discussion in this week's GHC call was\\r\\n[https://phabricator.haskell.org/D757 Phabricator D757], a long-languishing\\r\\nchange which moves the generation of `Typeable` instances from types' use sites to\\r\\ntheir definition sites. This change involves a trade-off as it moves compilation\\r\\neffort to the defining module, which will adversely affect compilation times of\\r\\nmodules defining many types. Moreover, in the event that `Typeable` is never actually used\\r\\nthis time is wasted effort. That being said, the current design of generating\\r\\n`Typeable` instances at the point of use makes the class a bit of a black sheep\\r\\nat the moment.\\r\\n\\r\\n== Runtime system matters ==\\r\\nThis week Simon Marlow will merge his [https://phabricator.haskell.org/D524 D524],\\r\\na rework of the runtime system's allocator which he reports has improved\\r\\nperformance significantly in his workloads. This commit splits the concerns of\\r\\nreserving address space and requesting backing memory for this address space. While the former is relatively cheap, the latter can be quite expensive due to page-table setup.\\r\\nConsequently, his rework allocates a large chunk of addressing space up front\\r\\nand then incrementally commits it as needed. Interested readers are encouraged\\r\\nto look at the patch, which offers a nice glimpse into the inner workings of\\r\\nGHC's memory allocator.\\r\\n\\r\\nSimon also has finished Phab:D1076, which should improve garbage collector performance by\\r\\nreworking the logic responsible for scavenging static objects. This work will\\r\\nbe merged shortly.\\r\\n\\r\\nAlso discussed was the profiler mis-attribution issue mentioned in the\\r\\nWeekly News from 6 July 2015 (#10007). Peter Wortmann is currently looking at this issue,\\r\\nwhich ends up being due to an infelicity in the semantics implemented by the\\r\\nruntime system. Simon Marlow expressed that he did not know of a way to resolve\\r\\nthis that isn't quite invasive. We will have to see what Peter proposes.\\r\\n\\r\\n== Applicative `do` ==\\r\\n\\r\\nFor some time now Simon Marlow has been working on\\r\\n[https://phabricator.haskell.org/D729 implementing] the [[ApplicativeDo]]\\r\\nproposal. Today in the call we discussed the status of this work and concluded\\r\\nthat while some refactoring is likely possible, the work can be merged as-is.\\r\\nHopefully at some point in the next few weeks this work will land.\\r\\n\\r\\n== Haddock comments for GADT constructors ==\\r\\n\\r\\nIt came to our attention that the GHC parser was unable to parse Haddock\\r\\ncomments attached to GADT constructors. As it turns out, this is a rather long-standing\\r\\nproblem. Despite this fact, the [https://phabricator.haskell.org/D1086 fix]\\r\\nended up being quite straightforward and will be in 7.12.\\r\\n\\r\\n= Backwards Compatibility =\\r\\n\\r\\nIn general one should be able to compile the current GHC `master` branch with\\r\\nthe last two compiler releases. Recently, however, the reality is a bit less\\r\\nclear-cut: while the current `ghc-7.10` branch GHC will technically **build** with\\r\\nGHC 7.6 and 7.8, the tree does not necessarily pass the `validate` script due\\r\\nto a variety of imports rendered redundant by AMP and FTP. Moreover, the\\r\\nofficial policy on backwards compatibility is rather well-hidden on the\\r\\n[[Commentary/CodingStyle]] page.\\r\\n\\r\\nThis was discussed in today's meeting and it was decided that we will in the future\\r\\nmaintain full validation-compatibility with the previous two releases. To ease this\\r\\nwe will relax the use of `-Werror` when building the stage 1 compiler.\\r\\n\\r\\nOn a related note, this week Thomas Miedema\\r\\n[https://phabricator.haskell.org/D904 ripped out] some `#ifdefs` for GHC 7.6\\r\\ncompatibility from the `master` branch. Be aware that you will now need GHC 7.8 or newer to build `master`.\\r\\n\\r\\n= Mac OS X El Capitan support =\\r\\n\\r\\nIt is well-known that the next Mac OS X release, El Capitan, will default to\\r\\n\"root-less\" mode, a security feature which restricts the operations available to\\r\\neven the `root` user. As a result of this feature some system calls in the El Capitan developer preview fail with\\r\\n`EPERM` instead of the usual `EACCES`. This\\r\\nchange uncovered a bug in the `unix` library where `EPERM` was not treated\\r\\nsimilarly to `EACCES`. This was\\r\\n[[https://github.com/haskell/unix/pull/18|fixed]] in November 2014, a fix which\\r\\nis included in GHC 7.10.1.\\r\\n\\r\\nHowever, there have been a\\r\\n[https://mail.haskell.org/pipermail/ghc-devs/2015-July/009403.html few calls]\\r\\non `ghc-devs` for a bugfix release of the 7.8 series including the updated `unix`. We\\r\\ndiscussed this in the call today and concluded that we would not make such a\\r\\nrelease. Given that El Capitan is not yet released and the issue is fixed in 7.10, it doesn't seem worthwhile to put more developer time into 7.8. We would suggest that any El\\r\\nCapitan user unable to update to GHC 7.10.1 or newer disable root-less mode for\\r\\nthe time being. This can be accomplished with,\\r\\n\\r\\n{{{\\r\\nsudo nvram boot-args=\"rootless=0\"\\r\\n}}}\\r\\n\\r\\n\\r\\n= Infrastructure =\\r\\n\\r\\nRecently it came to our attention that one of the build machines used by\\r\\nHarbormaster (Phabricator's build mechanism) was still running GHC 7.6. If you\\r\\nhave seen strange validation issues on Harbormaster builds in the past, this is may\\r\\nbe the cause. As of today this is fixed; all Harbormaster validations are now\\r\\nbeing built with GHC 7.8.4.\\r\\n\\r\\nHarbormaster has historically had trouble working with Differentials which\\r\\nchanged submodule revisions. This has made testing revisions involving submodules quite tricky. Thanks to a\\r\\n[https://github.com/haskell-infra/phab-ghc-builder/pull/2 patch] from Adam Sandberg Eriksson Harbormaster can now grab submodule commits from non-upstream repositories if set in `.gitmodules`.\\r\\n\\r\\nHerbert Valerio Riedel has been making great strides improving the\\r\\nresponsiveness of Trac. A Trac upgrade, a move to Postresql, and some fiddling\\r\\nwith the WSGI configuration should result in a much better experience for\\r\\neveryone.\\r\\n\\r\\nHave a great week!\\r\\n\\r\\n~ Ben\\r\\n\\r\\n","publish_time":1437506438,"version_time":1437518223,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150729","version":1,"title":"GHC Weekly News - 2015/07/29","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. Today GHC HQ met to discuss plans post-7.10.2.\\r\\n\\r\\n= GHC 7.10.2 release =\\r\\n\\r\\nGHC 7.10.2 has been [https://mail.haskell.org/pipermail/haskell/2015-July/024634.html released]!\\r\\n\\r\\nFeel free to grab a [https://www.haskell.org/ghc/download_ghc_7_10_2 tarball] and enjoy! See the [https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/release-7-10-2.html release notes] for discussion of what has changed.\\r\\n\\r\\nAs always, if you suspect that you have found a regression don't hesitate to [https://ghc.haskell.org/trac/ghc/wiki/ReportABug open a Trac ticket]. We are especially interested in performance regressions with fairly minimal reproduction cases.\\r\\n\\r\\n== GHC 7.10.2 and the `text` package ==\\r\\n\\r\\nA few days ago a report came in of long compilations times under 7.10.2 on a program with many `Text` literals (#10528). This ended up being due to a change in the simplifier which caused it to perform rule rewrites on the left-hand-side of other rules. While this is questionable (read \"buggy\") behavior, it doesn't typically cause trouble so long as rules are properly annotated with phase control numbers to ensure they are performed in the correct order.  Unfortunately, it turns out that the rules provided by the `text` package for efficiently handling string literals did not include phase control annotations. This resulted in a rule from `base` being performed on the literal rules, which rendered the literal rules ineffective. The simplifier would then  expend a great deal of effort trying to simplify the rather complex terms that remained.\\r\\n\\r\\nThankfully, the [https://github.com/bos/text/pull/129/files fix] is quite straightforward: ensure that the the text literal rules fire in the first simplifier phase (phase 2). This avoids interference from the `base` rules, allowing them to fire as expected. \\r\\n\\r\\nThis fix is now present in `text-1.2.1.2`. **Users of GHC 7.10.2 should be use this release if at all possible.** Thanks to `text`'s maintainer, Bryan O'Sullivan for taking time out of his vacation to help me get this new release out.\\r\\n\\r\\nWhile this mis-behaviour was triggered by a bug in GHC, a similar outcome could have arisen even without this bug. This highlights the importance of including phase control annotations on `INLINE` and `RULE` pragmas: Without them the compiler may choose the rewrite in an order that you did not anticipate. This has also drawn attention to a few shortcomings in the current rewrite rule mechanism, which lacks the expressiveness to encode complex ordering relationships between rules. This limitation pops up in a number of places, including when trying to write rules on class-overloaded functions. Simon Peyton Jones is currently pondering possible solutions to this on #10595.\\r\\n\\r\\n= StrictData =\\r\\n\\r\\nThis week we merged the long-anticipated `-XStrictData` extension (Phab:D1033) by Adam Sandberg Ericsson. This implements a subset of the [StrictPragma] proposal initiated by Johan Tibell.In particular, `StrictData` allows a user to specify that datatype fields should be strict-by-default on a per-module basis, greatly reducing the syntactic noise introduced by this common pattern. In addition to implementing a useful feature, the patch ended up being a nice clean-up of the GHC's handling of strictness annotations.\\r\\n\\r\\nWhat remains of this proposal is the more strong `-XStrict` extension which essentially makes all bindings strict-by-default. Adam has indicated that he may take up this work later this summer.\\r\\n\\r\\n= AMP-related performance regression =\\r\\n\\r\\nIn late May Herbert Valerio Riedel opened Phab:D924, which removed an explicit definition for `mapM` in the `[]` `Traversable` instance, as well as redefined `mapM_` in terms of `traverse_` to [https://mail.haskell.org/pipermail/libraries/2015-May/025708.html bring consistency] with the post-AMP world. The patch remains unmerged, however, due to a failing ghci testcase. It turns out the regression is due to the redefinition of `mapM_`, which uses `(*>)` where `(>>)` was once used. This tickles poor behavior in ghci's `ByteCodeAsm` module. The problem can be resolved by defining `(*>) = (>>)` in the `Applicative Assembler` instance (e.g. Phab:1097). That being said, the fact that this change has already exposed performance regressions raises doubts as to whether it is prudent.\\r\\n\\r\\n= GHC Performance work =\\r\\n\\r\\nOver the last month or so I have been working on nailing down a variety of performance issues in GHC and the code it produces. This has resulted in a number of patches which in some cases dramatically improve compilation time (namely Phab:1012 and Phab:D1041). Now since 7.10.2 is out I'll again be spending most of my time on these issues. We have heard a number of reports that GHC 7.10 has regressed on real-world programs. If you have a reproducible performance regression that you would like to see addressed please open a Trac ticket. \\r\\n\\r\\n= Merged patches =\\r\\n\\r\\n * Phab:D1028: Fixity declarations are now allowed for infix data constructors in GHCi (thanks to Thomas Miedema)\\r\\n * Phab:D1061: Fix a long-standing correctness issue arising when pattern matching on floating point values\\r\\n * Phab:D1085: Allow programs to run in environments lacking iconv (thanks to Reid Barton)\\r\\n * Phab:D1094: Improve code generation in `integer-gmp` (thanks to Reid Barton)\\r\\n * Phab:D1068: Implement support for the `MO_U_Mul2` `MachOp` in the LLVM backend (thanks to Michael Terepeta)\\r\\n * Phab:D524: Improve runtime system allocator performance with two-step allocation (thanks to Simon Marlow)\\r\\n\\r\\nThat's all for this time. Enjoy your week!\\r\\n\\r\\nCheers,\\r\\n\\r\\n - Ben\\r\\n \\r\\n","publish_time":1438185139,"version_time":1438185139,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150806","version":1,"title":"GHC Weekly News - 2015/08/06","body":"GHC Weekly News - 6 Aug 2015\\r\\n\\r\\nHello *,\\r\\n\\r\\nHere is a rather belated Weekly News which I found sitting nearly done on my\\r\\nwork-queue. I hope this will make for a good read despite its age. The next\\r\\nedition of the Weekly News will be posted soon.\\r\\n\\r\\n== Warnings for missed specialization opportunities\\r\\n\\r\\nSimon Peyton Jones recently\\r\\n[a4261549afaee56b00fbea1b4bc1a07c95e60929 introduced] a warning in `master` to\\r\\nalert users when the compiler was unable to specialize an imported binding\\r\\ndespite it being marked as `INLINEABLE`. This change was motivated by #10720,\\r\\nwhere the reporter observed poor runtime performance despite taking care to\\r\\nensure his binding could be inlined. Up until now, ensuring that the compiler's\\r\\noptimizations meet the user's expectation would require a careful look at the\\r\\nproduced Core. With this change the user is notified of exactly where the\\r\\ncompiler had to stop specializing, along with a helpful hint on where to add a\\r\\n`INLINABLE` pragma.\\r\\n\\r\\n== Ticky-Ticky profiling\\r\\n\\r\\nRecently I have been looking into breathing life back into GHC's [wiki:Debugging/TickyTicky ticky-ticky]\\r\\nprofiling mechanism. When enabled, ticky-ticky maintains low-level counters of various runtime-system events. These include closure entries, updates, and allocations. While ticky doesn't provide nearly the detail that the cost-center profiler allows, it is invisible to the Core-to-Core optimization passes and has minimal runtime overhead (manifested as a bit more memory traffic due to counter updates). For this reason, the ticky-ticky profiler can be a useful tool for those working on the Core simplifier. \\r\\n\\r\\nSadly, ticky-ticky has fallen into quite a state of disrepair in recent years as the runtime system and native code generator have evolved. As the beginning of an effort to resuscitate the ticky-ticky profiler I've started putting together a [https://ghc.haskell.org/trac/ghc/wiki/Debugging/TickyTicky#Ticky-Tickycounters list] of the counters currently implemented and whether they can be expected to do something useful. Evaluating the functionality of these counters is non-trivial, however, so this will be an on-going effort.\\r\\n\\r\\nOne of our goals is to eventually do a systematic comparison of the heap allocation numbers produced by the ticky-ticky profiler, the cost-center profiler, and ticky-ticky. While this will help validate some of the more coarse-grained counters exposed by ticky, most of them will need a more thorough read-through of the runtime system to verify.\\r\\n\\r\\n== `integer-gmp` Performance\\r\\n\\r\\nSince the 7.10.2 release much of my effort has been devoted to characterizing the performance of various benchmarks over various GHC versions. This is part of an effort to find places where we have regressed in the past few versions. One product of this effort is a complete comparison of [http://home.smart-cactus.org/~ben/nofib.html results] from our `nofib` benchmark suite ranging from 7.4.2 to 7.10.1.\\r\\n\\r\\nThe good news is there are essentially no disastrous regressions. Moreover, on the mean runtimes are over 10% faster than they were in 7.4.2. There are, however, a few cases which have regressed.  The runtime of the `integer` test, for instance, has increased by 7%. Looking at the trend across versions, it becomes apparent that the regression began with 7.10.1.\\r\\n\\r\\nOne of the improvements that was introduced with 7.10 was a rewrite of the `integer-gmp` library, which this benchmark tests heavily. To isolate this potential cause, I recompiled GHC 7.10.1 with the old `integer-gmp-0.5`. Comparing 7.10.1 with the two `integer-gmp` versions reveals a 4% increase in allocations.\\r\\n\\r\\nWhile we can't necessarily attribute all of the runtime increase to these allocations, they are something that should be addressed if possible. Herbert Valerio Riedel, the author of the `integer-gmp` rewrite, believes that the cause may be due to the tendency for the rewrite to initially allocate a conservatively-sized backing `ByteArray#` for results. This leads to increased allocations due to the reallocations that are later required to accommodate larger-than-expected results.\\r\\n\\r\\nWhile being more liberal in the initial allocation sizes would solve the reallocation issue, this approach may substantially increase working-set sizes and heap fragmentation for integer-heavy workloads. For this reason, Herbert will be looking into exploiting a feature of our heap allocator. Heap allocations in GHC occur by bumping a pointer into an allocation block. Not only is this a very efficient means of allocating, it potentially allows one to efficiently grow an existing allocation. In this case, if we allocate a buffer and soon after realize that our request was too small we can simply bump the heap pointer by the size deficit, so long as no other allocations have occurred since our initial allocation. We can do this since we know that the memory after the heap pointer is available; we merely need to ensure that the current block we are allocating into is large enough.\\r\\n\\r\\nSimon Marlow and Herbert will be investigating this possibility in the coming weeks.\\r\\n\\r\\n== D924: `mapM_` and `traverse_`\\r\\n\\r\\nAs discussed in the [https://ghc.haskell.org/trac/ghc/blog#AMP-relatedperformanceregression most recent] Weekly News, one issue on our plate at the moment is Phab:D924, which attempted to patch up two remaining facets of the Applicative-Monad Proposal,\\r\\n\\r\\n1. Remove the override of `mapM` for the `[]` `Traversal` instance\\r\\n2. Rewrite `mapM_` in terms of `traverse_`\\r\\n\\r\\nWhile (1) seems like an obvious cleanup, (2) is a bit tricky. As noted last time, `traverse_` appears to give rise to non-linear behavior in this context.\\r\\n\\r\\n`akio` has contributed an insightful [analysis https://ghc.haskell.org/trac/ghc/timeline?from=2015-08-01T10%3A00%3A33Z&precision=second] shedding light on the cause of this behavior. Given that the quadratic behavior is intrinsic to the `Applicative` formulation, we'll be sending this matter back to the Core Libraries Committee to inform their future design decisions.\\r\\n\\r\\nThat is all for this week!\\r\\n\\r\\nCheers,\\r\\n\\r\\n- Ben\\r\\n","publish_time":1440537248,"version_time":1440537248,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150806","version":2,"title":"GHC Weekly News - 2015/08/06","body":"GHC Weekly News - 6 Aug 2015\\r\\n\\r\\nHello *,\\r\\n\\r\\nHere is a rather belated Weekly News which I found sitting nearly done on my\\r\\nwork-queue. I hope this will make for a good read despite its age. The next\\r\\nedition of the Weekly News will be posted soon.\\r\\n\\r\\n== Warnings for missed specialization opportunities\\r\\n\\r\\nSimon Peyton Jones recently\\r\\n[a4261549afaee56b00fbea1b4bc1a07c95e60929 introduced] a warning in `master` to\\r\\nalert users when the compiler was unable to specialize an imported binding\\r\\ndespite it being marked as `INLINEABLE`. This change was motivated by #10720,\\r\\nwhere the reporter observed poor runtime performance despite taking care to\\r\\nensure his binding could be inlined. Up until now, ensuring that the compiler's\\r\\noptimizations meet the user's expectation would require a careful look at the\\r\\nproduced Core. With this change the user is notified of exactly where the\\r\\ncompiler had to stop specializing, along with a helpful hint on where to add a\\r\\n`INLINABLE` pragma.\\r\\n\\r\\n== Ticky-Ticky profiling\\r\\n\\r\\nRecently I have been looking into breathing life back into GHC's [wiki:Debugging/TickyTicky ticky-ticky]\\r\\nprofiling mechanism. When enabled, ticky-ticky maintains low-level counters of various runtime-system events. These include closure entries, updates, and allocations. While ticky doesn't provide nearly the detail that the cost-center profiler allows, it is invisible to the Core-to-Core optimization passes and has minimal runtime overhead (manifested as a bit more memory traffic due to counter updates). For this reason, the ticky-ticky profiler can be a useful tool for those working on the Core simplifier. \\r\\n\\r\\nSadly, ticky-ticky has fallen into quite a state of disrepair in recent years as the runtime system and native code generator have evolved. As the beginning of an effort to resuscitate the ticky-ticky profiler I've started putting together a [https://ghc.haskell.org/trac/ghc/wiki/Debugging/TickyTicky#Ticky-Tickycounters list] of the counters currently implemented and whether they can be expected to do something useful. Evaluating the functionality of these counters is non-trivial, however, so this will be an on-going effort.\\r\\n\\r\\nOne of our goals is to eventually do a systematic comparison of the heap allocation numbers produced by the ticky-ticky profiler, the cost-center profiler, and ticky-ticky. While this will help validate some of the more coarse-grained counters exposed by ticky, most of them will need a more thorough read-through of the runtime system to verify.\\r\\n\\r\\n== `integer-gmp` Performance\\r\\n\\r\\nSince the 7.10.2 release much of my effort has been devoted to characterizing the performance of various benchmarks over various GHC versions. This is part of an effort to find places where we have regressed in the past few versions. One product of this effort is a complete comparison of [http://home.smart-cactus.org/~ben/nofib.html results] from our `nofib` benchmark suite ranging from 7.4.2 to 7.10.1.\\r\\n\\r\\nThe good news is there are essentially no disastrous regressions. Moreover, on the mean runtimes are over 10% faster than they were in 7.4.2. There are, however, a few cases which have regressed.  The runtime of the `integer` test, for instance, has increased by 7%. Looking at the trend across versions, it becomes apparent that the regression began with 7.10.1.\\r\\n\\r\\nOne of the improvements that was introduced with 7.10 was a rewrite of the `integer-gmp` library, which this benchmark tests heavily. To isolate this potential cause, I recompiled GHC 7.10.1 with the old `integer-gmp-0.5`. Comparing 7.10.1 with the two `integer-gmp` versions reveals a 4% increase in allocations.\\r\\n\\r\\nWhile we can't necessarily attribute all of the runtime increase to these allocations, they are something that should be addressed if possible. Herbert Valerio Riedel, the author of the `integer-gmp` rewrite, believes that the cause may be due to the tendency for the rewrite to initially allocate a conservatively-sized backing `ByteArray#` for results. This leads to increased allocations due to the reallocations that are later required to accommodate larger-than-expected results.\\r\\n\\r\\nWhile being more liberal in the initial allocation sizes would solve the reallocation issue, this approach may substantially increase working-set sizes and heap fragmentation for integer-heavy workloads. For this reason, Herbert will be looking into exploiting a feature of our heap allocator. Heap allocations in GHC occur by bumping a pointer into an allocation block. Not only is this a very efficient means of allocating, it potentially allows one to efficiently grow an existing allocation. In this case, if we allocate a buffer and soon after realize that our request was too small we can simply bump the heap pointer by the size deficit, so long as no other allocations have occurred since our initial allocation. We can do this since we know that the memory after the heap pointer is available; we merely need to ensure that the current block we are allocating into is large enough.\\r\\n\\r\\nSimon Marlow and Herbert will be investigating this possibility in the coming weeks.\\r\\n\\r\\n== D924: `mapM_` and `traverse_`\\r\\n\\r\\nAs discussed in the [https://ghc.haskell.org/trac/ghc/blog#AMP-relatedperformanceregression most recent] Weekly News, one issue on our plate at the moment is Phab:D924, which attempted to patch up two remaining facets of the Applicative-Monad Proposal,\\r\\n\\r\\n1. Remove the override of `mapM` for the `[]` `Traversal` instance\\r\\n2. Rewrite `mapM_` in terms of `traverse_`\\r\\n\\r\\nWhile (1) seems like an obvious cleanup, (2) is a bit tricky. As noted last time, `traverse_` appears to give rise to non-linear behavior in this context.\\r\\n\\r\\n`akio` has contributed an insightful [analysis https://ghc.haskell.org/trac/ghc/timeline?from=2015-08-01T10%3A00%3A33Z&precision=second] shedding light on the cause of this behavior. Given that the quadratic behavior is intrinsic to the `Applicative` formulation, we'll be sending this matter back to the Core Libraries Committee to inform their future design decisions.\\r\\n\\r\\nThat is all for this week!\\r\\n\\r\\nCheers,\\r\\n\\r\\n~ Ben\\r\\n","publish_time":1440537248,"version_time":1440537266,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"weekly20150917","version":1,"title":"GHC Weekly News - 2015/09/17","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News. It's been a little while, but here we are!\\r\\n\\r\\nAnd your author has finally returned from his 8 week sabbatical, too! So without any futher ado, lets get going...\\r\\n\\r\\n== 8.0.1 release roadmap ==\\r\\n\\r\\nSo `HEAD` has been steaming along pretty smoothly for the past few months now. After talking with Simon last week, we decided that the best course of action would be to release 8.0.1 (a super-major release) sometime around late February, which were the plans for 7.10 (modulo a few weeks due to the FTP debates). The current schedule is roughly:\\r\\n\\r\\n - November: Fork the new `ghc-8.0` STABLE branch\\r\\n  - At this point, `master` development will probably slow as we fix bugs.\\r\\n  - This gives us 2 months or so until branch, from Today.\\r\\n  - This is nice as the branch is close to the first RC.\\r\\n - December: First release candidate\\r\\n - Mid/late February: Final release.\\r\\n\\r\\n\"'''Why call it 8.0.1?'''\", you ask? Because we have a lot of excellent features planned! I'm particularly partial to Richard's work for merging types and kinds (Phab:D808). But there's a lot of other stuff.\\r\\n\\r\\nFor all the nitty gritty details, be sure to check [wiki:Status/GHC-8.0.1 8.0.1 status page] to keep track of everything - it will be our prime source of information and coordination. And be sure to [https://mail.haskell.org/pipermail/ghc-devs/2015-September/009952.html read my email to `ghc-devs`] for more info.\\r\\n\\r\\n=== ... and a 7.10.3 release perhaps? ===\\r\\n\\r\\nOn top of this, we've been wondering if another release in the 7.10 branch should be done. Ben did the release shortly after I left, and for the most part looked pretty great. But there have been some snags, as usual.\\r\\n\\r\\nSo we're asking: [https://mail.haskell.org/pipermail/ghc-devs/2015-September/009953.html who needs GHC 7.10.3?] We'd really like to know of any major showstoppers you've found with 7.10 that are preventing you from using it. Especially if you're stuck or there's no clear workaround.\\r\\n\\r\\nCurrently, we're still not 100% committed to this course of action (since the release will take time away from other things). However, we'll keep the polls open for a while - so ''please'' get in touch with us if you need it! (Be sure to read my email for specific information.)\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n(Over the past two weeks)\\r\\n\\r\\n  - Bartosz Nitka writes to `ghc-devs` about the ongoing work to try and fix deterministic compilation in GHC (the dreaded ticket #4012). There's a very detailed breakdown of the current problems and issues in play, with responses from others - https://mail.haskell.org/pipermail/ghc-devs/2015-September/009964.html\\r\\n\\r\\n  - Richard Eisenberg wants to know - how can I download all of `Hackage` to play with it? GHC developers are surely interested in this, so they can find regressions quickly - https://mail.haskell.org/pipermail/ghc-devs/2015-September/009956.html\\r\\n\\r\\n  - I wrote to the list about the upcoming tentative 7.10.3 plans, as I mentioned above. https://mail.haskell.org/pipermail/ghc-devs/2015-September/009953.html\\r\\n\\r\\n  - I ''also'' wrote to the list about the tentative 8.0.1 plans, too. https://mail.haskell.org/pipermail/ghc-devs/2015-September/009952.html\\r\\n\\r\\n  - Johan Tibell asks about his ongoing work for implementing unboxed sum types - in particular, converting unboxed sum types in `StgCmm`. https://mail.haskell.org/pipermail/ghc-devs/2015-September/009926.html\\r\\n\\r\\n  - Ryan Scott wrote a proposal for the automatic derivation of `Lift` through GHC's deriving mechanism, specifically for `template-hasekll` users. The response was positive and the code is going through review now (Phab:D1168). https://mail.haskell.org/pipermail/ghc-devs/2015-September/009838.html\\r\\n\\r\\n  - Andrew Gibiansky writes in with his own proposal for a new \"Argument Do\" syntax - a change which would allow `do` to appear in positions without `($)` or parenthesis, essentially changing the parser to insert parens as needed. The code is up at Phabricator for brave souls (Phab:D1219). https://mail.haskell.org/pipermail/ghc-devs/2015-September/009821.html\\r\\n\\r\\n  - Edward Yang started a monstrous thread after some discussions at ICFP about a future for ''unlifted'' data types in GHC. These currently exist as special magic, but the proposals included would allow users to declare their own types as unlifted, and make unlifted values more flexible (allowing `newtype` for example). See wiki:UnliftedDataTypes and Edward's thread for more. https://mail.haskell.org/pipermail/ghc-devs/2015-September/009799.html\\r\\n\\r\\n== Noteworthy commits ==\\r\\n\\r\\n(Over the past several weeks)\\r\\n\\r\\n  - Commit 374457809de343f409fbeea0a885877947a133a2 - '''Injective Type Families'''\\r\\n\\r\\n  - Commit 8ecf6d8f7dfee9e5b1844cd196f83f00f3b6b879 - '''Applicative Do notation'''\\r\\n\\r\\n  - Commit 6740d70d95cb81cea3859ff847afc61ec439db4f - Use IP-based CallStack in `error` and `undefined`\\r\\n\\r\\n  - Commit 43eb1dc52a4d3cbba9617f5a26177b8251d84b6a - Show `MINIMAL` complete definition in GHCi's `:info`\\r\\n\\r\\n  - Commit 296bc70b5ff6c853f2782e9ec5aa47a52110345e - Use a response file for linker command line arguments\\r\\n\\r\\n  - Commit 4356dacb4a2ae29dfbd7126b25b72d89bb9db1b0 - Forbid annotations when Safe Haskell is enabled\\r\\n\\r\\n  - Commit 7b211b4e5a38efca437d76ea442495370da7cc9a - Upgrade GCC/binutils to 5.2.0 release for Windows (i386/amd64)\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n(Over the past two weeks)\\r\\n\\r\\n#10834, #10830, #10047, #9943, #1851, #1477, #8229, #8926, #8614, #10777, #8596, #10788, #9500, #9087, #10157, #10866, #10806, #10836, #10849, #10869, #10682, #10863, #10880, #10883, #10787, #8552, #10884, #7305, #5757, #9389, #8689, #10105, #8168, #9925, #10305, #4438, #9710, #10889, #10885, #10825, #10821, #10790, #10781, #9855, #9912, #10033, #9782, #10035, #9976, #10847, and #10865.","publish_time":1442530837,"version_time":1442530837,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"weekly20151016","version":1,"title":"GHC Weekly News - 2015/10/16","body":"Hi *,\\r\\n\\r\\nWelcome for the latest entry in the GHC Weekly News, which has been somewhat irregularly scheduled - but we're as busy as ever!\\r\\n\\r\\n== 8.0.1 release roadmap ==\\r\\n\\r\\nWe're still steaming ahead on GHC 8.0.1 - any interested participants are suggested to look at the wiki:Status/GHC-8.0.1 page, to see where we're currently at.\\r\\n\\r\\nThese past few weeks have been good: we've gotten the first part of the overloaded record fields work in, and we have plans to land the kind equalities work in November. Furthermore, Simon Marlow, Peter Wortmann and Ben are working on reviewing all of the DWARF improvements, and hopefully the start of this work will land next week.\\r\\n\\r\\nBut 8.0 isn't the only thing that'll be getting released...\\r\\n\\r\\n== And some other minor releases ==\\r\\n\\r\\nIn a total, unprecedented upset - we're aiming to do ''three'' GHC releases in a fairly short amount of time.\\r\\n\\r\\n=== 7.10.3 ===\\r\\n\\r\\nBen Gamari has been working on steadily hacking away at GHC 7.10.3, and the hopes are that we'll be able to ship it soon. This will fix several dozen bugs, some of which are critical for our users.\\r\\n\\r\\nYou can keep up to date by following the wiki:Status/GHC-7.10.3 page.\\r\\n\\r\\n=== 7.8.5 ===\\r\\n\\r\\nSimultaneously, your author will ''also'' be working on a GHC 7.8.5 release. While we were alerted a few months ago to this breakage, it seems rather unfortunate for the 7.8 series to remain broken on such a popular OS.\\r\\n\\r\\nFurthermore, the \"Three GHC Release Policy\" for many authors - to support the last three major versions of GHC - would mean that 7.8 would be broken for OS X developers for an ''entire year until GHC 8.2.1''. Which is a pretty unfortunate circumstance.\\r\\n\\r\\nIt's not expected the 7.8.5 release will contain any other fixes, however.\\r\\n\\r\\n\\r\\n== List chatter ==\\r\\n\\r\\n(Over the past two weeks)\\r\\n\\r\\n  - Ben Gamari wrote in about '''switching the users guide to reStructuredText''', and the TL;DR is - it's done! We'll have a beautiful new users guide for GHC 8.0.1 https://mail.haskell.org/pipermail/ghc-devs/2015-October/010029.html\\r\\n\\r\\n  - Matthew Pickering comments about the state of pattern synonym signatures, remarking that they're currently confusing, noting down some things we could possibly fix. https://mail.haskell.org/pipermail/ghc-devs/2015-October/010024.html\\r\\n\\r\\n  - Ben Gamari talked about the status of the recent DWARF work, and so far it's looking good. The needed patches are still in the review pipeline, but the hope is that they'll all be done in time for 8.0.1. https://mail.haskell.org/pipermail/ghc-devs/2015-October/010039.html\\r\\n\\r\\n  - David A Roberts wrote in to ask a question: now that we have `ApplicativeDo`, what about `Applicative` comprehensions? The responses indicate this seems like it would be a great addition. https://mail.haskell.org/pipermail/ghc-devs/2015-October/010062.html\\r\\n\\r\\n  - Richard Eisenberg sent in a status update about his work on kind equalities, and the hope is it will land shortly in November! (Your editor then hassled him for a syntax change before landing.) https://mail.haskell.org/pipermail/ghc-devs/2015-October/010077.html\\r\\n\\r\\n  - Adam Foltzer has requested another release of the GHC 7.8 series, due to it being completely broken on OS X El Capitan. Expect more news on this soon. https://mail.haskell.org/pipermail/ghc-devs/2015-October/010078.html\\r\\n\\r\\n  - Erik de Castro Lopo has recently been working with LLVM, and decided to publish his automation so interested GHC hackers could keep up to date and try new LLVMs easily. https://mail.haskell.org/pipermail/ghc-devs/2015-October/010086.html\\r\\n\\r\\n== Noteworthy commits ==\\r\\n\\r\\n(Over the past two weeks)\\r\\n\\r\\n  - Commit 4fd6207ec6960c429e6a1bcbe0282f625010f52a - Move the users guide to reStructured Text.\\r\\n\\r\\n  - Commit 6cde981a8788b225819be28659caddc35b77972d - Make `GHC.Generics` capable of handling unboxed tuples.\\r\\n\\r\\n  - Commit 0eb8fcd94b29ee9997b386e64203037bdf2aaa04 - Enable `Enumeration is empty` warnings for `Integer`\\r\\n\\r\\n  - Commit 620fc6f909cd6e51b5613454097ec1c9f323839a - Make Windows linker more robust to unknown sections\\r\\n\\r\\n  - Commit 5d841108acef950fed6a5e608ac9b18e7431aa87 - Add short library names support to the Windows linker\\r\\n\\r\\n  - Commit f8fbf385b879fe177409a25cc9499275ea3dc45d - Reinstate monomorphism-restriction warnings\\r\\n\\r\\n  - Commit dcc342870b4d8a739ccbed3ae26e84dcc3579914 - Don't inline/apply other rules when simplifying a rule RHS.\\r\\n\\r\\n  - Commit dec5cd4085488686b5ed50bb26ccbc0ba7b645ec - base: Add `forkOSWithUnmask`\\r\\n\\r\\n  - Commit e8c8173923302268ef950c3b21e276779e45ac83 - Allow arr ∧ (first ∨ (***)) as minimal definition of Arrow instance\\r\\n\\r\\n  - Commit 29310b622801733e1b29a9a61988406872db13ca - Switch to LLVM version 3.7\\r\\n\\r\\n  - Commit 04e8366608fee4f5e3358acc855bc6f556c3f508 - ELF/x86_64: map object file sections separately into the low 2GB\\r\\n\\r\\n  - Commit b1884b0e62f62e3c0859515c4137124ab0c9560e - Implement `DuplicateRecordFields`\\r\\n\\r\\n  - Commit 75492e7467ff962f2f2e29e5c8b2c588c94ae8a7 - Add typed holes support in Template Haskell.\\r\\n\\r\\n  - Commit 6a8ca65032c6b3ed61b5378765e70120083cf5da - Allow left ∨ (+++) as minimal definition of ArrowChoice instance\\r\\n\\r\\n== Closed tickets ==\\r\\n\\r\\n(Over the past two weeks)\\r\\n\\r\\n#10392, #7883, #10475, #10745, #10926, #9238, #10700, #10810, #10342, #365(!), #10361, #10929, #10563, #9907, #10513, #10868, #10932, #8920, #10516, #10416, #5966, #8335, #10520, #10687, #10571, #9058, #10939, #10938, #9590, #10949, #10153, #10947, #10948, #10936, #1883, #5289, #10733, #10950, #10611, #10959, #10960, #10831, #10796, #10890, #8010, #10216, #10965, #10953, #10964, #10931, #10714, #10888, #10633, #8652, #3971, #10882, #10977, #10267, and #10911.","publish_time":1445049101,"version_time":1445049101,"version_comment":"Initial revision","version_author":"thoughtpolice","author":"thoughtpolice","categories":"ghc news"},
{"name":"ghc-8.0.1-released","version":1,"title":"GHC 8.0.1 Released","body":"= GHC version 8.0.1 released =\\r\\n\\r\\nThe GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting new developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available at,\\r\\n\\r\\n    http://www.haskell.org/ghc/\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the web interfaces at\\r\\n\\r\\n    http://mail.haskell.org/cgi-bin/mailman/listinfo/glasgow-haskell-users\\r\\n    http://mail.haskell.org/cgi-bin/mailman/listinfo/ghc-devs\\r\\n    http://mail.haskell.org/cgi-bin/mailman/listinfo/ghc-tickets\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell\\r\\nwiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463837053,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":2,"title":"GHC 8.0.1 Released","body":"= GHC version 8.0.1 released =\\r\\n\\r\\nThe GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting new developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell\\r\\nwiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463837154,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":3,"title":"GHC 8.0.1 Released","body":"= GHC version 8.0.1 released =\\r\\n\\r\\nThe GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting new developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463837175,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":4,"title":"GHC 8.0.1 Released","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting new developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463837191,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":5,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting new developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463838542,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":6,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\n\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * A more refined interface for implicit callstacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463838809,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":7,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * A more refined interface for implicit call-stacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * The introduction of the long-awaited DuplicateRecordFields language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more agressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Support for desugaring do-notation to use Applicative combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * The introduction of Strict and StrictData language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * An improved Generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * The TypeInType extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463841408,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":8,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * A more refined interface for implicit call-stacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * The introduction of the long-awaited `DuplicateRecordFields` language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more aggressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Support for desugaring do-notation to use `Applicative` combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * The introduction of `Strict` and `StrictData` language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * An improved generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * The `TypeInType` extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463841531,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":9,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * A more refined interface for implicit call-stacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * The introduction of the `DuplicateRecordFields` language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more aggressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Support for desugaring do-notation to use `Applicative` combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * The introduction of `Strict` and `StrictData` language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * An improved generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * The `TypeInType` extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463841721,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":10,"title":"[Draft] GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * A more refined interface for implicit call-stacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * The introduction of the `DuplicateRecordFields` language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more aggressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Support for desugaring do-notation to use `Applicative` combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * The introduction of `Strict` and `StrictData` language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * An improved generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * The `TypeInType` extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463842769,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.0.1-released","version":11,"title":"GHC 8.0.1 is available!","body":"The GHC developers are very pleased to announce the release of the first\\r\\nnew super-major version of our Haskell compiler in six years, GHC 8.0.1.\\r\\nThis release features dozens of exciting developments including,\\r\\n\\r\\n * A more refined interface for implicit call-stacks, allowing libraries to\\r\\n   provide more helpful runtime error messages to users\\r\\n\\r\\n * The introduction of the `DuplicateRecordFields` language\\r\\n   extension, allowing multiple datatypes to declare fields of the same name\\r\\n\\r\\n * Significant improvements in error message readability and content, including\\r\\n   facilities for libraries to provide custom error messages, more aggressive\\r\\n   warnings for fragile rewrite rules, and more helpful errors for missing\\r\\n   imports\\r\\n\\r\\n * A rewritten and substantially more thorough pattern match checker, providing\\r\\n   more precise exhaustiveness checking in GADT pattern matches\\r\\n\\r\\n * More reliable debugging information including experimental backtrace support,\\r\\n   allowing better integration with traditional debugging tools\\r\\n\\r\\n * Support for desugaring do-notation to use `Applicative` combinators, allowing\\r\\n   the intuitive do notation to be used in settings which previously required\\r\\n   the direct use of Applicative combinators\\r\\n\\r\\n * The introduction of `Strict` and `StrictData` language extensions, allowing\\r\\n   modules to be compiled with strict-by-default evaluation of bindings\\r\\n\\r\\n * Great improvements in portability, including more reliable linking on\\r\\n   Windows, a new PPC64 code generator, support for the AIX operating system,\\r\\n   unregisterised m68k support, and significant stabilization on ARM targets\\r\\n\\r\\n * A greatly improved user's guide, with beautiful and modern PDF and HTML\\r\\n   output\\r\\n\\r\\n * Introduction of type application syntax, reducing the need for proxies\\r\\n\\r\\n * More complete support for pattern synonyms, including record pattern synonyms\\r\\n   and the ability to export patterns \"bundled\" with a type, as you would a data\\r\\n   constructor\\r\\n\\r\\n * Support for injective type families and recursive superclass relationships\\r\\n\\r\\n * An improved generics representation leveraging GHC's support for type-level\\r\\n   literals\\r\\n\\r\\n * The `TypeInType` extension, which unifies types and kinds, allowing GHC to\\r\\n   reason about kind equality and enabling promotion of more constructs to the\\r\\n   type level\\r\\n\\r\\n * ...and more!\\r\\n\\r\\nA more thorough list of the changes included in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/8.0.1-notes.html|release notes]],\\r\\n\\r\\n\\r\\nAs always, we have collected various points of interest for users of previous\\r\\nGHC releases on the GHC 8.0 [[Migration/8.0|migration page]],\\r\\nPlease let us know if you encounter anything missing or unclear on this page.\\r\\n\\r\\nThis release is the culmination of nearly eighteen months of effort by over one\\r\\nhundred contributors. We'd like to thank everyone who has contributed code, bug\\r\\nreports, and feedback over the past year. It's only because of their efforts\\r\\nthat GHC continues to evolve.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1463837053,"version_time":1463843582,"version_comment":"Remove [Draft] from title","version_author":"thoughtpolice","author":"bgamari","categories":"release"},
{"name":"ContributingToGhc","version":1,"title":"Contributing to GHC","body":"This post is a response to [http://www.arcadianvisions.com/blog/2016/ghc-contributing.html Anthony's blog post] about contributing to GHC, and the subsequent [https://www.reddit.com/r/haskell/comments/4isua9/ghc_development_outsidein Reddit discussion]. You'll find it easier to follow my comments below if you read Anthony's post first.  Short summary: many of Anthony's criticisms are accurate, but they are not easy to address, especially in a volunteer-only project.  However we will do something about the feature-request process.\\r\\n\\r\\n\\r\\n== Barrier to entry ==\\r\\n\\r\\nI am ashamed that GHC seems difficult to contribute to. The details don't matter; the fact that it made you feel that way is by definition bad. I'm really sorry.  We should find a way to do better.\\r\\n\\r\\nAn underlying issue is one of effort budget. GHC has essentially no full-timers, unlike many open-source projects.  In particular, Simon Marlow and I are volunteers like everyone else, and like everyone else we have a day job.  Microsoft Research generously pays Well Typed for front-line support, manifested in the heroic form of Ben and Austin, totalling around one FTE.  But their effort is fully absorbed by managing releases, reviewing patches, maintaining the infrastructure, and so on.\\r\\n\\r\\nIt's a real challenge to maintain a low barrier to entry for a large complex project, whose motive force is primarily volunteers.  It means that any initiative will only fly if someone steps up to drive it.\\r\\n\\r\\n\\r\\n== Technical documentation ==\\r\\n\\r\\nThe questions of scattered and inconsistent documentation are difficult to address. GHC is twenty-five years old; it has hundreds of authors and documentation that was once accurate falls out of date. I would love it to have consistent, well-explained documentation. But I don't know how to achieve it.\\r\\n\\r\\nGHC's technical documentation is either in the code itself, or on GHC's wiki. An advantage of a wiki is that anyone can edit it. Yes, instructions and technical descriptions go out of date.  Who will fix them?  You, gentle reader!  There is no one else.\\r\\n\\r\\nBut in practice few do. Perhaps that's because such work is invisible, so no one even knows you've done it? What would make people feel \"I'd really like to improve those instructions or that documentation?\"\\r\\n\\r\\nI will argue for two things. First, I find Notes incredibly helpful. They live with the code, so they are less likely to go out of date. They don't mess up the flow of the code. They can be referred to from multiple places. They are the single most successful code documentation mechanism we have. (To be fair to Anthony, I don't think was complaining about Notes, just expressing surprise.)\\r\\n\\r\\nSecond, I really do think that each new proposed feature needs a description, somewhere, of what it is, why it's a good thing, and as precisely as possible what its specification is. Plus perhaps some implementation notes. It's very important when reading an implementation to know what it is that the code is seeking to implement. So yes, I do frequently ask for a specification.\\r\\n\\r\\n== Arc, github, phabricator, etc ==\\r\\n\\r\\nPersonally I carry no torch for `arc`. I do whatever I'm told, workflow-wise. If GitHub has got a lot better since we took the Arc decision, and there's a consensus that we should shift, I'm all for it provided someone explains to me what my new workflows should be. I am absolutely in favour of reducing barriers to contribution.  (Other members of the [wiki:TeamGHC GHC team] have much stronger and better informed views than me, though.)\\r\\n\\r\\nBut there ''are'' costs to moving, especially if the move implies friction in the future. In particular, those that worry me most are those surrounding issue tracking. Github's issue tracker simply doesn't seem sufficient for a project as large and multi-faceted as GHC; in particular, tags as the only form of metadata is extremely limiting.\\r\\n\\r\\nOne alternative would be to use Github and Trac side-by-side, but then we face the issue of conflicting ticket number spaces as both systems insist on ticket numbers of the form #NNNN.\\r\\n\\r\\n== Coding style ==\\r\\n\\r\\nCoding style is rather a personal thing, and we have been reluctant to enforce a single uniform style. (Quite apart from the task of reformatting 150k lines of Haskell.) Personally I don't find it an obstacle to reading other people's code.\\r\\n\\r\\n== Feature requests ==\\r\\n\\r\\nThat leaves the most substantial issue that Anthony poses: the process of making a contribution.\\r\\n\\r\\nFor fixing a bug, I think that (aside from the `arc`/Github debate) things are not too bad.  On the arc/Github question, Austin has been working with the Phabricator maintainers to try to have them introduce a workflow which might be more familiar and more convenient for Github experts.\\r\\n\\r\\nBut for offering a new feature, Anthony argues that the process is unacceptably arduous. There are lots of things to think about\\r\\n\\r\\n* GHC has tons of features implemented by talented and motivated folk... who have since moved on.  So when a new feature is proposed, my baseline guess is that I will personally be responsible for maintaining it in five years time.  So I want to understand what the feature is.  I want to understand how the implementation works.  I want to be reasonably sure that it doesn't add a bunch of complexity to an already very complicated code base.  And since ''any'' new feature adds some complexity, I want to have some confidence that the feature commands broad support -- even when it's behind a language extension flag.\\r\\n\\r\\n  So actually I think it's reasonable that the process should be somewhat arduous.  A new feature imposes costs on every single person who works on that code in the future.  We don't really make this point explicitly, but the [https://secure.phabricator.com/book/phabcontrib/article/contributing_code/ contributor guidelines for Phabricator] do.  It might be helpful if we articulated similar guidelines.\\r\\n\\r\\n* \"Any proposal needs a lightweight way to gauge broad support, then a period of constructive refinement\".  Indeed!  What would be such a lightweight way?  The trouble is that there is an enormous silent majority, and discussions are typically driven by a handful of articulate and well-informed contributors.  All credit to them, but they may very well be an unrepresentative sample.  I simply don't know how to gauge true broad support.\\r\\n\\r\\n* There is a problem with my own personal lack of bandwidth.  I am one of the main gatekeepers for some big chunks of GHC, the renamer, typechecker and optimisation passes.  That is good in a way, because if GHC lacked gatekeepers, it would soon lose conceptual integrity and become a huge ball of mud. But it is bad in other ways.  I review a lot of code; but not fast enough! In prioritising I am guided by my (doubtless flawed) perceptions of things that lots of people are eagerly awaiting.  The same thing goes for Simon Marlow, especially in the runtime system. We both have other day jobs.  Even writing this post means that I'm not reviewing someone's code.\\r\\n\\r\\n  But I am acutely aware that \"Simon and Simon are busy\" is pretty cold comfort to someone awaiting a review.  Maybe there should be a bunch of other people playing this role.  That would be great.  For example, Richard Eisenberg has taken responsibility for Template Haskell, which is totally fantastic.  I would love to hear from people who are willing to take overall responsibility for a piece of GHC.\\r\\n\\r\\nNone of this is an argument for the status quo.  Simon, Ben, Austin, Herbert, and I have been talking about a rather more systematic process for new features. We'd like to learn from experience elsewhere, rather than reinvent the wheel, such as the [https://github.com/rust-lang/rfcs#before-creating-an-rfc Rust process]. Please suggest processes that you have seen working well elsewhere.\\r\\n\\r\\n\\r\\n","publish_time":1466426108,"version_time":1466426108,"version_comment":"","version_author":"simonpj","author":"simonpj","categories":""},
{"name":"rethinking-proposals","version":1,"title":"Rethinking GHC's approach to managing proposals","body":"Recently there has been a [[https://www.reddit.com/r/haskell/comments/4oyxo2/blog_contributing_to_ghc/|fair bit]] of [[https://www.reddit.com/r/haskell/comments/4isua9/ghc_development_outsidein/|discussion]] around the\\r\\nmechanisms by which proposed changes to GHC are evaluated. While we have\\r\\nsomething of a formal proposal [[https://ghc.haskell.org/trac/ghc/wiki/WorkingConventions/AddingFeatures|protocol]], it is not clearly\\r\\ndocumented, inconsistently applied, and may be failing to serve a\\r\\nsignificant fraction of GHC's potential contributor pool.\\r\\n\\r\\nOver the last few weeks, I have been doing a fair amount of reading,\\r\\nthinking, and discussing to try to piece together a proposal scheme\\r\\nwhich better serves our community.\\r\\n\\r\\nThe [[https://github.com/ghc-proposals/ghc-proposals/pull/1/files?short_path=14d66cd#diff-14d66cda32248456a5f223b6333c6132|resulting proposal]] is strongly inspired by the [[https://github.com/rust-lang/rfcs|RFC process]] in\\r\\nplace in the Rust community, the leaders of which have thought quite\\r\\nhard about fostering community growth and participation. While no\\r\\nprocess is perfect, I feel like the Rust process is a good starting\\r\\npoint for discussion, offering enough structure to guide new\\r\\ncontributors through the process while requiring only a modest\\r\\ninvestment of developer time.\\r\\n\\r\\nTo get a sense for how well this will work in our community, I propose\\r\\nthat we attempt to self-host the proposed process. To this end I have\\r\\nsetup a `ghc-proposals` [[https://github.com/ghc-proposals/ghc-proposals|repository]] and opened a pull request for\\r\\ndiscussion of the [[https://github.com/ghc-proposals/ghc-proposals/pull/1/files?short_path=14d66cd#diff-14d66cda32248456a5f223b6333c6132|process proposal]].\\r\\n           \\r\\nLet's see how this goes.\\r\\n\\r\\nCheers,\\r\\n\\r\\n- Ben\\r\\n","publish_time":1468096868,"version_time":1468096868,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"proposals"},
{"name":"rethinking-proposals","version":2,"title":"Rethinking GHC's approach to managing proposals","body":"Recently there has been a [[https://www.reddit.com/r/haskell/comments/4oyxo2/blog_contributing_to_ghc/|fair bit]] of [[https://www.reddit.com/r/haskell/comments/4isua9/ghc_development_outsidein/|discussion]] around the\\r\\nmechanisms by which proposed changes to GHC are evaluated. While we have\\r\\nsomething of a formal proposal [[https://ghc.haskell.org/trac/ghc/wiki/WorkingConventions/AddingFeatures|protocol]], it is not clearly\\r\\ndocumented, inconsistently applied, and may be failing to serve a\\r\\nsignificant fraction of GHC's potential contributor pool.\\r\\n\\r\\nOver the last few weeks, I have been doing a fair amount of reading,\\r\\nthinking, and discussing to try to piece together a proposal scheme\\r\\nwhich better serves our community.\\r\\n\\r\\nThe [[https://github.com/ghc-proposals/ghc-proposals/pull/1/files?short_path=14d66cd#diff-14d66cda32248456a5f223b6333c6132|resulting proposal]] is strongly inspired by the [[https://github.com/rust-lang/rfcs|RFC process]] in\\r\\nplace in the Rust community, the leaders of which have thought quite\\r\\nhard about fostering community growth and participation. While no\\r\\nprocess is perfect, I feel like the Rust process is a good starting\\r\\npoint for discussion, offering enough structure to guide new\\r\\ncontributors through the process while requiring only a modest\\r\\ninvestment of developer time.\\r\\n\\r\\nTo get a sense for how well this will work in our community, I propose\\r\\nthat we attempt to self-host the proposed process. To this end I have\\r\\nsetup a `ghc-proposals` [[https://github.com/ghc-proposals/ghc-proposals|repository]] and opened a pull request for\\r\\ndiscussion of the [[https://github.com/ghc-proposals/ghc-proposals/pull/1/files?short_path=14d66cd#diff-14d66cda32248456a5f223b6333c6132|process proposal]].\\r\\n           \\r\\nLet's see how this goes.\\r\\n\\r\\nCheers,\\r\\n\\r\\n~ Ben\\r\\n","publish_time":1468096868,"version_time":1468096894,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"proposals"},
{"name":"2017-release-schedule","version":17,"title":"Reflections on GHC's release schedule","body":"Looking back on GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be born in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than desired for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about,\\r\\n\\r\\n 1. Do you feel that it takes too long for GHC features to make it to users' hands?\\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous? Would the current load of interface changes per release be acceptable under a faster release cadence?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n 4. Would you feel more likely to contribute to GHC if your work were more quickly available in a release?\\r\\n\\r\\n\\r\\nWe would love to hear your thoughts. Be sure to mention whether you are a user, GHC contributor, or both.\\r\\n","publish_time":1501549144,"version_time":1501551897,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"jenkins-ci","version":9,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a hole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\npre-release Stackage builds will be more fruitful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies (e.g. `directory`, `process`) up-to-date with their respective upstreams\\r\\nis important to ensure that tools that link against the `ghc` library (e.g. `ghc-mod`) can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501576937,"version_comment":"","version_author":"simonpj","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":10,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nSee the Trac ticket #13716\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a hole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\npre-release Stackage builds will be more fruitful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies (e.g. `directory`, `process`) up-to-date with their respective upstreams\\r\\nis important to ensure that tools that link against the `ghc` library (e.g. `ghc-mod`) can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1503326188,"version_comment":"","version_author":"simonpj","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"ghc-8.2.2-released","version":1,"title":"GHC 8.2.2 is available","body":"\\r\\n           ===============================================\\r\\n            The Glasgow Haskell Compiler -- version 8.2.2\\r\\n           ===============================================\\r\\n\\r\\nThe GHC Team is pleased to announce a new minor release of GHC. This release\\r\\nbuilds on the performance and stability improvements of 8.2.1, fixing a variety\\r\\nof correctness bugs, improving error messages, and making the compiler more\\r\\nportable.\\r\\n\\r\\nNotable bug-fixes include\\r\\n\\r\\n * A correctness issue resulting in segmentation faults in some\\r\\n   FFI-users (#13707, #14346)\\r\\n\\r\\n * A correctness issue resulting in undefined behavior in some programs\\r\\n   using STM (#14171)\\r\\n\\r\\n * A bug which may have manifested in segmentation faults in\\r\\n   out-of-memory condition (#14329)\\r\\n\\r\\n * clearBit of Natural no longer bottoms (#13203)\\r\\n\\r\\n * A specialisation bug resulting in exponential blowup of compilation\\r\\n   time in some specialisation-intensive programs (#14379)\\r\\n\\r\\n * ghc-pkg now works even in environments with misconfigured NFS mounts\\r\\n   (#13945)\\r\\n\\r\\n * GHC again supports production of position-independent executables\\r\\n   (#13702)\\r\\n\\r\\n * Better error messages around kind mismatches (#11198, #12373, #13530,\\r\\n   #13610)\\r\\n\\r\\nA thorough list of the changes in the release can be found in the release\\r\\nnotes,\\r\\n\\r\\n    https://haskell.org/ghc/docs/8.2.2/html/users_guide/release-8-2-2.html\\r\\n\\r\\nHow to get it\\r\\n~~~~~~~~~~~~~\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_2_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\nBackground\\r\\n~~~~~~~~~~\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell. Included is an\\r\\noptimising compiler generating efficient code for a variety of platforms,\\r\\ntogether with an interactive system for convenient, quick development. The\\r\\ndistribution includes space and time profiling facilities, a large collection of\\r\\nlibraries, and support for various language extensions, including concurrency,\\r\\nexceptions, and foreign language interfaces. GHC is distributed under a\\r\\nBSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references, contact\\r\\ninformation, links to research groups) are available from the Haskell home page\\r\\n(see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\nGHC home page              https://www.haskell.org/ghc/\\r\\nGHC developers' home page  https://ghc.haskell.org/trac/ghc/\\r\\nHaskell home page          https://www.haskell.org/\\r\\n\\r\\nSupported Platforms\\r\\n~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, is here:\\r\\n\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Contributors\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\nBuilding Guide describes how to go about porting to a new platform:\\r\\n\\r\\n    https://ghc.haskell.org/trac/ghc/wiki/Building\\r\\n\\r\\nDevelopers\\r\\n~~~~~~~~~~\\r\\n\\r\\nWe welcome new contributors. Instructions on accessing our source code\\r\\nrepository, and getting started with hacking on GHC, are available from the\\r\\nGHC's developer's site:\\r\\n\\r\\n    https://ghc.haskell.org/trac/ghc/\\r\\n\\r\\nMailing lists\\r\\n~~~~~~~~~~~~~\\r\\n\\r\\nWe run mailing lists for GHC users and bug reports; to subscribe, use the web\\r\\ninterfaces at\\r\\n\\r\\n    https://mail.haskell.org/cgi-bin/mailman/listinfo/glasgow-haskell-users\\r\\n    https://mail.haskell.org/cgi-bin/mailman/listinfo/ghc-tickets\\r\\n\\r\\nThere are several other haskell and ghc-related mailing lists on\\r\\nwww.haskell.org; for the full list, see\\r\\n\\r\\n    https://mail.haskell.org/cgi-bin/mailman/listinfo\\r\\n\\r\\nMany GHC developers hang out on #haskell on IRC:\\r\\n\\r\\n    https://www.haskell.org/haskellwiki/IRC_channel\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found here:\\r\\n\\r\\n    https://www.haskell.org/ghc/reportabug\\r\\n\\r\\n","publish_time":1511302017,"version_time":1511302017,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.2-released","version":2,"title":"GHC 8.2.2 is available","body":"The GHC Team is pleased to announce a new minor release of GHC. This release\\r\\nbuilds on the performance and stability improvements of 8.2.1, fixing a variety\\r\\nof correctness bugs, improving error messages, and making the compiler more\\r\\nportable.\\r\\n\\r\\nNotable bug-fixes include\\r\\n\\r\\n * A correctness issue resulting in segmentation faults in some\\r\\n   FFI-users (#13707, #14346)\\r\\n\\r\\n * A correctness issue resulting in undefined behavior in some programs\\r\\n   using STM (#14171)\\r\\n\\r\\n * A bug which may have manifested in segmentation faults in\\r\\n   out-of-memory condition (#14329)\\r\\n\\r\\n * clearBit of Natural no longer bottoms (#13203)\\r\\n\\r\\n * A specialisation bug resulting in exponential blowup of compilation\\r\\n   time in some specialisation-intensive programs (#14379)\\r\\n\\r\\n * ghc-pkg now works even in environments with misconfigured NFS mounts\\r\\n   (#13945)\\r\\n\\r\\n * GHC again supports production of position-independent executables\\r\\n   (#13702)\\r\\n\\r\\n * Better error messages around kind mismatches (#11198, #12373, #13530,\\r\\n   #13610)\\r\\n\\r\\nA thorough list of the changes in the release can be found in the release\\r\\nnotes,\\r\\n\\r\\n    https://haskell.org/ghc/docs/8.2.2/html/users_guide/release-8-2-2.html\\r\\n\\r\\nHow to get it\\r\\n~~~~~~~~~~~~~\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_2_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1511302017,"version_time":1511302103,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.2-released","version":3,"title":"GHC 8.2.2 is available","body":"The GHC Team is pleased to announce a new minor release of GHC. This release\\r\\nbuilds on the performance and stability improvements of 8.2.1, fixing a variety\\r\\nof correctness bugs, improving error messages, and making the compiler more\\r\\nportable.\\r\\n\\r\\nNotable bug-fixes include\\r\\n\\r\\n * A correctness issue resulting in segmentation faults in some\\r\\n   FFI-users (#13707, #14346)\\r\\n\\r\\n * A correctness issue resulting in undefined behavior in some programs\\r\\n   using STM (#14171)\\r\\n\\r\\n * A bug which may have manifested in segmentation faults in\\r\\n   out-of-memory condition (#14329)\\r\\n\\r\\n * clearBit of Natural no longer bottoms (#13203)\\r\\n\\r\\n * A specialisation bug resulting in exponential blowup of compilation\\r\\n   time in some specialisation-intensive programs (#14379)\\r\\n\\r\\n * ghc-pkg now works even in environments with misconfigured NFS mounts\\r\\n   (#13945)\\r\\n\\r\\n * GHC again supports production of position-independent executables\\r\\n   (#13702)\\r\\n\\r\\n * Better error messages around kind mismatches (#11198, #12373, #13530,\\r\\n   #13610)\\r\\n\\r\\nA thorough list of the changes in the release can be found in the release\\r\\nnotes,\\r\\n\\r\\n    https://haskell.org/ghc/docs/8.2.2/html/users_guide/release-8-2-2.html\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_2_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1511302017,"version_time":1511302121,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.11-released","version":4,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/html/users_guide/8.2.1-notes.html\\r\\n|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n   GHC HQ building these distributions ourselves will allow us to more\\r\\n   quickly ship distributions to users by eliminating the need for a\\r\\n   long lag time between source release availability and having all\\r\\n   binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n=== How to get it ===\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1511302169,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"steering-committee-cfn","version":1,"title":"Call for Nominations: GHC Steering Committee","body":"Hello everyone,\\r\\n\\r\\nAs you likely know, over the last few months we have been discussing\\r\\noptions for reforming the process for proposing language and\\r\\ncompiler changes to GHC. After much discussion, we have a [[http://github.com/ghc-proposals/ghc-proposals|process]]\\r\\nwhich, while not perfect, is acceptable to a majority of our contributor\\r\\nbase and will be an improvement over the status quo. While we invite\\r\\nsuggestions for future improvements, we are at a point where we can move\\r\\nahead with implementation.\\r\\n\\r\\nConsequently, we are seeking nominations for the initial GHC steering\\r\\ncommittee. This body is responsible for overseeing the progression of\\r\\nproposals through the process, working with authors on refining their\\r\\nideas, and evaluating proposals for acceptance. The committee will\\r\\nconsist of five to eight members of diverse backgrounds.\\r\\n\\r\\nWe would like to offer the following as a criteria for membership. Note\\r\\nthat a candidate is not expected to satisfy all or even most of these\\r\\ncriteria, but a good candidate should satisfy at least one:\\r\\n\\r\\n* A history of contributions to the design of new language features\\r\\n\\r\\n* Experience developing Haskell libraries and applications\\r\\n\\r\\n* A demonstrated track record of contributing code to GHC\\r\\n\\r\\n* A pedagogical background, with experience in either teaching or\\r\\n  authoring educational materials\\r\\n\\r\\n* Experience in compiler development\\r\\n\\r\\n* Knowledge of functional programming language theory\\r\\n\\r\\nI'd like to emphasize that committee membership is as much a duty as it\\r\\nis a privilege. Membership is not intended to be a platform to be used\\r\\nby members to drive their own ideas; rather it is a way of serving the\\r\\nHaskell community by helping other community members refine and advance\\r\\ntheir proposals. This, of course, requires an investment of\\r\\ntime and effort, which you should be willing and able to consistently\\r\\nput forth.\\r\\n\\r\\nIf you'd like to be considered for committee membership then please\\r\\nwrite a statement describing why you feel you are well-qualified to\\r\\nserve, in terms of the criteria above and any others that you would like\\r\\nto offer. Please send your statements to ben at well-typed.com by September\\r\\n30th. The initial committee selection will be made by the Simons soon\\r\\nthereafter.\\r\\n\\r\\nThanks to everyone for their feedback and cooperation so far!\\r\\n\\r\\nCheers,\\r\\n\\r\\n~ Ben\\r\\n","publish_time":1473101799,"version_time":1473101799,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"steering-committee-cfn","version":2,"title":"Call for Nominations: GHC Steering Committee","body":"Hello everyone,\\r\\n\\r\\nAs you likely know, over the last few months we have been discussing\\r\\noptions for reforming the process for proposing language and\\r\\ncompiler changes to GHC. After much discussion, we have a [[http://github.com/ghc-proposals/ghc-proposals|process]]\\r\\nwhich, while not perfect, is acceptable to a majority of our contributor\\r\\nbase and will be an improvement over the status quo. While we invite\\r\\nsuggestions for future improvements, we are at a point where we can move\\r\\nahead with implementation.\\r\\n\\r\\nConsequently, we are seeking nominations for the initial GHC steering\\r\\ncommittee. This body is responsible for overseeing the progression of\\r\\nproposals through the process, working with authors on refining their\\r\\nideas, and evaluating proposals for acceptance. The committee will\\r\\nconsist of five to eight members of diverse backgrounds.\\r\\n\\r\\nWe would like to offer the following as a criteria for membership. Note\\r\\nthat a candidate is not expected to satisfy all or even most of these\\r\\ncriteria, but a good candidate should satisfy at least one:\\r\\n\\r\\n* A history of contributions to the design of new language features\\r\\n\\r\\n* Experience developing Haskell libraries and applications\\r\\n\\r\\n* A demonstrated track record of contributing code to GHC\\r\\n\\r\\n* A pedagogical background, with experience in either teaching or\\r\\n  authoring educational materials\\r\\n\\r\\n* Experience in compiler development\\r\\n\\r\\n* Knowledge of functional programming language theory\\r\\n\\r\\nI would like to emphasize that committee membership is as much a duty as it\\r\\nis a privilege. Membership is not intended to be a platform to be used\\r\\nby members to drive their own ideas; rather it is a way of serving the\\r\\nHaskell community by helping other community members refine and advance\\r\\ntheir proposals. This, of course, requires an investment of\\r\\ntime and effort, which you should be willing and able to consistently\\r\\nput forth.\\r\\n\\r\\nIf you would like to be considered for committee membership then please\\r\\nwrite a statement describing why you feel you are well-qualified to\\r\\nserve, in terms of the criteria above and any others that you would like\\r\\nto offer. Please send your statements to ben at well-typed.com by September\\r\\n30th. The initial committee selection will be made by the Simons soon\\r\\nthereafter.\\r\\n\\r\\nThanks to everyone for their feedback and cooperation so far!\\r\\n\\r\\nCheers,\\r\\n\\r\\n~ Ben\\r\\n","publish_time":1473101799,"version_time":1473101834,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":""},
{"name":"ghc-8.0.2-released","version":1,"title":"GHC 8.0.2 is available!","body":"The GHC team is happy to at last announce the 8.0.2 release of the\\r\\nGlasgow Haskell Compiler. Source and binary distributions are available\\r\\nat\\r\\n\\r\\n    http://downloads.haskell.org/~ghc/8.0.2/\\r\\n\\r\\nThis is the second release of the 8.0 series and fixes nearly\\r\\ntwo-hundred bugs. These include,\\r\\n\\r\\n  * Interface file build determinism (#4012).\\r\\n\\r\\n  * Compatibility with macOS Sierra and GCC compilers which compile \\r\\n    position-independent executables by default\\r\\n\\r\\n  * Compatibility with systems which use the gold linker\\r\\n\\r\\n  * Runtime linker fixes on Windows (see #12797)\\r\\n\\r\\n  * A compiler bug which resulted in undefined reference errors while\\r\\n    compiling some packages (see #12076)\\r\\n\\r\\n  * A number of memory consistency bugs in the runtime system\\r\\n\\r\\n  * A number of efficiency issues in the threaded runtime which manifest\\r\\n    on larger core counts and large numbers of bound threads.\\r\\n\\r\\n  * A typechecker bug which caused some programs using\\r\\n    -XDefaultSignatures to be incorrectly accepted.\\r\\n\\r\\n  * More than two-hundred other bugs. See [[https://ghc.haskell.org/trac/ghc/query?status=closed&milestone=8.0.2&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&order=priority|Trac]] for a complete\\r\\n    listing.\\r\\n\\r\\n  * #12757, which lead to broken runtime behavior and even crashes in\\r\\n    the presence of primitive strings.\\r\\n\\r\\n  * #12844, a type inference issue affecting partial type signatures.\\r\\n\\r\\n  * A bump of the `directory` library, fixing buggy path\\r\\n    canonicalization behavior (#12894). Unfortunately this required a\\r\\n    major version bump in `directory` and minor bumps in several other\\r\\n    libraries.\\r\\n\\r\\n  * #12912, where use of the `select` system call would lead to runtime\\r\\n    system failures with large numbers of open file handles.\\r\\n\\r\\n  * #10635, wherein -Wredundant-constraints was included in the -Wall\\r\\n    warning set\\r\\n\\r\\nA more detailed list of the changes included in this release can be\\r\\nfound in the [[https://downloads.haskell.org/~ghc/8.0.2/docs/html/users_guide/8.0.2-notes.html|release notes]].\\r\\n\\r\\nPlease note that this release breaks with our usual tendency to avoid\\r\\nmajor version bumps of core libraries in minor GHC releases by including\\r\\nan upgrade of the `directory` library to 1.3.0.0.\\r\\n\\r\\nAlso note that, due to a rather serious bug (#13100) affecting Windows\\r\\nnoticed late in the release cycle, the Windows binary distributions were\\r\\nproduced using a slightly [[http://downloads.haskell.org/~ghc/8.0.2/0001-SysTools-Revert-linker-flags-change.patch|patched]] source tree. Users compiling from\\r\\nsource for Windows should be certain to include this patch in their\\r\\nbuild.\\r\\n\\r\\nThis release is the result of six months of effort by the GHC\\r\\ndevelopment community. We'd like to thank everyone who has contributed\\r\\ncode, bug reports, and feedback to this release. It's only due to\\r\\ntheir efforts that GHC remains a vibrant and exciting project.\\r\\n\\r\\n \\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms\\r\\nare available [[http://www.haskell.org/ghc/|here]].\\r\\n\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standardized lazy functional programming language.\\r\\n\\r\\nThe Glasgow Haskell Compiler (GHC) is a state-of-the-art programming suite for\\r\\nHaskell. Included is an optimising compiler generating efficient code for a\\r\\nvariety of platforms, together with an interactive system for convenient, quick\\r\\ndevelopment. The distribution includes space and time profiling facilities, a\\r\\nlarge collection of libraries, and support for various language extensions,\\r\\nincluding concurrency, exceptions, and foreign language interfaces. GHC is\\r\\ndistributed under a BSD-style open source license.\\r\\n\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them, can be\\r\\nfound on the [[Platforms|GHC wiki]]\\r\\n\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of difficulty. The\\r\\n[[Building|Building Guide]] describes how to go about porting to a new platform.\\r\\n\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors. Instructions on getting started with hacking on GHC\\r\\nare available from GHC's [[http://ghc.haskell.org/trac/ghc/|developer site]].\\r\\n\\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1484160035,"version_time":1484160035,"version_comment":"","version_author":"bgamari","author":"bgamari","categories":"release"},
{"name":"ghc-8.2.11-released","version":1,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/docs/html/users_guide/8.2.1-notes.html|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n   GHC HQ building these distributions ourselves will allow us to more\\r\\n   quickly ship distributions to users by eliminating the need for a\\r\\n   long lag time between source release availability and having all\\r\\n   binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\nHow to get it\\r\\n~~~~~~~~~~~~~\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\nBackground\\r\\n~~~~~~~~~~\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\nGHC home page              http://www.haskell.org/ghc/\\r\\nGHC developers' home page  http://ghc.haskell.org/trac/ghc/\\r\\nHaskell home page          http://www.haskell.org/\\r\\n\\r\\nSupported Platforms\\r\\n~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis here:\\r\\n\\r\\n   http://ghc.haskell.org/trac/ghc/wiki/Contributors\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty.  The Building Guide describes how to go about porting to a\\r\\nnew platform:\\r\\n\\r\\n    http://ghc.haskell.org/trac/ghc/wiki/Building\\r\\n\\r\\nDevelopers\\r\\n~~~~~~~~~~\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1500817720,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":""},
{"name":"ghc-8.2.11-released","version":2,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/docs/html/users_guide/8.2.1-notes.html|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n   GHC HQ building these distributions ourselves will allow us to more\\r\\n   quickly ship distributions to users by eliminating the need for a\\r\\n   long lag time between source release availability and having all\\r\\n   binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\nHow to get it\\r\\n~~~~~~~~~~~~~\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\nBackground\\r\\n~~~~~~~~~~\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\nGHC home page              http://www.haskell.org/ghc/\\r\\nGHC developers' home page  http://ghc.haskell.org/trac/ghc/\\r\\nHaskell home page          http://www.haskell.org/\\r\\n\\r\\nSupported Platforms\\r\\n~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis here:\\r\\n\\r\\n   http://ghc.haskell.org/trac/ghc/wiki/Contributors\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty.  The Building Guide describes how to go about porting to a\\r\\nnew platform:\\r\\n\\r\\n    http://ghc.haskell.org/trac/ghc/wiki/Building\\r\\n\\r\\nDevelopers\\r\\n~~~~~~~~~~\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1500817734,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.11-released","version":3,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/html/users_guide/8.2.1-notes.html\\r\\n|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n   GHC HQ building these distributions ourselves will allow us to more\\r\\n   quickly ship distributions to users by eliminating the need for a\\r\\n   long lag time between source release availability and having all\\r\\n   binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n=== How to get it ===\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[http://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[http://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[http://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis here:\\r\\n\\r\\n   http://ghc.haskell.org/trac/ghc/wiki/Contributors\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty.  The Building Guide describes how to go about porting to a\\r\\nnew platform:\\r\\n\\r\\n    http://ghc.haskell.org/trac/ghc/wiki/Building\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1500827397,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"2017-release-schedule","version":1,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. **(typically a few months after the previous major release)** A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time to allow the community\\r\\nto adopt the new release and discover its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549144,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":2,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release || Date || Time until next major release ||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. **(typically a few months after the previous major release)** A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time to allow the community\\r\\nto adopt the new release and discover its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549195,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":3,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time until next major release =||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. **(typically a few months after the previous major release)** A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time to allow the community\\r\\nto adopt the new release and discover its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549212,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"jenkins-ci","version":1,"title":"Meeting Jenkins: GHC's new CI infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more useful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories like\\r\\nStackage, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]).\\r\\nWe'll be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501549328,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":2,"title":"Meeting Jenkins: GHC's new CI infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more useful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories like\\r\\nStackage, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501549408,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":3,"title":"Meet Jenkins: GHC's new CI infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more useful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories like\\r\\nStackage, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501549425,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":4,"title":"Meet Jenkins: GHC's new CI infrastructure and release","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more useful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories like\\r\\nStackage, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501549444,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"2017-release-schedule","version":4,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time until next major release =||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. **(typically a few months after the previous major release)** A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549525,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":5,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time until next major release =||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. '''(typically a few months after the previous major release)''' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549564,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":6,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time until next major release =||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(typically a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549585,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":7,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time until next major release =||\\r\\n||  6.12.1 ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1 ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549604,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":8,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1  ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1  ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || cut stable branch                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || cut release candidate 1              ||\\r\\n|| Mid May 2017     || cut release candidate 2              ||\\r\\n|| Early July 2017  || cut release candidate 3              ||\\r\\n|| Late July 2017   || cut final release                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549642,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":9,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1  ||  mid December 2009                ||             ||\\r\\n||         ||                                   || 12 months   ||\\r\\n||  7.0.1  ||  mid November 2010                ||             ||\\r\\n||         ||                                   || 9.5 months  ||\\r\\n||  7.2.1  ||  early August 2011                ||             ||\\r\\n||         ||                                   || 6 months    ||\\r\\n||  7.4.1  ||  early February 2012              ||             ||\\r\\n||         ||                                   || 7 months    ||\\r\\n||  7.6.1  ||  early September 2012             ||             ||\\r\\n||         ||                                   || 19 months   ||\\r\\n||  7.8.1  ||  early April 2014                 ||             ||\\r\\n||         ||                                   || 13 months   ||\\r\\n||  7.10.1  ||  late March 2015                  ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.0.1  ||  late May 2016                    ||             ||\\r\\n||         ||                                   || 14 months   ||\\r\\n||  8.2.1  ||  late July 2017                   ||             ||        \\r\\n||         ||                                   || -           ||\\r\\n||  8.4.1  ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time =||= Event =||\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || stable branch cut                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || release candidate 1 cut              ||\\r\\n|| Mid May 2017     || release candidate 2 cut              ||\\r\\n|| Early July 2017  || release candidate 3 cut              ||\\r\\n|| Late July 2017   || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549697,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":10,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nIn general the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time =||= Event =||\\r\\n|| Fall 2016        || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017 || stable branch cut                    ||\\r\\n|| Early April 2017 || most core library versions set       ||\\r\\n||                  || release candidate 1 cut              ||\\r\\n|| Mid May 2017     || release candidate 2 cut              ||\\r\\n|| Early July 2017  || release candidate 3 cut              ||\\r\\n|| Late July 2017   || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant efforts to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved.\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501549756,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":11,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, much be kept in mind when deciding release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501550056,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":12,"title":"Reflections on GHC's release schedule","body":"Reviewing GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be kept in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501550153,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":13,"title":"Reflections on GHC's release schedule","body":"Looking back on GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be kept in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501550220,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":14,"title":"Reflections on GHC's release schedule","body":"Looking back on GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be born in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about?\\r\\n\\r\\n 1. Is the release cycle currently too long? \\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\nWe would love to hear your thoughts.\\r\\n","publish_time":1501549144,"version_time":1501550294,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"jenkins-ci","version":5,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more useful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories like\\r\\nStackage, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501550432,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":6,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\nStackage builds will be more fruitful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501550533,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":7,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\npre-release Stackage builds will be more fruitful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies up-to-date with their upstreams\\r\\nis important to ensure that tools like `ghc-mod` can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501550563,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"jenkins-ci","version":8,"title":"Meet Jenkins: GHC's new CI and build infrastructure","body":"While Phabricator is generally well-liked among GHC developers, GHC's\\r\\ninteraction with Harbormaster, Phabricator's continuous integration\\r\\ncomponent, has been less than rosy. The problem is in large part a mismatch\\r\\nbetween Harbormaster's design assumptions and GHC's needs, but it's also\\r\\nin part attributable to the somewhat half-finished state in which\\r\\nHarbormaster seems to linger. Regardless, we won't go into detail here;\\r\\nthese issues are well covered [[ticket:13716|elsewhere]].\\r\\n\\r\\nSuffice it to say that, after having looked at a number of alternatives to\\r\\nHarbormaster (including [[https://buildbot.net/|buildbot]], GitLab's\\r\\n[[https://gitlab.com/|Pipelines]], [[https://concourse.ci/|Concourse]],\\r\\nand home-grown solutions), Jenkins seems to be the best option at\\r\\nthe moment. Of course, this is not to say that it is perfect; as we have\\r\\nlearned over the last few months it is very far from perfect. However,\\r\\nit has the maturity and user-base to be almost-certainly able to handle\\r\\nwhat we need of it on the platforms that we care about.\\r\\n\\r\\nLet's see what we get out of this new bit of infrastructure:\\r\\n\\r\\n=== Pre-merge testing ===\\r\\n\\r\\nCurrently there are two ways that code ends up in `master`,\\r\\n\\r\\n * a Differential is opened, built with Harbormaster, and eventually\\r\\n   landed (hopefully, but not always, after Harbormaster successfully finishes)\\r\\n\\r\\n * someone pushes commits directly\\r\\n\\r\\nBad commits routinely end up merged via both channels. This means that\\r\\nauthors of patches failing CI often need to consider whether *their*\\r\\npatch is incorrect or whether they rather simply had the misfortune of\\r\\nbasing their patch on a bad commit. Even worse, if the commit isn't\\r\\nquickly reverted or fixed GHC will end up with a whole in its commit\\r\\nhistory where neither bisection nor performance tracking will be possible.\\r\\nFor these reasons, we want to catch these commits before they make it\\r\\ninto `master`.\\r\\n\\r\\nTo accomplish this we have developed some\\r\\n[[https://github.com/bgamari/ghc-auto-push|tooling]] to run CI on\\r\\ncommits *before* they are finally merged to `master`. By making CI the\\r\\nonly path patches can take to get to `master`, improve our changes of\\r\\nrejecting bad patches before they turn the tree red.\\r\\n\\r\\n\\r\\n=== Automation of the release builds ===\\r\\n\\r\\nSince the 7.10.3 release we have been gradually working towards\\r\\nautomating GHC's release process. Thanks to this work, today a single\\r\\nperson can build binary distributions for all seven tier-1\\r\\nconfigurations in approximately a day, most of which is spent simply\\r\\nwaiting. This has allowed us to take responsibility (starting in\\r\\n8.2.1) for the OpenBSD, FreeBSD, ARMv7 and AArch64 builds in addition to\\r\\nthe traditional tier-1 platforms, allowing us to eliminate the week-long\\r\\nwait between source distribution availability and the binary\\r\\ndistribution announcement previously needed for correspondence with\\r\\nbinary build contributors..\\r\\n\\r\\nHowever, we are far from done: our new Jenkins-based build infrastructure\\r\\n(see #13716) will allow us to produce binary distributions directly from CI,\\r\\nreducing the cost of producing release builds to nearly nothing.\\r\\n\\r\\n\\r\\n=== Testing of GHC against user packages ===\\r\\n\\r\\nWhile GHC is already tested against Hackage and Stackage prior to release\\r\\ncandidate availability, these builds have been of limited use as\\r\\npackages low on the dependency tree (think `hashable` and `lens`)\\r\\noften don't build prior to the first release candidate. While we do our\\r\\nbest to fix these packages up, the sheer number of them makes\\r\\nthis a losing battle for a small team such as GHC's.\\r\\n\\r\\nHaving the ability to cheaply produce binary distributions means that we\\r\\ncan produce and validate nightly snapshot releases. This gives users a\\r\\nconvenient way to test pre-release compilers and fix their libraries\\r\\naccordingly. We hope this will spread the maintenance effort across a\\r\\nlarger fraction of the Haskell community and over a longer period of\\r\\ntime, meaning there will be less to do at release time and consequently\\r\\npre-release Stackage builds will be more fruitful.\\r\\n\\r\\nOnce the Jenkins infrastructure is stable, we can consider introducing\\r\\nnightly builds of user packages as well. While building a large\\r\\npopulation such as Stackage would likely not be productive, working with\\r\\na smaller sample of popular, low-dependency-count packages would be\\r\\nquite possible. For testing against larger package repositories, leaning on a dedicated tool such as the\\r\\n[[https://matrix.hackage.haskell.org/|Hackage Matrix Builder]] will\\r\\nlikely be a more productive path.\\r\\n\\r\\n=== Expanded platform coverage of CI ===\\r\\n\\r\\nWhile GHC targets a wide variety of architectures and operating systems\\r\\n(and don't forget cross-compilation targets),\\r\\nby far the majority of developers use Linux, Darwin, or Windows on\\r\\namd64. This means that breakage often only comes to light long after the\\r\\nculpable patch was merged.\\r\\n\\r\\nOf course, GHC, being a project with modest financial resources, can't\\r\\ntest each commit on every supported platform. We can, however, shrink\\r\\nthe time between a bad commit being merged and the breakage being found\\r\\nby testing these \"unusual\" platforms on a regular (e.g. nightly) basis.\\r\\n\\r\\nBy catching regressions early, we hope to reduce the amount of time\\r\\nspent bisecting and fixing bugs around release time.\\r\\n\\r\\n=== Tracking core libraries ===\\r\\n\\r\\nKeeping GHC's core library dependencies (e.g. `directory`, `process`) up-to-date with their respective upstreams\\r\\nis important to ensure that tools that link against the `ghc` library (e.g. `ghc-mod`) can build easily.\\r\\nHowever, it also requires that we work with nearly a dozen upstream\\r\\nmaintainers at various points in their own release cycles to arrange\\r\\nthat releases are made prior to the GHC release. Moreover, there is\\r\\ninevitably a fair amount of work propagating verion bounds changes down\\r\\nthe dependency tree. While this work takes relatively little effort in\\r\\nterms of man-hours,\\r\\n\\r\\nJenkins can help us here by allowing us to automate integration testing\\r\\nof upstream libraries, catching bounds issues and other compatibility\\r\\nissues well before they are in the critical path of the release.\\r\\n\\r\\n=== Improved debugging tools ===\\r\\n\\r\\nOne of the most useful ways to track down a bugs in GHC is bisection.\\r\\nThis is especially true for regressions found in release candidates,\\r\\nwhere you have at most a few thousand commits to bisect through.\\r\\nNevertheless, GHC builds are long and developer time scarce so this\\r\\napproach isn't used as often as it could be.\\r\\n\\r\\nHaving an archive of nightly GHC builds will free the developer from\\r\\nhaving to build dozens of compilers during bisection, making the process\\r\\na significantly more enjoyable experience than it is today. This will\\r\\nallow us to solve more bugs in less time and with far fewer grey hairs.\\r\\n\\r\\n== Status of Jenkins effort ==\\r\\n\\r\\nThe Jenkins CI overhaul has been an on-going project throughout the\\r\\nspring and summer and is nearing completion. The Jenkins configuration\\r\\ncan be seen in the `wip/jenkins` branch on `git.haskell.org`\\r\\n([[https://git.haskell.org/ghc.git/shortlog/refs/heads/wip/jenkins|gitweb]]). At the moment the prototype is running on a few private machines but we will be setting up a publicly accessible test instance in the coming\\r\\nweeks. Jenkins will likely coexist with our current Harbormaster\\r\\ninfrastructure for a month or so while we validate that things are\\r\\nstable.\\r\\n","publish_time":1501549328,"version_time":1501550801,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"ci testing infrastructure"},
{"name":"2017-release-schedule","version":15,"title":"Reflections on GHC's release schedule","body":"Looking back on GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be born in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about,\\r\\n\\r\\n 1. Do you feel that it takes too long for GHC features to make it to users' hands?\\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n\\r\\n\\r\\nWe would love to hear your thoughts. Be sure to mention whether you are a user, GHC contributor, or both.\\r\\n","publish_time":1501549144,"version_time":1501551447,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"2017-release-schedule","version":16,"title":"Reflections on GHC's release schedule","body":"Looking back on GHC's past release schedule reveals a rather checkered past,\\r\\n\\r\\n||= Release =||= Date =||= Time to next major release =||\\r\\n||  6.12.1   ||  mid December 2009                ||             ||\\r\\n||           ||                                   || 12 months   ||\\r\\n||  7.0.1    ||  mid November 2010                ||             ||\\r\\n||           ||                                   || 9.5 months  ||\\r\\n||  7.2.1    ||  early August 2011                ||             ||\\r\\n||           ||                                   || 6 months    ||\\r\\n||  7.4.1    ||  early February 2012              ||             ||\\r\\n||           ||                                   || 7 months    ||\\r\\n||  7.6.1    ||  early September 2012             ||             ||\\r\\n||           ||                                   || 19 months   ||\\r\\n||  7.8.1    ||  early April 2014                 ||             ||\\r\\n||           ||                                   || 13 months   ||\\r\\n||  7.10.1   ||  late March 2015                  ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.0.1    ||  late May 2016                    ||             ||\\r\\n||           ||                                   || 14 months   ||\\r\\n||  8.2.1    ||  late July 2017                   ||             ||        \\r\\n||           ||                                   || -           ||\\r\\n||  8.4.1    ||  TDB and the topic of this post   ||             ||\\r\\n\\r\\nThere are a few things to notice here:\\r\\n\\r\\n * release cadence has swung rather wildly\\r\\n * the release cycle has stretched in the last several releases\\r\\n * time-between-releases generally tends to be on the order of a year\\r\\n\\r\\nWhile GHC is far from the only compiler with such an extended release\\r\\nschedule, others (namely LLVM, Go, and, on the extreme end, Rust) have shown\\r\\nthat shorter cycles are possible. I personally think that a more\\r\\nstable, shorter release cycle would be better for developers and users\\r\\nalike,\\r\\n\\r\\n * developers have a tighter feedback loop, inducing less pressure\\r\\n   to get new features and non-critical bugfixes into minor releases\\r\\n * release managers have fewer patches to cherry-pick\\r\\n * users see new features and bugfixes more quickly\\r\\n\\r\\nWith 8.2.1 at long last behind us, now is a good time to reflect\\r\\non why these cycles are so long, what release schedule we would like\\r\\nto have, and what we can change to realize such a schedule. On the way we'll take some time to examine the circumstances that lead to the 8.2.1 release which, while not typical, remind us that there is a certain amount of unpredictability inherent in developing large systems like GHC; a fact that must be born in mind when considering release policy.\\r\\n\\r\\nLet's dig in...\\r\\n\\r\\n== The release process today ==\\r\\n\\r\\nCutting a GHC release is a fairly lengthy process involving many\\r\\nparties and a significant amount of planning. The typical process\\r\\nfor a major release looks something like this,\\r\\n\\r\\n 1. ''(a few months after the previous major release)'' A set\\r\\n    of release priorities are defined determining which major features\\r\\n    we want in the coming release\\r\\n 2. wait until all major features are merged to the `master` branch\\r\\n 3. when all features are merged, cut a stable branch\\r\\n 4. in parallel:\\r\\n    a. coordinate with core library authors to determine which library\\r\\n       versions the new release should ship\\r\\n    b. prepare release documentation\\r\\n    c. do preliminary testing against Hackage and Stackage to identify and\\r\\n       fix early bugs\\r\\n    d. backport significant fixes merged to `master`\\r\\n 5. when the tasks in (4) are sufficiently advanced, cut a source\\r\\n    release for a release candidate \\r\\n 6. produce tier-1 builds and send source tarballs to binary packagers,\\r\\n    wait a week to prepare binary builds; if anyone finds the tree is\\r\\n    unbuildable, go back to (5)\\r\\n 7. upload release artifacts, announce release candidate\\r\\n 8. wait a few weeks for testing\\r\\n 9. if there are significant issues: fix them and return to (5)\\r\\n 10. finalize release details (e.g. release notes, last check over core library versions)\\r\\n 11. cut source tarball, send to binary build contributors, wait a week for builds\\r\\n 12. announce final release, celebrate!\\r\\n\\r\\nTypically the largest time-sinks in this process are waiting for\\r\\nregression fixes and coordinating with core library authors. In\\r\\nparticular, the coordination involved in the latter isn't difficult, but\\r\\nmerely high latency.\\r\\n\\r\\nIn the case of 8.2.1, the timeline looked something like this,\\r\\n\\r\\n||= Time            =||= Event =||\\r\\n|| Fall 2016         || release priorities for 8.2 discussed ||\\r\\n|| Early March 2017  || stable branch cut                    ||\\r\\n|| Early April 2017  || most core library versions set       ||\\r\\n||                   || release candidate 1 cut              ||\\r\\n|| Mid May 2017      || release candidate 2 cut              ||\\r\\n|| Early July 2017   || release candidate 3 cut              ||\\r\\n|| Late July 2017    || final release cut                    ||\\r\\n\\r\\n== Unexpected set-backs ==\\r\\n\\r\\nThis timeline was a bit more extended than ideal for a few\\r\\nreasons.\\r\\n\\r\\nThe first issues were #13426 and #13535, compile-time performance regressions which\\r\\ncame to light shortly after the branch and after the first release\\r\\ncandidate, respectively. In #13535 it was observed that the testsuite of\\r\\nthe `vector` package (already\\r\\n[[https://ghc.haskell.org/trac/ghc/ticket/10800|known]] for its\\r\\npropensity to reveal compiler regressions) increased by nearly a factor\\r\\nof five in compile-time allocations over 8.0.2.\\r\\n\\r\\nWhile a performance regression would rarely classify as a release\\r\\nblocker, both the severity of the regressions combined with the fact that\\r\\n8.2 was intended to be a performance-oriented release made releasing\\r\\nbefore fixes were available quite unappealing. For this reason David\\r\\nFeuer, Reid Barton, and I invested significant effort to try to track down the\\r\\nculprits. Unfortunately, the timescale on which this sort of bug is\\r\\nresolved span days, stretching to weeks when time is split with other\\r\\nresponsibilities. While Reid's valiant efforts lead to the resolution of\\r\\n#13426, we were eventually forced to set #13535 aside as the release\\r\\ncycle wore on.\\r\\n\\r\\nThe second setback came in the form of two quite grave correctness\\r\\nissues (#13615, #13916) late in the cycle. GHC being a compiler, we take\\r\\ncorrectness very seriously: Users' confidence that GHC will\\r\\ncompile their programs faithfully is crucial for language adoption, yet\\r\\nalso very easily shaken. Consequently, while neither of these issues\\r\\nwere regressions from 8.0, we deemed it important to hold the 8.2\\r\\nrelease until these issues were resolved (which ended up being significant efforts in their own right; a blog post on this will be coming soon).\\r\\n\\r\\nFinally, there was the realization (#13739) after release candidate 2\\r\\nthat some BFD linker releases suffered from very poor performance when\\r\\nlinking with split-sections enabled (the default behavior in 8.2.1).\\r\\nThis served as a forcing function to act on #13541, which we originally\\r\\nplanned for 8.4. As expected, it took quite some time to follow through\\r\\non this in a way that satisfied users and distribution packagers in a\\r\\nportable manner.\\r\\n\\r\\n== Moving forward: Compressing the release schedule ==\\r\\n\\r\\nCollectively the above issues set the release back by perhaps six or\\r\\neight weeks in total, including the additional release candidate\\r\\nnecessary to validate the raft of resulting patches. While set-backs due\\r\\nto long-standing bugs are hard to avoid, there are a few areas where we\\r\\ncan do better,\\r\\n\\r\\n a. automate the production of release artifacts\\r\\n b. regularly test GHC against user packages in between releases\\r\\n c. expand continuous integration of GHC to less common platforms to\\r\\n    ensure that compatibility problems are caught before the release\\r\\n    candidate stage\\r\\n d. regularly synchronize with core library maintainers between releases\\r\\n    to reduce need for version bound bumps at release time\\r\\n e. putting in place tools to ease bisection, which is frequently a\\r\\n    useful debugging strategy around release-time\\r\\n\\r\\nAs it turns out, nearly all of these are helped by our on-going effort\\r\\nto move GHC's CI infrastructure to Jenkins (see #13716). As this is a\\r\\nrather deep topic in its own right, I'll leave this more technical\\r\\ndiscussion for a second post (blog:jenkins-ci).\\r\\n\\r\\nWith the above tooling and process improvements, I think it would be\\r\\nfeasible to get the GHC release cycle down to six months or shorter if\\r\\nwe so desired. Of course, shorter isn't necessarily better: we need to\\r\\nbe careful to balance the desire for a short release cycle against the\\r\\nneed for an adequate post-release \"percolation\" time. This time is crucial to allow the community\\r\\nto adopt the new release, discover and fix its regressions. In fact, the\\r\\npredictability that a short release schedule (hopefully) affords is\\r\\narguably more important than the high cadence itself.\\r\\n\\r\\nConsequently, we are considering tightening up the release schedule for\\r\\nfuture GHC releases in a slow and measured manner. Given that we are now\\r\\nwell into the summer, I think positioning the 8.4 release around\\r\\nFebruary 2018, around seven months from now, would be a sensible\\r\\ntimeline. However, we would like to hear your opinions.\\r\\n\\r\\nHere are some things to think about,\\r\\n\\r\\n 1. Do you feel that it takes too long for GHC features to make it to users' hands?\\r\\n 2. How many times per year do you envision upgrading your compiler\\r\\n    before the process becomes too onerous? Would the current load of interface changes per release be acceptable under a faster release cadence?\\r\\n 3. Should we adjust the\\r\\n    [[https://prime.haskell.org/wiki/Libraries/3-Release-Policy|three-release policy]]\\r\\n    to counteract a shorter GHC release cycle?\\r\\n 4. Would you feel more likely to contribute to GHC if your work were more quickly available in a release?\\r\\n\\r\\n\\r\\nWe would love to hear your thoughts. Be sure to mention whether you are a user, GHC contributor, or both.\\r\\n","publish_time":1501549144,"version_time":1501551630,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release schedule"},
{"name":"ghc-8.2.11-released","version":5,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/html/users_guide/8.2.1-notes.html\\r\\n|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n  GHC HQ building these distributions ourselves will allow us to more\\r\\n  quickly ship distributions to users by eliminating the need for a\\r\\n  long lag time between source release availability and having all\\r\\n  binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n=== How to get it ===\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1511302193,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.2-released","version":4,"title":"GHC 8.2.2 is available","body":"The GHC Team is pleased to announce a new minor release of GHC. This release\\r\\nbuilds on the performance and stability improvements of 8.2.1, fixing a variety\\r\\nof correctness bugs, improving error messages, and making the compiler more\\r\\nportable.\\r\\n\\r\\nNotable bug-fixes include\\r\\n\\r\\n * A correctness issue resulting in segmentation faults in some\\r\\n   FFI-users (#13707, #14346)\\r\\n\\r\\n * A correctness issue resulting in undefined behavior in some programs\\r\\n   using STM (#14171)\\r\\n\\r\\n * A bug which may have manifested in segmentation faults in\\r\\n   out-of-memory condition (#14329)\\r\\n\\r\\n * clearBit of Natural no longer bottoms (#13203)\\r\\n\\r\\n * A specialisation bug resulting in exponential blowup of compilation\\r\\n   time in some specialisation-intensive programs (#14379)\\r\\n\\r\\n * ghc-pkg now works even in environments with misconfigured NFS mounts\\r\\n   (#13945)\\r\\n\\r\\n * GHC again supports production of position-independent executables\\r\\n   (#13702)\\r\\n\\r\\n * Better error messages around kind mismatches (#11198, #12373, #13530,\\r\\n   #13610)\\r\\n\\r\\nA thorough list of the changes in the release can be found in the release\\r\\nnotes,\\r\\n\\r\\n    https://haskell.org/ghc/docs/8.2.2/html/users_guide/8.2.2-notes.html\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_2_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1511302017,"version_time":1511302961,"version_comment":"Fix release notes","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.2.11-released","version":6,"title":"GHC 8.2.1 is available","body":"= The Glasgow Haskell Compiler -- version 8.2.1 =\\r\\n\\r\\nThe GHC developers are very happy to announce the long-awaited 8.2.1\\r\\nrelease of Glasgow Haskell Compiler. Binary and source distributions can\\r\\nbe found at <https://downloads.haskell.org/~ghc/8.2.1/>.\\r\\n\\r\\nThis is the second release in the 8.0 series. As such, the focus of this\\r\\nrelease is performance, stability, and consolidation. Consequently\\r\\nnumerous cleanups can be seen throughout the compiler including,\\r\\n\\r\\n * Significant improvements in compiler performance\\r\\n\\r\\n * More robust support for levity polymorphism\\r\\n\\r\\n * Reliable DWARF debugging information\\r\\n\\r\\n * Improved runtime system performance on NUMA systems\\r\\n\\r\\n * Retooling of the cost-center profiler, including support for live\\r\\n   streaming of profile data via the GHC event log\\r\\n\\r\\n * Interface file determinism\\r\\n\\r\\n * More robust treatment of join points, enabling significantly better\\r\\n   code generation in many cases\\r\\n\\r\\n * Numerous improvements in robustness on Windows\\r\\n\\r\\n * and the resolution of over 500 other tickets\\r\\n\\r\\nIn addition, there are a number of new features,\\r\\n\\r\\n * A new, more type-safe type reflection mechanism\\r\\n\\r\\n * The long-awaited Backpack module system\\r\\n\\r\\n * Deriving strategies to disambiguate between GHC's various instance\\r\\n   deriving mechanisms\\r\\n\\r\\n * Unboxed sum types, for efficient unpacked representation of sum data\\r\\n   types\\r\\n\\r\\n * Compact regions, allowing better control over garbage collection\\r\\n   in the presence of large heaps containing many long-lived objects.\\r\\n\\r\\n * Colorful messages and caret diagnostics for more legible errors\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\n[[https://haskell.org/ghc/docs/8.2.1/html/users_guide/8.2.1-notes.html\\r\\n|release notes]].\\r\\n\\r\\nThere are a few changes in release-engineering that should be noted,\\r\\n\\r\\n * Binary distributions for 32-bit CentOS 6.7 have been dropped.\\r\\n   Moreover, there are no dedicated CentOS 7.0 distributions as CentOS 7\\r\\n   can use can use Debian 8 binaries. If you would like us to continue\\r\\n   to produce 32-bit CentOS 6.7 distributions please let us know.\\r\\n\\r\\n * GHC HQ now builds FreeBSD and OpenBSD distributions for amd64; this\\r\\n   comes after many years of these distributions being faithfully\\r\\n   provided by Karel Gardas and Pali Gabor Janos, who we should heartily\\r\\n   thank for their contributions.\\r\\n\\r\\n  GHC HQ building these distributions ourselves will allow us to more\\r\\n  quickly ship distributions to users by eliminating the need for a\\r\\n  long lag time between source release availability and having all\\r\\n  binary distributions available.\\r\\n\\r\\n * There is a technology-preview of an AArch64 Linux binary\\r\\n   distribution, as well as an ARM Linux build. AArch64 support is quite\\r\\n   preliminary but should be stable in 8.4 thanks to further linker\\r\\n   fixes by Moritz Angerman. ARM should be stable.\\r\\n\\r\\n * GHC now tries to use the gold and lld linkers by default. These\\r\\n   linkers are significantly faster than the BFD linker implementation\\r\\n   that most Linux distributions use by default. If gold or lld are not\\r\\n   available GHC will use the system's default linker. GHC can be forced\\r\\n   to use the default linker by passing --disable-ld-override to\\r\\n   configure.\\r\\n\\r\\nThis release has been the result of over a year of hard work by over 150\\r\\ncode contributors. Thanks to everyone who has helped in writing patches,\\r\\ntesting, reporting bugs, and offering feedback over the last year.\\r\\n\\r\\nThis release cycle was admittedly quite drawn out, significantly longer\\r\\nthan expected or desired. While we are confident that the result is\\r\\nworth the wait, we have been steadily working on infrastructure which\\r\\nshould help shrink future release cycles and give us better testing\\r\\nbetween releases. More details on this coming soon.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n=== How to get it ===\\r\\n\\r\\nBoth the source tarball and binary distributions for a wide variety of platforms are available [[https://downloads.haskell.org/~ghc/8.2.1/|here]].\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, developers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1500817720,"version_time":1511307631,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.1-released","version":1,"title":"GHC 8.4.1 released","body":"The GHC developers are very happy to announce the 8.4.1 release of\\r\\nGlasgow Haskell Compiler. Binary and source distributions can be found\\r\\nat\\r\\n\\r\\n    https://downloads.haskell.org/~ghc/8.4.1/\\r\\n\\r\\nThis is the third major release in the GHC 8 series. As such, the focus\\r\\nof this release is performance, stability, and consolidation.\\r\\nConsequently numerous cleanups can be seen throughout the compiler\\r\\nincluding,\\r\\n\\r\\n * Further refinement of TypeInType, including significant improvements\\r\\n   in error messages.\\r\\n\\r\\n * Improvements in code generation resulting in noticable performance\\r\\n   improvements in some types of programs.\\r\\n\\r\\n * Core library improvements, including phase 2 of the Semigroup/Monoid\\r\\n   proposal\\r\\n\\r\\n * Many improvements to instance deriving\\r\\n\\r\\n * The resolution of nearly 300 other tickets\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\nrelease notes,\\r\\n\\r\\n  https://downloads.haskell.org/~ghc/8.4.1/docs/html/users_guide/8.4.1-notes.html\\r\\n\\r\\nThere are a few changes in release-engineering matters that should be\\r\\nnoted,\\r\\n\\r\\n * This is GHC's first release on it's new, accelerated release\\r\\n   schedule. From now on GHC will produce one release every six months.\\r\\n\\r\\n * While we typically strive to produce OpenBSD builds, the gcc shipped\\r\\n   with OpenBSD 6.1 is unfortunately too old to compile this release.\\r\\n\\r\\n * FreeBSD builds are still in progress\\r\\n\\r\\nThis release has been the result of approximately six months of work by\\r\\nover one hundred code contributors. Thanks to everyone who has helped in\\r\\nwriting patches, testing, reporting bugs, and offering feedback over the\\r\\nlast year.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_2_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1520529751,"version_time":1520529751,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.1-released","version":2,"title":"GHC 8.4.1 released","body":"The GHC developers are very happy to announce the 8.4.1 release of\\r\\nGlasgow Haskell Compiler. Binary and source distributions can be found\\r\\nat\\r\\n\\r\\n    https://downloads.haskell.org/~ghc/8.4.1/\\r\\n\\r\\nThis is the third major release in the GHC 8 series. As such, the focus\\r\\nof this release is performance, stability, and consolidation.\\r\\nConsequently numerous cleanups can be seen throughout the compiler\\r\\nincluding,\\r\\n\\r\\n * Further refinement of TypeInType, including significant improvements\\r\\n   in error messages.\\r\\n\\r\\n * Improvements in code generation resulting in noticable performance\\r\\n   improvements in some types of programs.\\r\\n\\r\\n * Core library improvements, including phase 2 of the Semigroup/Monoid\\r\\n   proposal\\r\\n\\r\\n * Many improvements to instance deriving\\r\\n\\r\\n * The resolution of nearly 300 other tickets\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\nrelease notes,\\r\\n\\r\\n  https://downloads.haskell.org/~ghc/8.4.1/docs/html/users_guide/8.4.1-notes.html\\r\\n\\r\\nThere are a few changes in release-engineering matters that should be\\r\\nnoted,\\r\\n\\r\\n * This is GHC's first release on it's new, accelerated release\\r\\n   schedule. From now on GHC will produce one release every six months.\\r\\n\\r\\n * While we typically strive to produce OpenBSD builds, the gcc shipped\\r\\n   with OpenBSD 6.1 is unfortunately too old to compile this release.\\r\\n\\r\\n * FreeBSD builds are still in progress\\r\\n\\r\\nThis release has been the result of approximately six months of work by\\r\\nover one hundred code contributors. Thanks to everyone who has helped in\\r\\nwriting patches, testing, reporting bugs, and offering feedback over the\\r\\nlast year.\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_4_1.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1520529751,"version_time":1520530521,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.2-released","version":1,"title":"GHC 8.4.2 released","body":"The GHC team is pleased to announce the availability of GHC 8.4.2. The\\r\\nsource distribution, binary distributions, and documentation for this\\r\\nrelease are available at\\r\\n\\r\\n    https://downloads.haskell.org/~ghc/8.4.2\\r\\n\\r\\nThis release is a bug-fix release, fixing numerous regressions and bugs\\r\\npresent in GHC 8.4.1. These include:\\r\\n\\r\\n * A regression resulting in some uses of `Control.Exception.evaluate`\\r\\n   to be inappropriately optimised away (see #13930)\\r\\n\\r\\n * A regression resulting in segmentation faults of programs compiled\\r\\n   with profiling (#14705)\\r\\n\\r\\n * A bug causing runtime system panics while running programs with\\r\\n   retainer profiling (#14947)\\r\\n\\r\\n * The configure scripts now accepts a `--disable-dtrace` option, again\\r\\n   allowing GHC to be bootstrapped on FreeBSD (#15040)\\r\\n\\r\\n * The version number of the `base` package has been bumped to\\r\\n   4.11.1.0 to reflect the addition of the `GHC.IO.FixIOException` type.\\r\\n   This interface was added in 8.4.1 but the version bump was missed due to\\r\\n   an oversight.\\r\\n\\r\\n * Support for DWARF debug information has been significantly improved\\r\\n   (#14894, #14779)\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\nrelease notes,\\r\\n\\r\\n  https://downloads.haskell.org/~ghc/8.4.2/docs/html/users_guide/8.4.2-notes.html\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_4_1.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1524182592,"version_time":1524182592,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.2-released","version":2,"title":"GHC 8.4.2 released","body":"The GHC team is pleased to announce the availability of GHC 8.4.2. The\\r\\nsource distribution, binary distributions, and documentation for this\\r\\nrelease are available at\\r\\n\\r\\n    https://downloads.haskell.org/~ghc/8.4.2\\r\\n\\r\\nThis release is a bug-fix release, fixing numerous regressions and bugs\\r\\npresent in GHC 8.4.1. These include:\\r\\n\\r\\n * A regression resulting in some uses of `Control.Exception.evaluate`\\r\\n   to be inappropriately optimised away (see #13930)\\r\\n\\r\\n * A regression resulting in segmentation faults of programs compiled\\r\\n   with profiling (#14705)\\r\\n\\r\\n * A bug causing runtime system panics while running programs with\\r\\n   retainer profiling (#14947)\\r\\n\\r\\n * The configure scripts now accepts a `--disable-dtrace` option, again\\r\\n   allowing GHC to be bootstrapped on FreeBSD (#15040)\\r\\n\\r\\n * The version number of the `base` package has been bumped to\\r\\n   4.11.1.0 to reflect the addition of the `GHC.IO.FixIOException` type.\\r\\n   This interface was added in 8.4.1 but the version bump was missed due to\\r\\n   an oversight.\\r\\n\\r\\n * Support for DWARF debug information has been significantly improved\\r\\n   (#14894, #14779)\\r\\n\\r\\nA more thorough list of the changes in this release can be found in the\\r\\nrelease notes,\\r\\n\\r\\n  https://downloads.haskell.org/~ghc/8.4.2/docs/html/users_guide/8.4.2-notes.html\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n\\r\\n== How to get it ==\\r\\n\\r\\nThis release can be downloaded from\\r\\n\\r\\n    https://www.haskell.org/ghc/download_ghc_8_4_2.html\\r\\n\\r\\nFor older versions see\\r\\n\\r\\n    https://www.haskell.org/ghc/\\r\\n\\r\\nWe supply binary builds in the native package format for many platforms, and the\\r\\nsource distribution is available from the same place.\\r\\n\\r\\n== Background ==\\r\\n\\r\\nHaskell is a standard lazy functional programming language.\\r\\n\\r\\nGHC is a state-of-the-art programming suite for Haskell.  Included is\\r\\nan optimising compiler generating efficient code for a variety of\\r\\nplatforms, together with an interactive system for convenient, quick\\r\\ndevelopment.  The distribution includes space and time profiling\\r\\nfacilities, a large collection of libraries, and support for various\\r\\nlanguage extensions, including concurrency, exceptions, and foreign\\r\\nlanguage interfaces. GHC is distributed under a BSD-style open source license.\\r\\n\\r\\nA wide variety of Haskell related resources (tutorials, libraries,\\r\\nspecifications, documentation, compilers, interpreters, references,\\r\\ncontact information, links to research groups) are available from the\\r\\nHaskell home page (see below).\\r\\n\\r\\nOn-line GHC-related resources\\r\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n\\r\\nRelevant URLs on the World-Wide Web:\\r\\n\\r\\n * [[https://www.haskell.org/ghc/|GHC home page]]\\r\\n * [[https://ghc.haskell.org/trac/ghc/|GHC developers' home page]]\\r\\n * [[https://www.haskell.org/|Haskell home page]]\\r\\n\\r\\n== Supported Platforms ==\\r\\n\\r\\nThe list of platforms we support, and the people responsible for them,\\r\\nis [[https://ghc.haskell.org/trac/ghc/wiki/Contributors|here]]\\r\\n\\r\\nPorts to other platforms are possible with varying degrees of\\r\\ndifficulty. The [[http://ghc.haskell.org/trac/ghc/wiki/Building|Building Guide]] describes how to go about porting to a\\r\\nnew platform.\\r\\n\\r\\n== Developers ==\\r\\n\\r\\nWe welcome new contributors.  Instructions on accessing our source\\r\\ncode repository, and getting started with hacking on GHC, are\\r\\navailable from the GHC's developer's site run by [[http://ghc.haskell.org/trac/ghc/|Trac]].\\r\\n  \\r\\n\\r\\n== Community Resources ==\\r\\n\\r\\nThere are mailing lists for GHC users, develpoers, and monitoring bug tracker\\r\\nactivity; to subscribe, use the Mailman\\r\\n[[http://mail.haskell.org/cgi-bin/mailman/listinfo|web interface]].\\r\\n\\r\\nThere are several other Haskell and GHC-related mailing lists on\\r\\n[[http://www.haskell.org|haskell.org]]; for the full list, see the\\r\\n[[https://mail.haskell.org/cgi-bin/mailman/listinfo|lists page]].\\r\\n\\r\\nSome GHC developers hang out on the `#ghc` and `#haskell` of the Freenode IRC\\r\\nnetwork, too. See the [[http://www.haskell.org/haskellwiki/IRC_channel|Haskell wiki]] for details.\\r\\n\\r\\nPlease report bugs using our bug tracking system. Instructions on reporting bugs\\r\\ncan be found [[http://www.haskell.org/ghc/reportabug|here]].\\r\\n","publish_time":1524182592,"version_time":1524231605,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.3-released","version":1,"title":"GHC 8.4.3 released","body":"Hello everyone,\\r\\n\\r\\nThe GHC team is pleased to announce the availability of GHC 8.4.3. The\\r\\nsource distribution, binary distributions, and documentation for this\\r\\nrelease are available [[https://downloads.haskell.org/~ghc/8.4.3|here]].\\r\\n\\r\\nThis release includes a few bug fixes including:\\r\\n\\r\\n * A code generation bug resulting in crashing of some programs using\\r\\n   UnboxedSums has been fixed (#15038).\\r\\n\\r\\n * #14381, where Cabal and GHC would disagree about `abi-depends`,\\r\\n   resulting in build failures, has been worked around. Note that the\\r\\n   work-around patch has already been shipped by several distributions\\r\\n   in previous releases, so this change may not be visible to you.\\r\\n\\r\\n * By popular demand, GHC now logs a message when it reads a package\\r\\n   environment file, hopefully eliminating some of the confusion wrought\\r\\n   by this feature.\\r\\n\\r\\n * GHC now emits assembler agreeable to newer versions of Gnu binutils,\\r\\n   fixing #15068.\\r\\n\\r\\n * `SmallArray#`s can now be compacted into a compact region\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n","publish_time":1527624538,"version_time":1527624538,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.4.3-released","version":2,"title":"GHC 8.4.3 released","body":"Hello everyone,\\r\\n\\r\\nThe GHC team is pleased to announce the availability of GHC 8.4.3. The\\r\\nsource distribution, binary distributions, and documentation for this\\r\\nrelease are available [[https://downloads.haskell.org/~ghc/8.4.3|here]].\\r\\n\\r\\nThis release includes a few bug fixes including:\\r\\n\\r\\n * A code generation bug resulting in crashing of some programs using\\r\\n   `UnboxedSums` has been fixed (#15038).\\r\\n\\r\\n * #14381, where Cabal and GHC would disagree about `abi-depends`,\\r\\n   resulting in build failures, has been worked around. Note that the\\r\\n   work-around patch has already been shipped by several distributions\\r\\n   in previous releases, so this change may not be visible to you.\\r\\n\\r\\n * By popular demand, GHC now logs a message when it reads a package\\r\\n   environment file, hopefully eliminating some of the confusion wrought\\r\\n   by this feature.\\r\\n\\r\\n * GHC now emits assembler agreeable to newer versions of Gnu binutils,\\r\\n   fixing #15068.\\r\\n\\r\\n * `SmallArray#`s can now be compacted into a compact region\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n","publish_time":1527624538,"version_time":1527624547,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.1-released","version":1,"title":"GHC 8.6.1 released","body":"The GHC team is pleased to announce the availability of GHC 8.6.1, the\\r\\nfourth major release in the GHC 8 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at [[https://downloads.haskell.org/~ghc/8.6.1|downloads.haskell.org]].\\r\\n\\r\\nThe 8.6 release fixes over 400 bugs from the 8.4 series and introduces a\\r\\nnumber of exciting features. These most notably include:\\r\\n\\r\\n * A new deriving mechanism, `deriving via`, providing a convenient way\\r\\n   for users to extend Haskell's typeclass deriving mechanism\\r\\n\\r\\n * Quantified constraints, allowing forall quantification in constraint contexts\\r\\n\\r\\n * An early version of the GHCi `:doc` command\\r\\n\\r\\n * The `ghc-heap-view` package, allowing introspection into the\\r\\n   structure of GHC's heap\\r\\n\\r\\n * Valid hole fit hints, helping the user to find terms to fill typed\\r\\n   holes in their programs\\r\\n\\r\\n * The BlockArguments extension, allowing the `$` operator to be omitted\\r\\n   in some unambiguous contexts\\r\\n\\r\\n * An exciting new plugin mechanism, source plugins, allowing plugins to\\r\\n   inspect and modify a wide variety of compiler representations.\\r\\n\\r\\n * Improved recompilation checking when plugins are used\\r\\n\\r\\n * Significantly better handling of macOS linker command size limits,\\r\\n   avoiding linker errors while linking large projects\\r\\n\\r\\n * The next phase of the `MonadFail` proposal, enabling\\r\\n   `-XMonadFailDesugaring` by default\\r\\n\\r\\nA full list of the changes in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/8.6.1-notes.html|release notes]].\\r\\n\\r\\nPerhaps of equal importance, GHC 8.6 is the second major release made\\r\\nunder GHC's accelerated six-month release schedule and the first set of\\r\\nbinary distributions built primarily using our new continuous\\r\\nintegration scheme. While the final 8.6 release is around three weeks\\r\\nlater than initially scheduled due to late-breaking bug reports, we\\r\\nexpect that the 8.8 release schedule shouldn't be affected.\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n","publish_time":1537577799,"version_time":1537577799,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":""},
{"name":"ghc-8.6.1-released","version":2,"title":"GHC 8.6.1 released","body":"The GHC team is pleased to announce the availability of GHC 8.6.1, the\\r\\nfourth major release in the GHC 8 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at [[https://downloads.haskell.org/~ghc/8.6.1|downloads.haskell.org]].\\r\\n\\r\\nThe 8.6 release fixes over 400 bugs from the 8.4 series and introduces a\\r\\nnumber of exciting features. These most notably include:\\r\\n\\r\\n * A new deriving mechanism, `deriving via`, providing a convenient way\\r\\n   for users to extend Haskell's typeclass deriving mechanism\\r\\n\\r\\n * Quantified constraints, allowing forall quantification in constraint contexts\\r\\n\\r\\n * An early version of the GHCi `:doc` command\\r\\n\\r\\n * The `ghc-heap-view` package, allowing introspection into the\\r\\n   structure of GHC's heap\\r\\n\\r\\n * Valid hole fit hints, helping the user to find terms to fill typed\\r\\n   holes in their programs\\r\\n\\r\\n * The BlockArguments extension, allowing the `$` operator to be omitted\\r\\n   in some unambiguous contexts\\r\\n\\r\\n * An exciting new plugin mechanism, source plugins, allowing plugins to\\r\\n   inspect and modify a wide variety of compiler representations.\\r\\n\\r\\n * Improved recompilation checking when plugins are used\\r\\n\\r\\n * Significantly better handling of macOS linker command size limits,\\r\\n   avoiding linker errors while linking large projects\\r\\n\\r\\n * The next phase of the `MonadFail` proposal, enabling\\r\\n   `-XMonadFailDesugaring` by default\\r\\n\\r\\nA full list of the changes in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/8.6.1-notes.html|release notes]].\\r\\n\\r\\nPerhaps of equal importance, GHC 8.6 is the second major release made\\r\\nunder GHC's accelerated six-month release schedule and the first set of\\r\\nbinary distributions built primarily using our new continuous\\r\\nintegration scheme. While the final 8.6 release is around three weeks\\r\\nlater than initially scheduled due to late-breaking bug reports, we\\r\\nexpect that the 8.8 release schedule shouldn't be affected.\\r\\n\\r\\n`cabal-install` users should note that GHC 8.6 can only be used with `cabal-install` 2.4.0.1 or later.\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n","publish_time":1537577799,"version_time":1537622415,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":""},
{"name":"ghc-8.4.4-released","version":1,"title":"GHC 8.4.4 released","body":"The GHC team is pleased to announce the availability of GHC 8.4.4, a\\r\\npatch-level release in the 8.4 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at\\r\\n[[https://downloads.haskell.org/~ghc/8.4.4|downloads.haskell.org]].\\r\\n\\r\\nThis release fixes several bugs present in 8.4.3. These include,\\r\\n\\r\\n  - A bug which could result in memory unsafety with certain uses of\\r\\n    `touch#` has been resolved. (#14346)\\r\\n\\r\\n  - A compiler panic triggered by some GADT record updates has been\\r\\n    fixed (#15499)\\r\\n\\r\\n  - The `text` library has been updated, fixing several serious bugs in\\r\\n    the version shipped with GHC 8.4.3 (see `text` issues #227, #221,\\r\\n    and #197.\\r\\n\\r\\n  - A serious code generation bug in the LLVM code generation,\\r\\n    potentially resulting in incorrect evaluation of floating point\\r\\n    expressions, has been fixed (#14251)\\r\\n\\r\\nAs always, the full release notes can be found in the [[https://downloads.haskell.org/~ghc/8.4.4/docs/html/users_guide/8.4.4-notes.html|users guide]].    \\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n\\r\\n","publish_time":1539555561,"version_time":1539555561,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.1-released","version":3,"title":"GHC 8.6.1 released","body":"The GHC team is pleased to announce the availability of GHC 8.6.1, the\\r\\nfourth major release in the GHC 8 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at [[https://downloads.haskell.org/~ghc/8.6.1|downloads.haskell.org]].\\r\\n\\r\\nThe 8.6 release fixes over 400 bugs from the 8.4 series and introduces a\\r\\nnumber of exciting features. These most notably include:\\r\\n\\r\\n * A new deriving mechanism, `deriving via`, providing a convenient way\\r\\n   for users to extend Haskell's typeclass deriving mechanism\\r\\n\\r\\n * Quantified constraints, allowing forall quantification in constraint contexts\\r\\n\\r\\n * An early version of the GHCi `:doc` command\\r\\n\\r\\n * The `ghc-heap-view` package, allowing introspection into the\\r\\n   structure of GHC's heap\\r\\n\\r\\n * Valid hole fit hints, helping the user to find terms to fill typed\\r\\n   holes in their programs\\r\\n\\r\\n * The BlockArguments extension, allowing the `$` operator to be omitted\\r\\n   in some unambiguous contexts\\r\\n\\r\\n * An exciting new plugin mechanism, source plugins, allowing plugins to\\r\\n   inspect and modify a wide variety of compiler representations.\\r\\n\\r\\n * Improved recompilation checking when plugins are used\\r\\n\\r\\n * Significantly better handling of macOS linker command size limits,\\r\\n   avoiding linker errors while linking large projects\\r\\n\\r\\n * The next phase of the `MonadFail` proposal, enabling\\r\\n   `-XMonadFailDesugaring` by default\\r\\n\\r\\nA full list of the changes in this release can be found in the\\r\\n[[https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/8.6.1-notes.html|release notes]].\\r\\n\\r\\nPerhaps of equal importance, GHC 8.6 is the second major release made\\r\\nunder GHC's accelerated six-month release schedule and the first set of\\r\\nbinary distributions built primarily using our new continuous\\r\\nintegration scheme. While the final 8.6 release is around three weeks\\r\\nlater than initially scheduled due to late-breaking bug reports, we\\r\\nexpect that the 8.8 release schedule shouldn't be affected.\\r\\n\\r\\n`cabal-install` users should note that GHC 8.6 can only be used with `cabal-install` 2.4.0.1 or later.\\r\\n\\r\\nThanks to everyone who has contributed to developing, documenting, and\\r\\ntesting this release!\\r\\n\\r\\nAs always, let us know if you encounter trouble.\\r\\n","publish_time":1537577799,"version_time":1539555572,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.2-released","version":1,"title":"GHC 8.6.2 released","body":"The GHC team is very happy to announce the availability of GHC 8.6.2, a\\r\\nbugfix release to GHC 8.6.1. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at [[https://downloads.haskell.org/~ghc/8.6.2|haskell.org]].\\r\\n\\r\\nThe 8.6 release fixes several regressions present in 8.6.1 including:\\r\\n\\r\\n * A long-standing (but previously hard to manifest) bug resulting in\\r\\n   undefined behavior for some applications of dataToTag# has been fixed\\r\\n   (#15696)\\r\\n\\r\\n * An incorrect linker path to libgmp in the Mac OS binary distributions\\r\\n   (#15404)\\r\\n\\r\\n * A regression rendering Windows installations to read-only directories\\r\\n   unusable (#15667)\\r\\n\\r\\n * A regression resulting in panics while compiling some record updates\\r\\n   of GADTs constructors  (#15499)\\r\\n\\r\\n * A regression resulting in incorrect type errors when splicing types\\r\\n   into constraint contexts has been fixed (#15815)\\r\\n\\r\\n * Around a dozen other issues.\\r\\n\\r\\nSee [[https://ghc.haskell.org/trac/ghc/query?status=closed&milestone=8.6.2&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&order=priority |Trac]] for a full list of issues resolved in this release.\\r\\n\\r\\nNote that this release ships with one significant but long-standing bug\\r\\n(#14251): Calls to functions taking both Float# and Double# may result\\r\\nin incorrect code generation when compiled using the LLVM code generator.\\r\\nThis is not a new issue, it has existed as long as the LLVM code\\r\\ngenerator has existed; however, changes in code generation in 8.6 made\\r\\nit more likely that user code using only lifted types will trigger it.\\r\\n\\r\\nHappy compiling!\\r\\n\\r\\nCheers,\\r\\n\\r\\n* Ben\\r\\n\\r\\n","publish_time":1541435501,"version_time":1541435501,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.3-released","version":1,"title":"GHC 8.6.3 released","body":"The GHC team is very happy to announce the availability of GHC 8.6.3, a\\r\\nbugfix release in the GHC 8.6 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at\\r\\n\\r\\n    https://downloads.haskell.org/~ghc/8.6.3\\r\\n\\r\\nThe 8.6 release fixes several regressions present in 8.6.2 including:\\r\\n\\r\\n - A code generation bug resulting in segmentations faults in some\\r\\n   programs (#15892)\\r\\n\\r\\n - Darwin binary distributions are now correctly built against an\\r\\n   in-tree GMP (#15404)\\r\\n\\r\\n - Three bugs leading to linker failures on Windows (#15105, #15894,\\r\\n   #15934)\\r\\n\\r\\n - A bug leading to programs with deep stacks crashing when run with\\r\\n   retainer profiling enabled (#14758)\\r\\n\\r\\n - A bug resulting in potential heap corruption during stable name\\r\\n   allocation (#15906)\\r\\n\\r\\n - Plugins are now loaded during GHCi sessions (#15633)\\r\\n\\r\\nAs a few of these issues are rather serious users are strongly\\r\\nencouraged to upgrade. See [[https://ghc.haskell.org/trac/ghc/query?status=closed&milestone=8.6.3&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&order=priority|Trac]] for a full list of issues resolved\\r\\nin this release.\\r\\n\\r\\nNote that this release ships with one significant but long-standing bug\\r\\n(#14251): Calls to functions taking both Float# and Double# may result\\r\\nin incorrect code generation when compiled using the LLVM code generator.\\r\\nThis is not a new issue, it has existed as long as the LLVM code\\r\\ngenerator has existed; however, changes in code generation in 8.6 made\\r\\nit more likely that user code using only lifted types will trigger it.\\r\\n\\r\\nHappy compiling!\\r\\n","publish_time":1544233532,"version_time":1544233532,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.3-released","version":2,"title":"GHC 8.6.3 released","body":"The GHC team is very happy to announce the availability of GHC 8.6.3, a\\r\\nbugfix release in the GHC 8.6 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are [[https://downloads.haskell.org/~ghc/8.6.3|available]].\\r\\n\\r\\nThe 8.6 release fixes several regressions present in 8.6.2 including:\\r\\n\\r\\n - A code generation bug resulting in segmentations faults in some\\r\\n   programs (#15892)\\r\\n\\r\\n - Darwin binary distributions are now correctly built against an\\r\\n   in-tree GMP (#15404)\\r\\n\\r\\n - Three bugs leading to linker failures on Windows (#15105, #15894,\\r\\n   #15934)\\r\\n\\r\\n - A bug leading to programs with deep stacks crashing when run with\\r\\n   retainer profiling enabled (#14758)\\r\\n\\r\\n - A bug resulting in potential heap corruption during stable name\\r\\n   allocation (#15906)\\r\\n\\r\\n - Plugins are now loaded during GHCi sessions (#15633)\\r\\n\\r\\nAs a few of these issues are rather serious users are strongly\\r\\nencouraged to upgrade. See [[https://ghc.haskell.org/trac/ghc/query?status=closed&milestone=8.6.3&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&order=priority|Trac]] for a full list of issues resolved\\r\\nin this release.\\r\\n\\r\\nNote that this release ships with one significant but long-standing bug\\r\\n(#14251): Calls to functions taking both Float# and Double# may result\\r\\nin incorrect code generation when compiled using the LLVM code generator.\\r\\nThis is not a new issue, it has existed as long as the LLVM code\\r\\ngenerator has existed; however, changes in code generation in 8.6 made\\r\\nit more likely that user code using only lifted types will trigger it.\\r\\n\\r\\nHappy compiling!\\r\\n","publish_time":1544233532,"version_time":1544233559,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"},
{"name":"ghc-8.6.4-released","version":1,"title":"GHC 8.6.4 released","body":"The GHC team is very happy to announce the availability of GHC 8.6.4, a\\r\\nbugfix release in the GHC 8.6 series. The source distribution, binary\\r\\ndistributions, and documentation for this release are available at\\r\\n[[https://downloads.haskell.org/~ghc/8.6.4|downloads.haskell.org]].\\r\\n\\r\\nThe 8.6.4 release fixes several regressions present in 8.6.3 including:\\r\\n\\r\\n - A regression resulting in segmentation faults on Windows introduced\\r\\n   by the fix for #16071 backported in 8.6.3. This fix has been reverted,\\r\\n   meaning that 8.6.4 is once again susceptible to #16071. #16071 will\\r\\n   be fixed in GHC 8.8.1.\\r\\n\\r\\n - A bug resulting in incorrect locking on Darwin, potentially resulting\\r\\n   in hangs at shutdown (#16150)\\r\\n\\r\\n - A few bugs in the profiled runtime resulting in the potential for\\r\\n   memory unsafety has been fixed (#15508).\\r\\n\\r\\n - The `process` and `transformers` libraries shipped properly reflect\\r\\n   released Hackage releases (#16199)\\r\\n\\r\\n - A bug where TH name resolution would break in a plugin context has\\r\\n   been fixed (#16104)\\r\\n\\r\\n - Compilers that do not support TemplateHaskell no longer advertise\\r\\n   such support in `--supported-languages` (#16331)\\r\\n\\r\\nAs a few of these issues are rather serious users are strongly\\r\\nencouraged to upgrade. See [[\\r\\nhttps://ghc.haskell.org/trac/ghc/query?status=closed&milestone=8.6.4&col=id&col=summary&col=status&col=type&col=priority&col=milestone&col=component&order=priority |Trac]] for a full list of issues resolved\\r\\nin this release.\\r\\n\\r\\nNote that this release ships with one significant but long-standing bug\\r\\n(#14251): Calls to functions taking both Float# and Double# may result\\r\\nin incorrect code generation when compiled using the LLVM code generator.\\r\\nThis is not a new issue, it has existed as long as the LLVM code\\r\\ngenerator has existed; however, changes in code generation in 8.6 made\\r\\nit more likely that user code using only lifted types will trigger it.\\r\\n\\r\\nNote also that this is the first release cut from our (yet again)\\r\\nrevamped continuous integration infrastructure. While we have done a\\r\\ngreat deal of checking to ensure that the build configuration reflects\\r\\nthat of previous releases, do let us know if something looks off.\\r\\n\\r\\nHappy compiling!\\r\\n\\r\\n","publish_time":1551819134,"version_time":1551819134,"version_comment":"","version_author":"bgamari","author":"Ben Gamari","categories":"release"}]
